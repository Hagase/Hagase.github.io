{"meta":{"title":"Shiroha","subtitle":null,"description":"Shiroha的个人博客网站。","author":"Shiroha","url":""},"pages":[{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2019-08-21T22:50:08.000Z","comments":false,"path":"client/index.html","permalink":"/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"comment","date":"2018-12-20T15:13:48.000Z","updated":"2019-08-21T22:50:08.000Z","comments":true,"path":"comment/index.html","permalink":"/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","keywords":"留言板"},{"title":"donate","date":"2018-12-20T15:13:05.000Z","updated":"2019-08-21T22:50:08.000Z","comments":false,"path":"donate/index.html","permalink":"/donate/index.html","excerpt":"","text":"","keywords":"谢谢饲主了喵~"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2019-08-21T22:50:08.000Z","comments":false,"path":"lab/index.html","permalink":"/lab/index.html","excerpt":"","text":"sakura主题balabala","keywords":"Lab实验室"},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2019-09-01T07:03:48.054Z","comments":false,"path":"music/index.html","permalink":"/music/index.html","excerpt":"","text":"","keywords":"喜欢的音乐"},{"title":"","date":"2020-07-20T00:58:43.238Z","updated":"2020-07-20T00:58:43.238Z","comments":true,"path":"taotao/index.html","permalink":"/taotao/index.html","excerpt":"","text":"Oda Nobuhime Count. 距离陆桃引退已经 Oda Nobuhime has separated from vtuber for: Designed by 森稳XenWayne——优秀的谢拉单推人 &nbsp;&nbsp;&nbsp; 萌娘百科-Cierra 基准时：北京时间2020年07月15日22:30 （UTC/GMT+08:00 2020/04/30 22:30） .snow-container{position:fixed;top:0;left:0;width:100%;height:100%;pointer-events:none;z-index:100001;}"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2019-08-21T22:50:08.000Z","comments":true,"path":"links/index.html","permalink":"/links/index.html","excerpt":"","text":"","keywords":"友人帐"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2019-09-01T13:37:44.317Z","comments":false,"path":"bangumi/index.html","permalink":"/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2019-08-21T22:50:08.000Z","comments":true,"path":"rss/index.html","permalink":"/rss/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2019-08-21T22:50:08.000Z","comments":true,"path":"tags/index.html","permalink":"/tags/index.html","excerpt":"","text":""},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2019-08-21T22:50:08.000Z","comments":false,"path":"theme-sakura/index.html","permalink":"/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro","keywords":"Hexo 主题 Sakura 🌸"},{"title":"about","date":"2018-12-12T14:14:36.000Z","updated":"2019-09-01T13:00:37.127Z","comments":false,"path":"about/index.html","permalink":"/about/index.html","excerpt":"","text":"[Shirohaの小矛屋] 与&nbsp; Shiroha&nbsp; （ 白（しろ）羽（は） ） 对话中... bot_ui_ini()","keywords":"关于"},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2019-08-21T22:50:08.000Z","comments":false,"path":"video/index.html","permalink":"/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"},{"title":"","date":"2020-07-20T00:39:39.723Z","updated":"2020-04-30T17:16:18.421Z","comments":true,"path":"taotao/css/main.css","permalink":"/taotao/css/main.css","excerpt":"","text":"h1,h2,h3,h4,h5,h6 { color: #6cf; font-family: aleo-regular,arial; letter-spacing: 1px } h1 { font-size: 1.7em } h2 { font-size: 1.5em } h3 { font-size: 1.17em } h5 { font-size: .83em } h6 { font-size: .75em } h1,h2,h3,h4,h5,h6 { font-weight: bolder } #main { font-size: 30px; padding-top: 1%; text-align: center; font-family: Microsoft JhengHei; color: #ff6ff7; text-shadow: 0 0 15px rgba(255, 255, 255, 1.0) } .wrapper { width: 790px; margin: 0 auto } #divfoot { width: 100%; height: 20px; text-align: center; font-family: Microsoft JhengHei; color: #fff } a { color: #fff } a:hover { color: #6cf } .content { position: absolute; display: block; overflow: hidden; z-index: 9999; text-align: center } .content h1 { color: #fff; font-family: aleo-bold,arial; font-size: 56px; font-weight: 700; text-transform: uppercase; letter-spacing: 1px } .content p { color: #fff; font-size: 16px; letter-spacing: 1px; line-height: 28px } .counter { margin-top: 40px } .time_circles { position: relative; width: 100%; height: 100% } .time_circles>div { position: absolute; text-align: center } .time_circles>div>h4 { margin: 0; padding: 0; text-align: center; text-transform: uppercase; font-family: lato-regular,Arial; color: #fff; font-weight: 400!important } .time_circles>div>span { display: block; width: 100%; text-align: center; font-family: lato-bold,Arial; margin: .25em 0 .5em; font-weight: 700; color: #fff; font-size: 40px } #web_bg { position: fixed; top: 0; left: 0; width: 100%; height: 100%; min-width: 1000px; z-index: -10; zoom:1;background-color: #fff; background-repeat: no-repeat; background-size: cover; -webkit-background-size: cover; -o-background-size: cover; background-position: center 0 }"},{"title":"","date":"2020-07-19T01:06:36.186Z","updated":"2020-02-07T12:45:30.465Z","comments":true,"path":"taotao/js/main.js","permalink":"/taotao/js/main.js","excerpt":"","text":"$(document).ready(function(){$box=$('.content');$ht=$box.height()+175;$win_ht=$(window).height();if($win_ht>$ht){$box.css({'left':'50%','top':'50%','margin-left':-$box.width()/2+'px','margin-top':-$ht/2+'px'});}else{$box.css({'left':'50%','margin-left':-$box.width()/2+'px','margin-top':'60px','margin-bottom':'60px'});} $.backstretch([\"img/bg_img.jpg\",\"img/bg_img2.jpg\",\"img/bg_img3.jpg\"],{fade:750,duration:2500});$(\".counter\").TimeCircles({\"direction\":\"Clockwise\",\"animation\":\"Tricks\",\"bg_width\":0,\"fg_width\":0.01,\"circle_bg_color\":\"rgba(255, 255, 255, 0)\",\"circle_bg_fill_color\":\"rgba(255, 255, 255, 0.1)\",\"time\":{\"Days\":{\"text\":\"Days\",\"color\":\"#ffffff\",\"show\":true},\"Hours\":{\"text\":\"Hrs\",\"color\":\"#ffffff\",\"show\":true},\"Minutes\":{\"text\":\"Mins\",\"color\":\"#ffffff\",\"show\":true},\"Seconds\":{\"text\":\"Secs\",\"color\":\"#ffffff\",\"show\":true}}});$('#sub_form').submit(function(){submit_icons('icon','loading');}) if($('#sub_form').length){$('#sub_form').ajaxChimp({callback:bcFunction});} function bcFunction(resp){if(resp.result==='success'){submit_icons('loading','icon');show_tooltip('Thank You For Subscribing To Our Email List');$('#sub_form #mc-email').val('');}else{submit_icons('loading','icon');show_tooltip('Please Enter a Correct Email');}} function submit_icons(hide,show){$('#mc_submit i').removeClass(hide);$('#mc_submit i').addClass(show);} function show_tooltip(msg){if($(\".tooltip\").length){$(\".tooltip\").remove();} $('.subscription_form').append('');var tooltip=$(\".tooltip\");tooltip.append(msg);var tipwidth=tooltip.outerWidth();var a_width=$('.subscription_form').width();var a_hegiht=$('.subscription_form').height()+10;var tipwidth=(a_width-tipwidth)/2;$('.tooltip').css({'left':tipwidth+'px','bottom':a_hegiht+'px'}).stop().animate({opacity:1},300);setTimeout(function(){hide_tooltip();},2000);} function hide_tooltip(){var tooltip=$(\".tooltip\");tooltip.animate({opacity:0},300,function(){tooltip.remove();});}});"},{"title":"","date":"2020-02-07T12:06:34.878Z","updated":"2020-02-07T12:06:34.845Z","comments":true,"path":"taotao/js/backstretch.js","permalink":"/taotao/js/backstretch.js","excerpt":"","text":"/*! Backstretch - v2.0.4 - 2013-06-19 * http://srobbin.com/jquery-plugins/backstretch/ * Copyright (c) 2013 Scott Robbin; Licensed MIT */(function(a,d,p){a.fn.backstretch=function(c,b){(c===p||0===c.length)&&a.error(\"No images were supplied for Backstretch\");0===a(d).scrollTop()&&d.scrollTo(0,0);return this.each(function(){var d=a(this),g=d.data(\"backstretch\");if(g){if(\"string\"==typeof c&&\"function\"==typeof g[c]){g[c](b);return}b=a.extend(g.options,b);g.destroy(!0)}g=new q(this,c,b);d.data(\"backstretch\",g)})};a.backstretch=function(c,b){return a(\"body\").backstretch(c,b).data(\"backstretch\")};a.expr[\":\"].backstretch=function(c){return a(c).data(\"backstretch\")!==p};a.fn.backstretch.defaults={centeredX:!0,centeredY:!0,duration:5E3,fade:0};var r={left:0,top:0,overflow:\"hidden\",margin:0,padding:0,height:\"100%\",width:\"100%\",zIndex:-999999},s={position:\"absolute\",display:\"none\",margin:0,padding:0,border:\"none\",width:\"auto\",height:\"auto\",maxHeight:\"none\",maxWidth:\"none\",zIndex:-999999},q=function(c,b,e){this.options=a.extend({},a.fn.backstretch.defaults,e||{});this.images=a.isArray(b)?b:[b];a.each(this.images,function(){a(\"\")[0].src=this});this.isBody=c===document.body;this.$container=a(c);this.$root=this.isBody?l?a(d):a(document):this.$container;c=this.$container.children(\".backstretch\").first();this.$wrap=c.length?c:a('').css(r).appendTo(this.$container);this.isBody||(c=this.$container.css(\"position\"),b=this.$container.css(\"zIndex\"),this.$container.css({position:\"static\"===c?\"relative\":c,zIndex:\"auto\"===b?0:b,background:\"none\"}),this.$wrap.css({zIndex:-999998}));this.$wrap.css({position:this.isBody&&l?\"fixed\":\"absolute\"});this.index=0;this.show(this.index);a(d).on(\"resize.backstretch\",a.proxy(this.resize,this)).on(\"orientationchange.backstretch\",a.proxy(function(){this.isBody&&0===d.pageYOffset&&(d.scrollTo(0,1),this.resize())},this))};q.prototype={resize:function(){try{var a={left:0,top:0},b=this.isBody?this.$root.width():this.$root.innerWidth(),e=b,g=this.isBody?d.innerHeight?d.innerHeight:this.$root.height():this.$root.innerHeight(),j=e/this.$img.data(\"ratio\"),f;j>=g?(f=(j-g)/2,this.options.centeredY&&(a.top=\"-\"+f+\"px\")):(j=g,e=j*this.$img.data(\"ratio\"),f=(e-b)/2,this.options.centeredX&&(a.left=\"-\"+f+\"px\"));this.$wrap.css({width:b,height:g}).find(\"img:not(.deleteable)\").css({width:e,height:j}).css(a)}catch(h){}return this},show:function(c){if(!(Math.abs(c)>this.images.length-1)){var b=this,e=b.$wrap.find(\"img\").addClass(\"deleteable\"),d={relatedTarget:b.$container[0]};b.$container.trigger(a.Event(\"backstretch.before\",d),[b,c]);this.index=c;clearInterval(b.interval);b.$img=a(\"\").css(s).bind(\"load\",function(f){var h=this.width||a(f.target).width();f=this.height||a(f.target).height();a(this).data(\"ratio\",h/f);a(this).fadeIn(b.options.speed||b.options.fade,function(){e.remove();b.paused||b.cycle();a([\"after\",\"show\"]).each(function(){b.$container.trigger(a.Event(\"backstretch.\"+this,d),[b,c])})});b.resize()}).appendTo(b.$wrap);b.$img.attr(\"src\",b.images[c]);return b}},next:function(){return this.show(this.indext||-1e||h&&6>h||\"palmGetResource\"in d&&e&&534>e||-1"},{"title":"","date":"2020-04-30T17:06:42.606Z","updated":"2020-04-30T17:06:42.606Z","comments":true,"path":"taotao/js/TimeCircles.js","permalink":"/taotao/js/TimeCircles.js","excerpt":"","text":"(function($) { var limited_mode = false; var tick_duration = 200; var debug = (location.hash === \"#debug\"); function debug_log(msg) { if (debug) { console.log(msg); } } var allUnits = [\"Days\", \"Hours\", \"Minutes\", \"Seconds\"]; var nextUnits = { Seconds: \"Minutes\", Minutes: \"Hours\", Hours: \"Days\", Days: \"Years\" }; var secondsIn = { Seconds: 1, Minutes: 60, Hours: 3600, Days: 86400, Months: 2678400, Years: 31536000 }; function hexToRgb(hex) { var shorthandRegex = /^#?([a-f\\d])([a-f\\d])([a-f\\d])$/i; hex = hex.replace(shorthandRegex, function(m, r, g, b) { return r + r + g + g + b + b; }); var result = /^#?([a-f\\d]{2})([a-f\\d]{2})([a-f\\d]{2})$/i.exec(hex); return result ? { r: parseInt(result[1], 16), g: parseInt(result[2], 16), b: parseInt(result[3], 16) } : null; } function isCanvasSupported() { var elem = document.createElement('canvas'); return !!(elem.getContext && elem.getContext('2d')); } function s4() { return Math.floor((1 + Math.random()) * 0x10000).toString(16).substring(1); } function guid() { return s4() + s4() + '-' + s4() + '-' + s4() + '-' + s4() + '-' + s4() + s4() + s4(); } if (!Array.prototype.indexOf) { Array.prototype.indexOf = function(elt) { var len = this.length >>> 0; var from = Number(arguments[1]) || 0; from = (from < 0) ? Math.ceil(from) : Math.floor(from); if (from < 0) from += len; for (; from < len; from++) { if (from in this && this[from] === elt) return from; } return -1; } ; } function parse_date(str) { var match = str.match(/^[0-9]{4}-[0-9]{2}-[0-9]{2}\\s[0-9]{1,2}:[0-9]{2}:[0-9]{2}$/); if (match !== null && match.length > 0) { var parts = str.split(\" \"); var date = parts[0].split(\"-\"); var time = parts[1].split(\":\"); return new Date(date[0],date[1] - 1,date[2],time[0],time[1],time[2]); } var d = Date.parse(str); if (!isNaN(d)) return d; d = Date.parse(str.replace(/-/g, '/').replace('T', ' ')); if (!isNaN(d)) return d; return new Date(); } function parse_times(diff, old_diff, total_duration, units, floor) { var raw_time = {}; var raw_old_time = {}; var time = {}; var pct = {}; var old_pct = {}; var old_time = {}; var greater_unit = null; for (var i in units) { var unit = units[i]; var maxUnits; if (greater_unit === null) { maxUnits = total_duration / secondsIn[unit]; } else { maxUnits = secondsIn[greater_unit] / secondsIn[unit]; } var curUnits = (diff / secondsIn[unit]); var oldUnits = (old_diff / secondsIn[unit]); if (floor) curUnits = Math.floor(curUnits); if (floor) oldUnits = Math.floor(oldUnits); if (unit !== \"Days\") { curUnits = curUnits % maxUnits; oldUnits = oldUnits % maxUnits; } raw_time[unit] = curUnits; time[unit] = Math.abs(curUnits); raw_old_time[unit] = oldUnits; old_time[unit] = Math.abs(oldUnits); pct[unit] = Math.abs(curUnits) / maxUnits; old_pct[unit] = Math.abs(oldUnits) / maxUnits; greater_unit = unit; } return { raw_time: raw_time, raw_old_time: raw_old_time, time: time, old_time: old_time, pct: pct, old_pct: old_pct }; } var TC_Instance_List = {}; if (window !== window.top && typeof window.top.TC_Instance_List !== \"undefined\") { TC_Instance_List = window.top.TC_Instance_List; } else { window.top.TC_Instance_List = TC_Instance_List; } (function() { var vendors = ['webkit', 'moz']; for (var x = 0; x < vendors.length && !window.top.requestAnimationFrame; ++x) { window.top.requestAnimationFrame = window.top[vendors[x] + 'RequestAnimationFrame']; window.top.cancelAnimationFrame = window.top[vendors[x] + 'CancelAnimationFrame']; } if (!window.top.requestAnimationFrame || !window.top.cancelAnimationFrame) { window.top.requestAnimationFrame = function(callback, element, instance) { if (typeof instance === \"undefined\") instance = { data: { last_frame: 0 } }; var currTime = new Date().getTime(); var timeToCall = Math.max(0, 16 - (currTime - instance.data.last_frame)); var id = window.top.setTimeout(function() { callback(currTime + timeToCall); }, timeToCall); instance.data.last_frame = currTime + timeToCall; return id; } ; window.top.cancelAnimationFrame = function(id) { clearTimeout(id); } ; } } )(); var TC_Instance = function(element, options) { this.element = element; this.container; this.listeners = null; this.data = { paused: false, last_frame: 0, animation_frame: null, timer: false, total_duration: null, prev_time: null, drawn_units: [], text_elements: { Days: null, Hours: null, Minutes: null, Seconds: null }, attributes: { canvas: null, context: null, item_size: null, line_width: null, radius: null, outer_radius: null }, state: { fading: { Days: false, Hours: false, Minutes: false, Seconds: false } } }; this.config = null; this.setOptions(options); this.initialize(); }; TC_Instance.prototype.initialize = function(clear_listeners) { this.data.drawn_units = []; for (var unit in this.config.time) { if (this.config.time[unit].show) { this.data.drawn_units.push(unit); } } $(this.element).children('div.time_circles').remove(); if (typeof clear_listeners === \"undefined\") clear_listeners = true; if (clear_listeners || this.listeners === null) { this.listeners = { all: [], visible: [] }; } this.container = $(\"\"); this.container.addClass('time_circles'); this.container.appendTo(this.element); var height = this.element.offsetHeight; var width = this.element.offsetWidth; if (height === 0) height = $(this.element).height(); if (width === 0) width = $(this.element).width(); if (height === 0 && width > 0) height = width / this.data.drawn_units.length; else if (width === 0 && height > 0) width = height * this.data.drawn_units.length; var canvasElement = document.createElement('canvas'); canvasElement.width = width; canvasElement.height = height; this.data.attributes.canvas = $(canvasElement); this.data.attributes.canvas.appendTo(this.container); var canvasSupported = isCanvasSupported(); if (!canvasSupported && typeof G_vmlCanvasManager !== \"undefined\") { G_vmlCanvasManager.initElement(canvasElement); limited_mode = true; canvasSupported = true; } if (canvasSupported) { this.data.attributes.context = canvasElement.getContext('2d'); } this.data.attributes.item_size = Math.min(width / this.data.drawn_units.length, height); this.data.attributes.line_width = this.data.attributes.item_size * this.config.fg_width; this.data.attributes.radius = ((this.data.attributes.item_size * 0.8) - this.data.attributes.line_width) / 2; this.data.attributes.outer_radius = this.data.attributes.radius + 0.5 * Math.max(this.data.attributes.line_width, this.data.attributes.line_width * this.config.bg_width); var i = 0; for (var key in this.data.text_elements) { if (!this.config.time[key].show) continue; var textElement = $(\"\"); textElement.addClass('textDiv_' + key); textElement.css(\"top\", Math.round(0.35 * this.data.attributes.item_size)); textElement.css(\"left\", Math.round(i++ * this.data.attributes.item_size)); textElement.css(\"width\", this.data.attributes.item_size); var numberElement = $(\"\"); numberElement.css(\"font-size\", Math.round(0.21 * this.data.attributes.item_size)); numberElement.css(\"line-height\", Math.round(0.07 * this.data.attributes.item_size) + \"px\"); numberElement.appendTo(textElement); textElement.appendTo(this.container); var headerElement = $(\"\"); headerElement.text(this.config.time[key].text); headerElement.css(\"font-size\", Math.round(0.07 * this.data.attributes.item_size)); headerElement.css(\"line-height\", Math.round(0.07 * this.data.attributes.item_size) + \"px\"); headerElement.appendTo(textElement); this.data.text_elements[key] = numberElement; } if (this.config.start && this.data.paused === false) this.start(); } ; TC_Instance.prototype.update = function() { if (limited_mode) { this.data.attributes.context.clearRect(0, 0, this.data.attributes.canvas[0].width, this.data.attributes.canvas[0].hright); } var diff, old_diff; var prevDate = this.data.prev_time; var curDate = new Date(); this.data.prev_time = curDate; if (prevDate === null) prevDate = curDate; if (!this.config.count_past_zero) { if (curDate > this.data.attributes.ref_date) { for (var i in this.data.drawn_units) { var key = this.data.drawn_units[i]; this.data.text_elements[key].text(\"0\"); var x = (i * this.data.attributes.item_size) + (this.data.attributes.item_size / 2); var y = this.data.attributes.item_size / 2; var color = this.config.time[key].color; this.drawArc(x, y, color, 0); } this.stop(); return; } } diff = (this.data.attributes.ref_date - curDate) / 1000; old_diff = (this.data.attributes.ref_date - prevDate) / 1000; var floor = this.config.animation !== \"smooth\"; var visible_times = parse_times(diff, old_diff, this.data.total_duration, this.data.drawn_units, floor); var all_times = parse_times(diff, old_diff, secondsIn[\"Years\"], allUnits, floor); var i = 0; var j = 0; var lastKey = null; var cur_shown = this.data.drawn_units.slice(); for (var i in allUnits) { var key = allUnits[i]; if (Math.floor(all_times.raw_time[key]) !== Math.floor(all_times.raw_old_time[key])) { this.notifyListeners(key, Math.floor(all_times.time[key]), Math.floor(diff), \"all\"); } if (cur_shown.indexOf(key) < 0) continue; if (Math.floor(visible_times.raw_time[key]) !== Math.floor(visible_times.raw_old_time[key])) { this.notifyListeners(key, Math.floor(visible_times.time[key]), Math.floor(diff), \"visible\"); } if(i==0){ console.log('modify here') this.data.text_elements[key].text(Math.floor(Math.abs(visible_times.time[key])-1)); }else{ this.data.text_elements[key].text(Math.floor(Math.abs(visible_times.time[key]))); } var x = (j * this.data.attributes.item_size) + (this.data.attributes.item_size / 2); var y = this.data.attributes.item_size / 2; var color = this.config.time[key].color; if (this.config.animation === \"smooth\") { if (lastKey !== null && !limited_mode) { if (Math.floor(visible_times.time[lastKey]) > Math.floor(visible_times.old_time[lastKey])) { this.radialFade(x, y, color, 1, key); this.data.state.fading[key] = true; } else if (Math.floor(visible_times.time[lastKey]) < Math.floor(visible_times.old_time[lastKey])) { this.radialFade(x, y, color, 0, key); this.data.state.fading[key] = true; } } if (!this.data.state.fading[key]) { this.drawArc(x, y, color, visible_times.pct[key]); } } else { this.animateArc(x, y, color, visible_times.pct[key], visible_times.old_pct[key], (new Date()).getTime() + tick_duration); } lastKey = key; j++; } var _this = this; var update = function() { _this.update.call(_this); }; if (this.config.animation === \"smooth\") { this.data.animation_frame = window.top.requestAnimationFrame(update, _this.element, _this); } else { var delay = (diff % 1) * 1000; if (delay < 0) delay = 1000 + delay; delay += 50; _this.data.animation_frame = window.top.setTimeout(function() { _this.data.animation_frame = window.top.requestAnimationFrame(update, _this.element, _this); }, delay); } } ; TC_Instance.prototype.animateArc = function(x, y, color, target_pct, cur_pct, animation_end) { if (this.data.attributes.context === null) return; var diff = cur_pct - target_pct; if (Math.abs(diff) > 0.5) { if (target_pct === 0) { this.radialFade(x, y, color, 1); } else { this.radialFade(x, y, color, 0); } } else { var progress = (tick_duration - (animation_end - (new Date()).getTime())) / tick_duration; if (progress > 1) progress = 1; var pct = (cur_pct * (1 - progress)) + (target_pct * progress); this.drawArc(x, y, color, pct); if (progress >= 1) return; var _this = this; window.top.requestAnimationFrame(function() { _this.animateArc(x, y, color, target_pct, cur_pct, animation_end); }, this.element); } } ; TC_Instance.prototype.drawArc = function(x, y, color, pct) { if (this.data.attributes.context === null) return; var clear_radius = Math.max(this.data.attributes.outer_radius, this.data.attributes.item_size / 2); if (!limited_mode) { this.data.attributes.context.clearRect(x - clear_radius, y - clear_radius, clear_radius * 2, clear_radius * 2); } if (this.config.use_background) { this.data.attributes.context.beginPath(); this.data.attributes.context.arc(x, y, this.data.attributes.radius, 0, 2 * Math.PI, false); this.data.attributes.context.lineWidth = this.data.attributes.line_width * this.config.bg_width; this.data.attributes.context.fillStyle = this.config.circle_bg_fill_color; this.data.attributes.context.fill(); this.data.attributes.context.strokeStyle = this.config.circle_bg_color; this.data.attributes.context.stroke(); } var startAngle, endAngle, counterClockwise; var defaultOffset = (-0.5 * Math.PI); var fullCircle = 2 * Math.PI; startAngle = defaultOffset + (this.config.start_angle / 360 * fullCircle); var offset = (2 * pct * Math.PI); if (this.config.direction === \"Both\") { counterClockwise = false; startAngle -= (offset / 2); endAngle = startAngle + offset; } else { if (this.config.direction === \"Clockwise\") { counterClockwise = false; endAngle = startAngle + offset; } else { counterClockwise = true; endAngle = startAngle - offset; } } this.data.attributes.context.beginPath(); this.data.attributes.context.arc(x, y, this.data.attributes.radius, startAngle, endAngle, counterClockwise); this.data.attributes.context.lineWidth = this.data.attributes.line_width; this.data.attributes.context.strokeStyle = color; this.data.attributes.context.stroke(); } ; TC_Instance.prototype.radialFade = function(x, y, color, from, key) { var rgb = hexToRgb(color); var _this = this; var step = 0.2 * ((from === 1) ? -1 : 1); var i; for (i = 0; from = 0; i++) { (function() { var delay = 50 * i; var rgba = \"rgba(\" + rgb.r + \", \" + rgb.g + \", \" + rgb.b + \", \" + (Math.round(from * 10) / 10) + \")\"; window.top.setTimeout(function() { _this.drawArc(x, y, rgba, 1); }, delay); }()); from += step; } if (typeof key !== undefined) { window.top.setTimeout(function() { _this.data.state.fading[key] = false; }, 50 * i); } } ; TC_Instance.prototype.timeLeft = function() { var now = new Date(); return ((this.data.attributes.ref_date - now) / 1000); } ; TC_Instance.prototype.start = function() { window.top.cancelAnimationFrame(this.data.animation_frame); window.top.clearTimeout(this.data.animation_frame) var attr_data_date = $(this.element).data('date'); if (typeof attr_data_date === \"undefined\") { attr_data_date = $(this.element).attr('data-date'); } if (typeof attr_data_date === \"string\") { this.data.attributes.ref_date = parse_date(attr_data_date); } else if (typeof this.data.timer === \"number\") { if (this.data.paused) { this.data.attributes.ref_date = (new Date()).getTime() + (this.data.timer * 1000); } } else { var attr_data_timer = $(this.element).data('timer'); if (typeof attr_data_timer === \"undefined\") { attr_data_timer = $(this.element).attr('data-timer'); } if (typeof attr_data_timer === \"string\") { attr_data_timer = parseFloat(attr_data_timer); } if (typeof attr_data_timer === \"number\") { this.data.timer = attr_data_timer; this.data.attributes.ref_date = (new Date()).getTime() + (attr_data_timer * 1000); } else { this.data.attributes.ref_date = this.config.ref_date; } } this.data.paused = false; this.update.call(this); } ; TC_Instance.prototype.restart = function() { this.data.timer = false; this.start(); } ; TC_Instance.prototype.stop = function() { if (typeof this.data.timer === \"number\") { this.data.timer = this.timeLeft(this); } this.data.paused = true; window.top.cancelAnimationFrame(this.data.animation_frame); } ; TC_Instance.prototype.destroy = function() { this.stop(); this.container.remove(); $(this.element).removeAttr('data-tc-id'); $(this.element).removeData('tc-id'); } ; TC_Instance.prototype.setOptions = function(options) { if (this.config === null) { this.default_options.ref_date = new Date(); this.config = $.extend(true, {}, this.default_options); } $.extend(true, this.config, options); this.data.total_duration = this.config.total_duration; if (typeof this.data.total_duration === \"string\") { if (typeof secondsIn[this.data.total_duration] !== \"undefined\") { this.data.total_duration = secondsIn[this.data.total_duration]; } else if (this.data.total_duration === \"Auto\") { for (var unit in this.config.time) { if (this.config.time[unit].show) { this.data.total_duration = secondsIn[nextUnits[unit]]; this.data.total_duration-=24*3600 break; } } } else { this.data.total_duration = secondsIn[\"Years\"]; console.error(\"Valid values for TimeCircles config.total_duration are either numeric, or (string) Years, Months, Days, Hours, Minutes, Auto\"); } } } ; TC_Instance.prototype.addListener = function(f, context, type) { if (typeof f !== \"function\") return; if (typeof type === \"undefined\") type = \"visible\"; this.listeners[type].push({ func: f, scope: context }); } ; TC_Instance.prototype.notifyListeners = function(unit, value, total, type) { for (var i = 0; i < this.listeners[type].length; i++) { var listener = this.listeners[type][i]; listener.func.apply(listener.scope, [unit, value, total]); } } ; TC_Instance.prototype.default_options = { ref_date: new Date(), start: true, animation: \"smooth\", count_past_zero: true, circle_bg_color: \"#60686F\", circle_bg_fill_color: \"#ffffff\", use_background: true, fg_width: 0.1, bg_width: 1.2, total_duration: \"Auto\", direction: \"Clockwise\", start_angle: 0, time: { Days: { show: true, text: \"Days\", color: \"#FC6\" }, Hours: { show: true, text: \"Hours\", color: \"#9CF\" }, Minutes: { show: true, text: \"Minutes\", color: \"#BFB\" }, Seconds: { show: true, text: \"Seconds\", color: \"#F99\" } } }; var TC_Class = function(elements, options) { this.elements = elements; this.options = options; this.foreach(); }; TC_Class.prototype.getInstance = function(element) { var instance; var cur_id = $(element).data(\"tc-id\"); if (typeof cur_id === \"undefined\") { cur_id = guid(); $(element).attr(\"data-tc-id\", cur_id); } if (typeof TC_Instance_List[cur_id] === \"undefined\") { var options = this.options; var element_options = $(element).data('options'); if (typeof element_options === \"string\") { element_options = JSON.parse(element_options); } if (typeof element_options === \"object\") { options = $.extend(true, {}, this.options, element_options); } instance = new TC_Instance(element,options); TC_Instance_List[cur_id] = instance; } else { instance = TC_Instance_List[cur_id]; if (typeof this.options !== \"undefined\") { instance.setOptions(this.options); } } return instance; } ; TC_Class.prototype.foreach = function(callback) { var _this = this; this.elements.each(function() { var instance = _this.getInstance(this); if (typeof callback === \"function\") { callback(instance); } }); return this; } ; TC_Class.prototype.start = function() { this.foreach(function(instance) { instance.start(); }); return this; } ; TC_Class.prototype.stop = function() { this.foreach(function(instance) { instance.stop(); }); return this; } ; TC_Class.prototype.restart = function() { this.foreach(function(instance) { instance.restart(); }); return this; } ; TC_Class.prototype.rebuild = function() { this.foreach(function(instance) { instance.initialize(false); }); return this; } ; TC_Class.prototype.getTime = function() { return this.getInstance(this.elements[0]).timeLeft(); } ; TC_Class.prototype.addListener = function(f, type) { if (typeof type === \"undefined\") type = \"visible\"; var _this = this; this.foreach(function(instance) { instance.addListener(f, _this.elements, type); }); return this; } ; TC_Class.prototype.destroy = function() { this.foreach(function(instance) { instance.destroy(); }); return this; } ; TC_Class.prototype.end = function() { return this.elements; } ; $.fn.TimeCircles = function(options) { return new TC_Class(this,options); } ; }(jQuery));"},{"title":"","date":"2020-02-07T12:06:45.201Z","updated":"2020-02-07T12:06:45.176Z","comments":true,"path":"taotao/js/snowy.js","permalink":"/taotao/js/snowy.js","excerpt":"","text":"var THREE=THREE||{};if(!self.Int32Array)self.Int32Array=Array,self.Float32Array=Array;THREE.Color=function(a){a!==void 0&&this.setHex(a);return this};THREE.Color.prototype={constructor:THREE.Color,r:1,g:1,b:1,copy:function(a){this.r=a.r;this.g=a.g;this.b=a.b;return this},copyGammaToLinear:function(a){this.r=a.r*a.r;this.g=a.g*a.g;this.b=a.b*a.b;return this},copyLinearToGamma:function(a){this.r=Math.sqrt(a.r);this.g=Math.sqrt(a.g);this.b=Math.sqrt(a.b);return this},setRGB:function(a,b,c){this.r=a;this.g=b;this.b=c;return this},setHSV:function(a,b,c){var d,f,e;if(c===0)this.r=this.g=this.b=0;else switch(d=Math.floor(a*6),f=a*6-d,a=c*(1-b),e=c*(1-b*f),b=c*(1-b*(1-f)),d){case 1:this.r=e;this.g=c;this.b=a;break;case 2:this.r=a;this.g=c;this.b=b;break;case 3:this.r=a;this.g=e;this.b=c;break;case 4:this.r=b;this.g=a;this.b=c;break;case 5:this.r=c;this.g=a;this.b=e;break;case 6:case 0:this.r=c,this.g=b,this.b=a}return this},setHex:function(a){a=Math.floor(a);this.r=(a>>16&255)/255;this.g=(a>>8&255)/255;this.b=(a&255)/255;return this},getHex:function(){return~~(this.r*255)e.getLeft()?b:e.getLeft();c=c>e.getTop()?c:e.getTop();d=d=0};this.empty=function(){h=!0;f=d=c=b=0;a()};this.isEmpty=function(){return h}};THREE.Math={clamp:function(a,b,c){return ac?c:a},clampBottom:function(a,b){return a"},{"title":"","date":"2020-02-07T12:06:41.169Z","updated":"2020-02-07T12:06:41.131Z","comments":true,"path":"taotao/js/jquery.js","permalink":"/taotao/js/jquery.js","excerpt":"","text":"/*!jQuery v1.11.0 | (c) 2005, 2014 jQuery Foundation, Inc. | jquery.org/license*/!function(a,b){\"object\"==typeof module&&\"object\"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error(\"jQuery requires a window with a document\");return b(a)}:b(a)}(\"undefined\"!=typeof window?window:this,function(a,b){var c=[],d=c.slice,e=c.concat,f=c.push,g=c.indexOf,h={},i=h.toString,j=h.hasOwnProperty,k=\"\".trim,l={},m=\"1.11.0\",n=function(a,b){return new n.fn.init(a,b)},o=/^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g,p=/^-ms-/,q=/-([\\da-z])/gi,r=function(a,b){return b.toUpperCase()};n.fn=n.prototype={jquery:m,constructor:n,selector:\"\",length:0,toArray:function(){return d.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:d.call(this)},pushStack:function(a){var b=n.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a,b){return n.each(this,a,b)},map:function(a){return this.pushStack(n.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(d.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},n.extend=n.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for(\"boolean\"==typeof g&&(j=g,g=arguments[h]||{},h++),\"object\"==typeof g||n.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(n.isPlainObject(c)||(b=n.isArray(c)))?(b?(b=!1,f=a&&n.isArray(a)?a:[]):f=a&&n.isPlainObject(a)?a:{},g[d]=n.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},n.extend({expando:\"jQuery\"+(m+Math.random()).replace(/\\D/g,\"\"),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return\"function\"===n.type(a)},isArray:Array.isArray||function(a){return\"array\"===n.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){return a-parseFloat(a)>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||\"object\"!==n.type(a)||a.nodeType||n.isWindow(a))return!1;try{if(a.constructor&&!j.call(a,\"constructor\")&&!j.call(a.constructor.prototype,\"isPrototypeOf\"))return!1}catch(c){return!1}if(l.ownLast)for(b in a)return j.call(a,b);for(b in a);return void 0===b||j.call(a,b)},type:function(a){return null==a?a+\"\":\"object\"==typeof a||\"function\"==typeof a?h[i.call(a)]||\"object\":typeof a},globalEval:function(b){b&&n.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(p,\"ms-\").replace(q,r)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b,c){var d,e=0,f=a.length,g=s(a);if(c){if(g){for(;f>e;e++)if(d=b.apply(a[e],c),d===!1)break}else for(e in a)if(d=b.apply(a[e],c),d===!1)break}else if(g){for(;f>e;e++)if(d=b.call(a[e],e,a[e]),d===!1)break}else for(e in a)if(d=b.call(a[e],e,a[e]),d===!1)break;return a},trim:k&&!k.call(\"\\ufeff\\xa0\")?function(a){return null==a?\"\":k.call(a)}:function(a){return null==a?\"\":(a+\"\").replace(o,\"\")},makeArray:function(a,b){var c=b||[];return null!=a&&(s(Object(a))?n.merge(c,\"string\"==typeof a?[a]:a):f.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(g)return g.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,f=0,g=a.length,h=s(a),i=[];if(h)for(;g>f;f++)d=b(a[f],f,c),null!=d&&i.push(d);else for(f in a)d=b(a[f],f,c),null!=d&&i.push(d);return e.apply([],i)},guid:1,proxy:function(a,b){var c,e,f;return\"string\"==typeof b&&(f=a[b],b=a,a=f),n.isFunction(a)?(c=d.call(arguments,2),e=function(){return a.apply(b||this,c.concat(d.call(arguments)))},e.guid=a.guid=a.guid||n.guid++,e):void 0},now:function(){return+new Date},support:l}),n.each(\"Boolean Number String Function Array Date RegExp Object Error\".split(\" \"),function(a,b){h[\"[object \"+b+\"]\"]=b.toLowerCase()});function s(a){var b=a.length,c=n.type(a);return\"function\"===c||n.isWindow(a)?!1:1===a.nodeType&&b?!0:\"array\"===c||0===b||\"number\"==typeof b&&b>0&&b-1 in a}var t=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s=\"sizzle\"+-new Date,t=a.document,u=0,v=0,w=eb(),x=eb(),y=eb(),z=function(a,b){return a===b&&(j=!0),0},A=\"undefined\",B=1"}],"posts":[{"title":"动漫语录收集","slug":"动漫语录收集","date":"2019-10-07T15:05:34.000Z","updated":"2019-10-07T15:04:42.463Z","comments":true,"path":"2019/10/07/动漫语录收集/","link":"","permalink":"/2019/10/07/动漫语录收集/","excerpt":"","text":"1.这早已司空见惯的风景, 在我们长大后也会变的面目全非. 但就算是风云变化, 也还是有不会改变的东西在记忆的深处,好好地保存着… ——土间埋 2.选项一直都有，但是，我们选择了这里！——比宇宙更远的地方","categories":[{"name":"生活","slug":"生活","permalink":"/categories/生活/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"/tags/动漫/"}],"keywords":[{"name":"生活","slug":"生活","permalink":"/categories/生活/"}]},{"title":"LearnOpenGL-模型加载","slug":"LearnOpenGL-模型加载","date":"2019-10-07T15:02:03.000Z","updated":"2019-10-07T15:01:56.405Z","comments":true,"path":"2019/10/07/LearnOpenGL-模型加载/","link":"","permalink":"/2019/10/07/LearnOpenGL-模型加载/","excerpt":"","text":"@[toc] AssimpAssimp数据结构的（简化）模型如下： 和材质和网格(Mesh)一样，所有的场景/模型数据都包含在Scene对象中.Scene对象也包含了场景根节点的引用. 场景的Root node（根节点）可能包含子节点（和其它的节点一样），它会有一系列指向场景对象中mMeshes数组中储存的网格数据的索引.Scene下的mMeshes数组储存了真正的Mesh对象，节点中的mMeshes数组保存的只是场景中网格数组的索引. 一个Mesh对象本身包含了渲染所需要的所有相关数据，像是顶点位置、法向量、纹理坐标、面(Face)和物体的材质. 一个网格包含了多个面.Face代表的是物体的渲染图元(Primitive)（三角形、方形、点）.一个面包含了组成图元的顶点的索引.由于顶点和索引是分开的，使用一个索引缓冲来渲染是非常简单的. 最后，一个网格也包含了一个Material对象，它包含了一些函数能让我们获取物体的材质属性，比如说颜色和纹理贴图（比如漫反射和镜面光贴图）. 所以，我们需要做的第一件事是将一个物体加载到Scene对象中，遍历节点，获取对应的Mesh对象（我们需要递归搜索每个节点的子节点），并处理每个Mesh对象来获取顶点数据、索引以及它的材质属性.最终的结果是一系列的网格数据，我们会将它们包含在一个Model对象中. 网格当使用建模工具对物体建模的时候，艺术家通常不会用单个形状创建出整个模型.通常每个模型都由几个子模型/形状组合而成.组合模型的每个单独的形状就叫做一个网格(Mesh).比如说有一个人形的角色：艺术家通常会将头部、四肢、衣服、武器建模为分开的组件，并将这些网格组合而成的结果表现为最终的模型。一个网格是我们在OpenGL中绘制物体所需的最小单位（顶点数据、索引和材质属性）.一个模型（通常）会包括多个网格. 网格首先我们来回顾一下我们目前学到的知识，想想一个网格最少需要什么数据.一个网格应该至少需要一系列的顶点，每个顶点包含一个位置向量、一个法向量和一个纹理坐标向量.一个网格还应该包含用于索引绘制的索引以及纹理形式的材质数据（漫反射/镜面光贴图）. 既然我们有了一个网格类的最低需求，我们可以在OpenGL中定义一个顶点了： struct Vertex &#123; glm::vec3 Position; glm::vec3 Normal; glm::vec2 TexCoords;&#125;; 我们将所有需要的向量储存到一个叫做Vertex的结构体中，我们可以用它来索引每个顶点属性.除了Vertex结构体之外，我们还需要将纹理数据整理到一个Texture结构体中.struct Texture &#123; unsigned int id; string type;&#125;; 我们储存了纹理的id以及它的类型，比如是漫反射贴图或者是镜面光贴图. 知道了顶点和纹理的实现，我们可以开始定义网格类的结构了： class Mesh &#123; public: /* 网格数据 */ vector&lt;Vertex&gt; vertices; vector&lt;unsigned int&gt; indices; vector&lt;Texture&gt; textures; /* 函数 */ Mesh(vector&lt;Vertex&gt; vertices, vector&lt;unsigned int&gt; indices, vector&lt;Texture&gt; textures); void Draw(Shader shader); private: /* 渲染数据 */ unsigned int VAO, VBO, EBO; /* 函数 */ void setupMesh();&#125;; 我们将所有必须的数据赋予了网格，我们在setupMesh函数中初始化缓冲，并最终使用Draw函数来绘制网格.注意我们将一个着色器传入了Draw函数中，将着色器传入网格类中可以让我们在绘制之前设置一些uniform（像是链接采样器到纹理单元）. Mesh构造函数：Mesh(vector&lt;Vertex&gt; vertices, vector&lt;unsigned int&gt; indices, vector&lt;Texture&gt; textures)&#123; this-&gt;vertices = vertices; this-&gt;indices = indices; this-&gt;textures = textures; setupMesh();&#125; 初始化由于有了构造器，我们现在有一大列的网格数据用于渲染.在此之前我们还必须配置正确的缓冲，并通过顶点属性指针定义顶点着色器的布局.现在你应该对这些概念都很熟悉了，但我们这次会稍微有一点变动，使用结构体中的顶点数据：void setupMesh()&#123; glGenVertexArrays(1, &amp;VAO); glGenBuffers(1, &amp;VBO); glGenBuffers(1, &amp;EBO); glBindVertexArray(VAO); glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, vertices.size() * sizeof(Vertex), &amp;vertices[0], GL_STATIC_DRAW); glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO); glBufferData(GL_ELEMENT_ARRAY_BUFFER, indices.size() * sizeof(unsigned int), &amp;indices[0], GL_STATIC_DRAW); // 顶点位置 glEnableVertexAttribArray(0); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex), (void*)0); // 顶点法线 glEnableVertexAttribArray(1); glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex), (void*)offsetof(Vertex, Normal)); // 顶点纹理坐标 glEnableVertexAttribArray(2); glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, sizeof(Vertex), (void*)offsetof(Vertex, TexCoords)); glBindVertexArray(0);&#125; C++结构体有一个很棒的特性，它们的内存布局是连续的(Sequential).也就是说，如果我们将结构体作为一个数据数组使用，那么它将会以顺序排列结构体的变量，这将会直接转换为我们在数组缓冲中所需要的float（实际上是字节）数组.比如说，如果我们有一个填充后的Vertex结构体，那么它的内存布局将会等于： Vertex vertex;vertex.Position = glm::vec3(0.2f, 0.4f, 0.6f);vertex.Normal = glm::vec3(0.0f, 1.0f, 0.0f);vertex.TexCoords = glm::vec2(1.0f, 0.0f);// = [0.2f, 0.4f, 0.6f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f]; 由于有了这个有用的特性，我们能够直接传入一大列的Vertex结构体的指针作为缓冲的数据，它们将会完美地转换为glBufferData所能用的参数： glBufferData(GL_ARRAY_BUFFER, vertices.size() * sizeof(Vertex), &amp;vertices[0], GL_STATIC_DRAW); 自然sizeof运算也可以用在结构体上来计算它的字节大小.这个应该是32字节的（8个float * 每个4字节）. 结构体的另外一个很好的用途是它的预处理指令offsetof(s, m)，它的第一个参数是一个结构体，第二个参数是这个结构体中变量的名字.这个宏会返回那个变量距结构体头部的字节偏移量(Byte Offset).这正好可以用在定义glVertexAttribPointer函数中的偏移参数： glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, sizeof(Vertex), (void*)offsetof(Vertex, Normal)); 偏移量现在是使用offsetof来定义了，在这里它会将法向量的字节偏移量设置为结构体中法向量的偏移量，也就是3个float，即12字节.注意，我们同样将步长参数设置为了Vertex结构体的大小. 使用这样的一个结构体不仅能够提供可读性更高的代码，也允许我们很容易地拓展这个结构.如果我们希望添加另一个顶点属性，我们只需要将它添加到结构体中就可以了.由于它的灵活性，渲染的代码不会被破坏. 渲染我们需要为Mesh类定义最后一个函数，它的Draw函数.在真正渲染这个网格之前，我们需要在调用glDrawElements函数之前先绑定相应的纹理.然而，这实际上有些困难，我们一开始并不知道这个网格（如果有的话）有多少纹理、纹理是什么类型的.所以我们该如何在着色器中设置纹理单元和采样器呢？ 为了解决这个问题，我们需要设定一个命名标准：每个漫反射纹理被命名为texture_diffuseN，每个镜面光纹理应该被命名为texture_specularN，其中N的范围是1到纹理采样器最大允许的数字.比如说我们对某一个网格有3个漫反射纹理，2个镜面光纹理，它们的纹理采样器应该之后会被调用： uniform sampler2D texture_diffuse1;uniform sampler2D texture_diffuse2;uniform sampler2D texture_diffuse3;uniform sampler2D texture_specular1;uniform sampler2D texture_specular2; 根据这个标准，我们可以在着色器中定义任意需要数量的纹理采样器，如果一个网格真的包含了（这么多）纹理，我们也能知道它们的名字是什么.根据这个标准，我们也能在一个网格中处理任意数量的纹理，开发者也可以自由选择需要使用的数量，他只需要定义正确的采样器就可以了（虽然定义少的话会有点浪费绑定和uniform调用）. 最终的渲染代码是这样的： void Draw(Shader shader) &#123; unsigned int diffuseNr = 1; unsigned int specularNr = 1; for(unsigned int i = 0; i &lt; textures.size(); i++) &#123; glActiveTexture(GL_TEXTURE0 + i); // 在绑定之前激活相应的纹理单元 // 获取纹理序号（diffuse_textureN 中的 N） string number; string name = textures[i].type; if(name == \"texture_diffuse\") number = std::to_string(diffuseNr++); else if(name == \"texture_specular\") number = std::to_string(specularNr++); shader.setFloat((\"material.\" + name + number).c_str(), i); glBindTexture(GL_TEXTURE_2D, textures[i].id); &#125; glActiveTexture(GL_TEXTURE0); // 绘制网格 glBindVertexArray(VAO); glDrawElements(GL_TRIANGLES, indices.size(), GL_UNSIGNED_INT, 0); glBindVertexArray(0);&#125; 我们首先计算了每个纹理类型的N-分量，并将其拼接到纹理类型字符串上，来获取对应的uniform名称.接下来我们查找对应的采样器，将它的位置值设置为当前激活的纹理单元，并绑定纹理.这也是我们在Draw函数中需要着色器的原因.我们也将”material.”添加到了最终的uniform名称中，因为我们希望将纹理储存在一个材质结构体中（这在每个实现中可能都不同）. 模型这一节我们会使用Assimp来加载模型，并将它转换(Translate)至多个在上一节中创建的Mesh对象.Model的定义如下:class Model &#123; public: /* 函数 */ Model(char *path) &#123; loadModel(path); &#125; void Draw(Shader shader); private: /* 模型数据 */ vector&lt;Mesh&gt; meshes; string directory; /* 函数 */ void loadModel(string path); void processNode(aiNode *node, const aiScene *scene); Mesh processMesh(aiMesh *mesh, const aiScene *scene); vector&lt;Texture&gt; loadMaterialTextures(aiMaterial *mat, aiTextureType type, string typeName);&#125;; Model类包含了一个Mesh对象的vector，构造器需要我们给它一个文件路径.在构造器中，它会直接通过loadModel来加载文件.私有函数将会处理Assimp导入过程中的一部分，我们很快就会介绍它们.我们还将储存文件路径的目录，在之后加载纹理的时候还会用到它. Draw函数没有什么特别之处，基本上就是遍历了所有网格，并调用它们各自的Draw函数. void Draw(Shader shader)&#123; for(unsigned int i = 0; i &lt; meshes.size(); i++) meshes[i].Draw(shader);&#125; 导入3D模型到OpenGL要想导入一个模型，并将它转换到我们自己的数据结构中的话，首先我们需要包含Assimp对应的头文件，这样编译器就不会抱怨我们了. #include &lt;assimp/Importer.hpp&gt;#include &lt;assimp/scene.h&gt;#include &lt;assimp/postprocess.h&gt; 首先需要调用的函数是loadModel，它会从构造器中直接调用.在loadModel中，我们使用Assimp来加载模型至Assimp的一个叫做scene的数据结构中.你可能还记得在模型加载章节的第一节教程中，这是Assimp数据接口的根对象.一旦我们有了这个场景对象，我们就能访问到加载后的模型中所有所需的数据了. Assimp很棒的一点在于，它抽象掉了加载不同文件格式的所有技术细节，只需要一行代码就能完成所有的工作： Assimp::Importer importer;const aiScene *scene = importer.ReadFile(path, aiProcess_Triangulate | aiProcess_FlipUVs); 我们首先声明了Assimp命名空间内的一个Importer，之后调用了它的ReadFile函数.这个函数需要一个文件路径，它的第二个参数是一些后期处理(Post-processing)的选项。除了加载文件之外，Assimp允许我们设定一些选项来强制它对导入的数据做一些额外的计算或操作。通过设定aiProcess_Triangulate，我们告诉Assimp，如果模型不是（全部）由三角形组成，它需要将模型所有的图元形状变换为三角形.aiProcess_FlipUVs将在处理的时候翻转y轴的纹理坐标（你可能还记得我们在纹理教程中说过，在OpenGL中大部分的图像的y轴都是反的，所以这个后期处理选项将会修复这个）.其它一些比较有用的选项有： aiProcess_GenNormals：如果模型不包含法向量的话，就为每个顶点创建法线. aiProcess_SplitLargeMeshes：将比较大的网格分割成更小的子网格，如果你的渲染有最大顶点数限制，只能渲染较小的网格，那么它会非常有用. aiProcess_OptimizeMeshes：和上个选项相反，它会将多个小网格拼接为一个大的网格，减少绘制调用从而进行优化. Assimp提供了很多有用的后期处理指令，你可以在这里找到全部的指令.实际上使用Assimp加载模型是非常容易的（你也可以看到）.困难的是之后使用返回的场景对象将加载的数据转换到一个Mesh对象的数组. 完整的loadModel函数将会是这样的： void loadModel(string path)&#123; Assimp::Importer import; const aiScene *scene = import.ReadFile(path, aiProcess_Triangulate | aiProcess_FlipUVs); if(!scene || scene-&gt;mFlags &amp; AI_SCENE_FLAGS_INCOMPLETE || !scene-&gt;mRootNode) &#123; cout &lt;&lt; \"ERROR::ASSIMP::\" &lt;&lt; import.GetErrorString() &lt;&lt; endl; return; &#125; directory = path.substr(0, path.find_last_of('/')); processNode(scene-&gt;mRootNode, scene);&#125; 在我们加载了模型之后，我们会检查场景和其根节点不为null，并且检查了它的一个标记(Flag)，来查看返回的数据是不是不完整的.如果遇到了任何错误，我们都会通过导入器的GetErrorString函数来报告错误并返回.我们也获取了文件路径的目录路径. 如果什么错误都没有发生，我们希望处理场景中的所有节点，所以我们将第一个节点（根节点）传入了递归的processNode函数.因为每个节点（可能）包含有多个子节点，我们希望首先处理参数中的节点，再继续处理该节点所有的子节点，以此类推.这正符合一个递归结构，所以我们将定义一个递归函数.递归函数在做一些处理之后，使用不同的参数递归调用这个函数自身，直到某个条件被满足停止递归.在我们的例子中退出条件(Exit Condition)是所有的节点都被处理完毕。 你可能还记得Assimp的结构中，每个节点包含了一系列的网格索引，每个索引指向场景对象中的那个特定网格.我们接下来就想去获取这些网格索引，获取每个网格，处理每个网格，接着对每个节点的子节点重复这一过程。processNode函数的内容如下：void processNode(aiNode *node, const aiScene *scene)&#123; // 处理节点所有的网格（如果有的话） for(unsigned int i = 0; i &lt; node-&gt;mNumMeshes; i++) &#123; aiMesh *mesh = scene-&gt;mMeshes[node-&gt;mMeshes[i]]; meshes.push_back(processMesh(mesh, scene)); &#125; // 接下来对它的子节点重复这一过程 for(unsigned int i = 0; i &lt; node-&gt;mNumChildren; i++) &#123; processNode(node-&gt;mChildren[i], scene); &#125;&#125; 我们首先检查每个节点的网格索引，并索引场景的mMeshes数组来获取对应的网格.返回的网格将会传递到processMesh函数中，它会返回一个Mesh对象，我们可以将它存储在meshes列表/vector. 所有网格都被处理之后，我们会遍历节点的所有子节点，并对它们调用相同的processMesh函数.当一个节点不再有任何子节点之后，这个函数将会停止执行. 认真的读者可能会发现，我们可以基本上忘掉处理任何的节点，只需要遍历场景对象的所有网格，就不需要为了索引做这一堆复杂的东西了.我们仍这么做的原因是，使用节点的最初想法是将网格之间定义一个父子关系.通过这样递归地遍历这层关系，我们就能将某个网格定义为另一个网格的父网格了.这个系统的一个使用案例是，当你想位移一个汽车的网格时，你可以保证它的所有子网格（比如引擎网格、方向盘网格、轮胎网格）都会随着一起位移。这样的系统能够用父子关系很容易地创建出来.然而，现在我们并没有使用这样一种系统，但如果你想对你的网格数据有更多的控制，通常都是建议使用这一种方法的。这种类节点的关系毕竟是由创建了这个模型的艺术家所定义. 从Assimp到网格将一个aiMesh对象转化为我们自己的网格对象不是那么困难.我们要做的只是访问网格的相关属性并将它们储存到我们自己的对象中.processMesh函数的大体结构如下： Mesh processMesh(aiMesh *mesh, const aiScene *scene)&#123; vector&lt;Vertex&gt; vertices; vector&lt;unsigned int&gt; indices; vector&lt;Texture&gt; textures; for(unsigned int i = 0; i &lt; mesh-&gt;mNumVertices; i++) &#123; Vertex vertex; // 处理顶点位置、法线和纹理坐标 ... vertices.push_back(vertex); &#125; // 处理索引 ... // 处理材质 if(mesh-&gt;mMaterialIndex &gt;= 0) &#123; ... &#125; return Mesh(vertices, indices, textures);&#125; 处理网格的过程主要有三部分：获取所有的顶点数据，获取它们的网格索引，并获取相关的材质数据.处理后的数据将会储存在三个vector当中，我们会利用它们构建一个Mesh对象，并返回它到函数的调用者那里. 获取顶点数据非常简单，我们定义了一个Vertex结构体，我们将在每个迭代之后将它加到vertices数组中.我们会遍历网格中的所有顶点（使用mesh-&gt;mNumVertices来获取）.在每个迭代中，我们希望使用所有的相关数据填充这个结构体。顶点的位置是这样处理的： glm::vec3 vector; vector.x = mesh-&gt;mVertices[i].x;vector.y = mesh-&gt;mVertices[i].y;vector.z = mesh-&gt;mVertices[i].z; vertex.Position = vector; 注意我们为了传输Assimp的数据，我们定义了一个vec3的临时变量.使用这样一个临时变量的原因是Assimp对向量、矩阵、字符串等都有自己的一套数据类型，它们并不能完美地转换到GLM的数据类型中. Assimp将它的顶点位置数组叫做mVertices，这其实并不是那么直观. 处理法线的步骤也是差不多的： vector.x = mesh-&gt;mNormals[i].x;vector.y = mesh-&gt;mNormals[i].y;vector.z = mesh-&gt;mNormals[i].z;vertex.Normal = vector; 纹理坐标的处理也大体相似，但Assimp允许一个模型在一个顶点上有最多8个不同的纹理坐标，我们不会用到那么多，我们只关心第一组纹理坐标.我们同样也想检查网格是否真的包含了纹理坐标（可能并不会一直如此）. if(mesh-&gt;mTextureCoords[0]) // 网格是否有纹理坐标？&#123; glm::vec2 vec; vec.x = mesh-&gt;mTextureCoords[0][i].x; vec.y = mesh-&gt;mTextureCoords[0][i].y; vertex.TexCoords = vec;&#125;else vertex.TexCoords = glm::vec2(0.0f, 0.0f); vertex结构体现在已经填充好了需要的顶点属性，我们会在迭代的最后将它压入vertices这个vector的尾部.这个过程会对每个网格的顶点都重复一遍. 索引Assimp的接口定义了每个网格都有一个面(Face)数组，每个面代表了一个图元，在我们的例子中（由于使用了aiProcess_Triangulate选项）它总是三角形.一个面包含了多个索引，它们定义了在每个图元中，我们应该绘制哪个顶点，并以什么顺序绘制，所以如果我们遍历了所有的面，并储存了面的索引到indices这个vector中就可以了. for(unsigned int i = 0; i &lt; mesh-&gt;mNumFaces; i++)&#123; aiFace face = mesh-&gt;mFaces[i]; for(unsigned int j = 0; j &lt; face.mNumIndices; j++) indices.push_back(face.mIndices[j]);&#125; 所有的外部循环都结束了，我们现在有了一系列的顶点和索引数据，它们可以用来通过glDrawElements函数来绘制网格.然而，为了结束这个话题，并且对网格提供一些细节，我们还需要处理网格的材质. 材质和节点一样，一个网格只包含了一个指向材质对象的索引.如果想要获取网格真正的材质，我们还需要索引场景的mMaterials数组.网格材质索引位于它的mMaterialIndex属性中，我们同样可以用它来检测一个网格是否包含有材质： if(mesh-&gt;mMaterialIndex &gt;= 0)&#123; aiMaterial *material = scene-&gt;mMaterials[mesh-&gt;mMaterialIndex]; vector&lt;Texture&gt; diffuseMaps = loadMaterialTextures(material, aiTextureType_DIFFUSE, \"texture_diffuse\"); textures.insert(textures.end(), diffuseMaps.begin(), diffuseMaps.end()); vector&lt;Texture&gt; specularMaps = loadMaterialTextures(material, aiTextureType_SPECULAR, \"texture_specular\"); textures.insert(textures.end(), specularMaps.begin(), specularMaps.end());&#125; 我们首先从场景的mMaterials数组中获取aiMaterial对象.接下来我们希望加载网格的漫反射和/或镜面光贴图.一个材质对象的内部对每种纹理类型都存储了一个纹理位置数组.不同的纹理类型都以aiTextureType_为前缀.我们使用一个叫做loadMaterialTextures的工具函数来从材质中获取纹理.这个函数将会返回一个Texture结构体的vector，我们将在模型的textures vector的尾部之后存储它. loadMaterialTextures函数遍历了给定纹理类型的所有纹理位置，获取了纹理的文件位置，并加载并和生成了纹理，将信息储存在了一个Vertex结构体中。它看起来会像这样： vector&lt;Texture&gt; loadMaterialTextures(aiMaterial *mat, aiTextureType type, string typeName)&#123; vector&lt;Texture&gt; textures; for(unsigned int i = 0; i &lt; mat-&gt;GetTextureCount(type); i++) &#123; aiString str; mat-&gt;GetTexture(type, i, &amp;str); Texture texture; texture.id = TextureFromFile(str.C_Str(), directory); texture.type = typeName; texture.path = str; textures.push_back(texture); &#125; return textures;&#125; 我们首先通过GetTextureCount函数检查储存在材质中纹理的数量，这个函数需要一个纹理类型。我们会使用GetTexture获取每个纹理的文件位置，它会将结果储存在一个aiString中.我们接下来使用另外一个叫做TextureFromFile的工具函数，它将会（用stb_image.h）加载一个纹理并返回该纹理的ID. 注意，我们假设了模型文件中纹理文件的路径是相对于模型文件的本地(Local)路径，比如说与模型文件处于同一目录下.我们可以将纹理位置字符串拼接到之前（在loadModel中）获取的目录字符串上，来获取完整的纹理路径（这也是为什么GetTexture函数也需要一个目录字符串）.在网络上找到的某些模型会对纹理位置使用绝对(Absolute)路径，这就不能在每台机器上都工作了。在这种情况下，你可能会需要手动修改这个文件，来让它对纹理使用本地路径（如果可能的话）. 重大优化大多数场景都会在多个网格中重用部分纹理.还是想想一个房子，它的墙壁有着花岗岩的纹理.这个纹理也可以被应用到地板、天花板、楼梯、桌子，甚至是附近的一口井上.加载纹理并不是一个开销不大的操作，在我们当前的实现中，即便同样的纹理已经被加载过很多遍了，对每个网格仍会加载并生成一个新的纹理.这很快就会变成模型加载实现的性能瓶颈. 所以我们会对模型的代码进行调整，将所有加载过的纹理全局储存，每当我们想加载一个纹理的时候，首先去检查它有没有被加载过.如果有的话，我们会直接使用那个纹理，并跳过整个加载流程，来为我们省下很多处理能力.为了能够比较纹理，我们还需要储存它们的路径： struct Texture &#123; unsigned int id; string type; aiString path; // 我们储存纹理的路径用于与其它纹理进行比较&#125;; 接下来我们将所有加载过的纹理储存在另一个vector中，在模型类的顶部声明为一个私有变量： vector&lt;Texture&gt; textures_loaded; 之后，在loadMaterialTextures函数中，我们希望将纹理的路径与储存在textures_loaded这个vector中的所有纹理进行比较，看看当前纹理的路径是否与其中的一个相同.如果是的话，则跳过纹理加载/生成的部分，直接使用定位到的纹理结构体为网格的纹理.更新后的函数如下： vector&lt;Texture&gt; loadMaterialTextures(aiMaterial *mat, aiTextureType type, string typeName)&#123; vector&lt;Texture&gt; textures; for(unsigned int i = 0; i &lt; mat-&gt;GetTextureCount(type); i++) &#123; aiString str; mat-&gt;GetTexture(type, i, &amp;str); bool skip = false; for(unsigned int j = 0; j &lt; textures_loaded.size(); j++) &#123; if(std::strcmp(textures_loaded[j].path.data(), str.C_Str()) == 0) &#123; textures.push_back(textures_loaded[j]); skip = true; break; &#125; &#125; if(!skip) &#123; // 如果纹理还没有被加载，则加载它 Texture texture; texture.id = TextureFromFile(str.C_Str(), directory); texture.type = typeName; texture.path = str.C_Str(); textures.push_back(texture); textures_loaded.push_back(texture); // 添加到已加载的纹理中 &#125; &#125; return textures;&#125;","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"/tags/OpenGL/"},{"name":"计算机图形学","slug":"计算机图形学","permalink":"/tags/计算机图形学/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"LearnOpenGL-光照","slug":"LearnOpenGL-光照","date":"2019-10-07T15:01:03.000Z","updated":"2019-10-07T15:02:36.295Z","comments":true,"path":"2019/10/07/LearnOpenGL-光照/","link":"","permalink":"/2019/10/07/LearnOpenGL-光照/","excerpt":"","text":"@[toc] 颜色当我们修改顶点或者片段着色器后，灯的位置或颜色也会随之改变，这并不是我们想要的效果.我们不希望灯的颜色在接下来的教程中因光照计算的结果而受到影响，而是希望它能够与其它的计算分离.我们希望灯一直保持明亮，不受其它颜色变化的影响（这样它才更像是一个真实的光源）. 为了实现这个目标，我们需要为灯的绘制创建另外的一套着色器，从而能保证它能够在其它光照着色器发生改变的时候不受影响.顶点着色器与我们当前的顶点着色器是一样的，所以你可以直接把现在的顶点着色器用在灯上.灯的片段着色器给灯定义了一个不变的常量白色，保证了灯的颜色一直是亮的： #version 330 coreout vec4 FragColor;void main()&#123; FragColor = vec4(1.0); // 将向量的四个分量全部设置为1.0&#125; 当我们想要绘制我们的物体的时候，我们需要使用刚刚定义的光照着色器来绘制箱子（或者可能是其它的物体）.当我们想要绘制灯的时候，我们会使用灯的着色器.在之后的教程里我们会逐步更新这个光照着色器，从而能够慢慢地实现更真实的效果. 使用这个灯立方体的主要目的是为了让我们知道光源在场景中的具体位置。我们通常在场景中定义一个光源的位置，但这只是一个位置，它并没有视觉意义.为了显示真正的灯，我们将表示光源的立方体绘制在与光源相同的位置。我们将使用我们为它新建的片段着色器来绘制它，让它一直处于白色的状态，不受场景中的光照影响. 我们声明一个全局vec3变量来表示光源在场景的世界空间坐标中的位置： glm::vec3 lightPos(1.2f, 1.0f, 2.0f); 然后我们把灯位移到这里，然后将它缩小一点，让它不那么明显： model = glm::mat4();model = glm::translate(model, lightPos);model = glm::scale(model, glm::vec3(0.2f)); 绘制灯立方体的代码应该与下面的类似： lampShader.use();// 设置模型、视图和投影矩阵uniform...// 绘制灯立方体对象glBindVertexArray(lightVAO);glDrawArrays(GL_TRIANGLES, 0, 36); 基础光照光的方向向量是光源位置向量与片段位置向量之间的向量差.你可能记得在变换教程中，我们能够简单地通过让两个向量相减的方式计算向量差.我们同样希望确保所有相关向量最后都转换为单位向量，所以我们把法线和最终的方向向量都进行标准化： vec3 norm = normalize(Normal);vec3 lightDir = normalize(lightPos - FragPos); 下一步，我们对norm和lightDir向量进行点乘，计算光源对当前片段实际的漫发射影响.结果值再乘以光的颜色，得到漫反射分量.两个向量之间的角度越大，漫反射分量就会越小： float diff = max(dot(norm, lightDir), 0.0);vec3 diffuse = diff * lightColor; 如果两个向量之间的角度大于90度，点乘的结果就会变成负数，这样会导致漫反射分量变为负数.为此，我们使用max函数返回两个参数之间较大的参数，从而保证漫反射分量不会变成负数.负数颜色的光照是没有定义的，所以最好避免它，除非你是那种古怪的艺术家. 移除法线位移现在我们已经把法向量从顶点着色器传到了片段着色器.可是，目前片段着色器里的计算都是在世界空间坐标中进行的.所以，我们是不是应该把法向量也转换为世界空间坐标？基本正确，但是这不是简单地把它乘以一个模型矩阵就能搞定的. 首先，法向量只是一个方向向量，不能表达空间中的特定位置.同时，法向量没有齐次坐标（顶点位置中的w分量）.这意味着，位移不应该影响到法向量.因此，如果我们打算把法向量乘以一个模型矩阵，我们就要从矩阵中移除位移部分，只选用模型矩阵左上角3×3的矩阵（注意，我们也可以把法向量的w分量设置为0，再乘以4×4矩阵；这同样可以移除位移）.对于法向量，我们只希望对它实施缩放和旋转变换. 其次，如果模型矩阵执行了不等比缩放，顶点的改变会导致法向量不再垂直于表面了.因此，我们不能用这样的模型矩阵来变换法向量.下面的图展示了应用了不等比缩放的模型矩阵对法向量的影响：修复这个行为的诀窍是使用一个为法向量专门定制的模型矩阵.这个矩阵称之为法线矩阵(Normal Matrix)，它使用了一些线性代数的操作来移除对法向量错误缩放的影响. 法线矩阵被定义为「模型矩阵左上角的逆矩阵的转置矩阵」.真是拗口，如果你不明白这是什么意思，别担心，我们还没有讨论逆矩阵(Inverse Matrix)和转置矩阵(Transpose Matrix).注意，大部分的资源都会将法线矩阵定义为应用到模型-观察矩阵(Model-view Matrix)上的操作，但是由于我们只在世界空间中进行操作（不是在观察空间），我们只使用模型矩阵. 在顶点着色器中，我们可以使用inverse和transpose函数自己生成这个法线矩阵，这两个函数对所有类型矩阵都有效.注意我们还要把被处理过的矩阵强制转换为3×3矩阵，来保证它失去了位移属性以及能够乘以vec3的法向量. Normal = mat3(transpose(inverse(model))) * aNormal; 在漫反射光照部分，光照表现并没有问题，这是因为我们没有对物体本身执行任何缩放操作，所以并不是必须要使用一个法线矩阵，仅仅让模型矩阵乘以法线也可以.可是，如果你进行了不等比缩放，使用法线矩阵去乘以法向量就是必不可少的了. 即使是对于着色器来说，逆矩阵也是一个开销比较大的运算，因此，只要可能就应该避免在着色器中进行逆矩阵运算，它们必须为你场景中的每个顶点都进行这样的处理.用作学习目这样做是可以的，但是对于一个对效率有要求的应用来说，在绘制之前你最好用CPU计算出法线矩阵，然后通过uniform把值传递给着色器（像模型矩阵一样）. 镜面分量现在我们已经获得所有需要的变量，可以计算高光强度了.首先，我们定义一个镜面强度(Specular Intensity)变量，给镜面高光一个中等亮度颜色，让它不要产生过度的影响. float specularStrength = 0.5; 下一步，我们计算视线方向向量，和对应的沿着法线轴的反射向量： vec3 viewDir = normalize(viewPos - FragPos);vec3 reflectDir = reflect(-lightDir, norm); 需要注意的是我们对lightDir向量进行了取反.reflect函数要求第一个向量是从光源指向片段位置的向量，但是lightDir当前正好相反，是从片段指向光源（由先前我们计算lightDir向量时，减法的顺序决定）.为了保证我们得到正确的reflect向量，我们通过对lightDir向量取反来获得相反的方向.第二个参数要求是一个法向量，所以我们提供的是已标准化的norm向量. float spec = pow(max(dot(viewDir, reflectDir), 0.0), 32);vec3 specular = specularStrength * spec * lightColor; 我们先计算视线方向与反射方向的点乘（并确保它不是负值），然后取它的32次幂。这个32是高光的反光度(Shininess).一个物体的反光度越高，反射光的能力越强，散射得越少，高光点就会越小.在下面的图片里，你会看到不同反光度的视觉效果影响：剩下的最后一件事情是把它加到环境光分量和漫反射分量里，再用结果乘以物体的颜色：vec3 result = (ambient + diffuse + specular) * objectColor;FragColor = vec4(result, 1.0); 材质当描述一个物体的时候，我们可以用这三个分量来定义一个材质颜色(Material Color)：环境光照(Ambient Lighting)、漫反射光照(Diffuse Lighting)和镜面光照(Specular Lighting).通过为每个分量指定一个颜色，我们就能够对物体的颜色输出有着精细的控制了.现在，我们再添加反光度(Shininess)这个分量到上述的三个颜色中，这就有我们需要的所有材质属性了： #version 330 corestruct Material &#123; vec3 ambient; vec3 diffuse; vec3 specular; float shininess;&#125;; uniform Material material; ambient材质向量定义了在环境光照下这个物体反射得是什么颜色，通常这是和物体颜色相同的颜色.diffuse材质向量定义了在漫反射光照下物体的颜色.（和环境光照一样）漫反射颜色也要设置为我们需要的物体颜色.specular材质向量设置的是镜面光照对物体的颜色影响（或者甚至可能反射一个物体特定的镜面高光颜色）.最后，shininess影响镜面高光的散射/半径. 这四个元素定义了一个物体的材质，通过它们我们能够模拟很多现实世界中的材质.devernay.free.fr上的一个表格展示了几种材质属性，它们模拟了现实世界中的真实材质.下面的图片展示了几种现实世界的材质对我们的立方体的影响： 设置材质void main()&#123; // 环境光 vec3 ambient = lightColor * material.ambient; // 漫反射 vec3 norm = normalize(Normal); vec3 lightDir = normalize(lightPos - FragPos); float diff = max(dot(norm, lightDir), 0.0); vec3 diffuse = lightColor * (diff * material.diffuse); // 镜面光 vec3 viewDir = normalize(viewPos - FragPos); vec3 reflectDir = reflect(-lightDir, norm); float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); vec3 specular = lightColor * (spec * material.specular); vec3 result = ambient + diffuse + specular; FragColor = vec4(result, 1.0);&#125; 我们现在可以在程序中设置适当的uniform，对物体设置材质了.GLSL中的结构体在设置uniform时并没有什么特别之处.结构体只是作为uniform变量的一个封装，所以如果想填充这个结构体的话，我们仍需要对每个单独的uniform进行设置，但这次要带上结构体名的前缀： lightingShader.setVec3(\"material.ambient\", 1.0f, 0.5f, 0.31f);lightingShader.setVec3(\"material.diffuse\", 1.0f, 0.5f, 0.31f);lightingShader.setVec3(\"material.specular\", 0.5f, 0.5f, 0.5f);lightingShader.setFloat(\"material.shininess\", 32.0f); 光的属性物体过亮的原因是环境光、漫反射和镜面光这三个颜色对任何一个光源都会去全力反射.光源对环境光、漫反射和镜面光分量也具有着不同的强度。前面的教程，我们通过使用一个强度值改变环境光和镜面光强度的方式解决了这个问题.我们想做一个类似的系统，但是这次是要为每个光照分量都指定一个强度向量. vec3 ambient = vec3(0.1) * material.ambient; 一个光源对它的ambient、diffuse和specular光照有着不同的强度.环境光照通常会设置为一个比较低的强度，因为我们不希望环境光颜色太过显眼.光源的漫反射分量通常设置为光所具有的颜色，通常是一个比较明亮的白色.镜面光分量通常会保持为vec3(1.0)，以最大强度发光. lightingShader.setVec3(\"light.ambient\", 0.2f, 0.2f, 0.2f);lightingShader.setVec3(\"light.diffuse\", 0.5f, 0.5f, 0.5f); // 将光照调暗了一些以搭配场景lightingShader.setVec3(\"light.specular\", 1.0f, 1.0f, 1.0f 不同的光源颜色我们可以利用sin和glfwGetTime函数改变光源的环境光和漫反射颜色，从而很容易地让光源的颜色随着时间变化： glm::vec3 lightColor;lightColor.x = sin(glfwGetTime() * 2.0f);lightColor.y = sin(glfwGetTime() * 0.7f);lightColor.z = sin(glfwGetTime() * 1.3f);glm::vec3 diffuseColor = lightColor * glm::vec3(0.5f); // 降低影响glm::vec3 ambientColor = diffuseColor * glm::vec3(0.2f); // 很低的影响lightingShader.setVec3(\"light.ambient\", ambientColor);lightingShader.setVec3(\"light.diffuse\", diffuseColor); 光照贴图在上一节中，我们将整个物体的材质定义为一个整体，但现实世界中的物体通常并不只包含有一种材质，而是由多种材质所组成.想想一辆汽车：它的外壳非常有光泽，车窗会部分反射周围的环境，轮胎不会那么有光泽，所以它没有镜面高光，轮毂非常闪亮（如果你洗车了的话）.汽车同样会有漫反射和环境光颜色，它们在整个物体上也不会是一样的，汽车有着许多种不同的环境光/漫反射颜色.总之，这样的物体在不同的部件上都有不同的材质属性. 所以，上一节中的那个材质系统是肯定不够的，它只是一个最简单的模型，所以我们需要拓展之前的系统，引入漫反射和镜面光贴图(Map).这允许我们对物体的漫反射分量（以及间接地对环境光分量，它们几乎总是一样的）和镜面光分量有着更精确的控制. 漫反射贴图 注意sampler2D是所谓的不透明类型(Opaque Type)，也就是说我们不能将它实例化，只能通过uniform来定义它.如果我们使用除uniform以外的方法（比如函数的参数）实例化这个结构体，GLSL会抛出一些奇怪的错误.这同样也适用于任何封装了不透明类型的结构体. 我们也移除了环境光材质颜色向量，因为环境光颜色在几乎所有情况下都等于漫反射颜色，所以我们不需要将它们分开储存： struct Material &#123; sampler2D diffuse; vec3 specular; float shininess;&#125;; ...in vec2 TexCoords; 镜面光贴图你可能会注意到，镜面高光看起来有些奇怪，因为我们的物体大部分都是木头，我们知道木头不应该有这么强的镜面高光的。我们可以将物体的镜面光材质设置为vec3(0.0)来解决这个问题，但这也意味着箱子钢制的边框将不再能够显示镜面高光了，我们知道钢铁应该是有一些镜面高光的.所以，我们想要让物体的某些部分以不同的强度显示镜面高光.这个问题看起来和漫反射贴图非常相似. 我们同样可以使用一个专门用于镜面高光的纹理贴图.这也就意味着我们需要生成一个黑白的（如果你想得话也可以是彩色的）纹理，来定义物体每部分的镜面光强度。下面是一个镜面光贴图(Specular Map)的例子：镜面高光的强度可以通过图像每个像素的亮度来获取.镜面光贴图上的每个像素都可以由一个颜色向量来表示，比如说黑色代表颜色向量vec3(0.0)，灰色代表颜色向量vec3(0.5).在片段着色器中，我们接下来会取样对应的颜色值并将它乘以光源的镜面强度.一个像素越「白」，乘积就会越大，物体的镜面光分量就会越亮. 由于箱子大部分都由木头所组成，而且木头材质应该没有镜面高光，所以漫反射纹理的整个木头部分全部都转换成了黑色.箱子钢制边框的镜面光强度是有细微变化的，钢铁本身会比较容易受到镜面高光的影响，而裂缝则不会. 采样镜面光贴图由于我们正在同一个片段着色器中使用另一个纹理采样器，我们必须要对镜面光贴图使用一个不同的纹理单元（GL_TEXTURE1），所以我们在渲染之前先把它绑定到合适的纹理单元上：lightingShader.setInt(\"material.specular\", 1);...glActiveTexture(GL_TEXTURE1);glBindTexture(GL_TEXTURE_2D, specularMap); 接下来更新片段着色器的材质属性，让其接受一个sampler2D而不是vec3作为镜面光分量： struct Material &#123; sampler2D diffuse; sampler2D specular; float shininess;&#125;; 最后我们希望采样镜面光贴图，来获取片段所对应的镜面光强度： vec3 ambient = light.ambient * vec3(texture(material.diffuse, TexCoords));vec3 diffuse = light.diffuse * diff * vec3(texture(material.diffuse, TexCoords)); vec3 specular = light.specular * spec * vec3(texture(material.specular, TexCoords));FragColor = vec4(ambient + diffuse + specular, 1.0); 通过使用镜面光贴图我们可以可以对物体设置大量的细节，比如物体的哪些部分需要有闪闪发光的属性，我们甚至可以设置它们对应的强度.镜面光贴图能够在漫反射贴图之上给予我们更高一层的控制. 投光物平行光当我们使用一个假设光源处于无限远处的模型时，它就被称为定向光，因为它的所有光线都有着相同的方向，它与光源的位置是没有关系的. 我们可以定义一个光线方向向量而不是位置向量来模拟一个定向光.着色器的计算基本保持不变，但这次我们将直接使用光的direction向量而不是通过direction来计算lightDir向量. struct Light &#123; // vec3 position; // 使用定向光就不再需要了 vec3 direction; vec3 ambient; vec3 diffuse; vec3 specular;&#125;;...void main()&#123; vec3 lightDir = normalize(-light.direction); ...&#125; 注意我们首先对light.direction向量取反.我们目前使用的光照计算需求一个从片段至光源的光线方向，但人们更习惯定义定向光为一个从光源出发的全局方向。所以我们需要对全局光照方向向量取反来改变它的方向，它现在是一个指向光源的方向向量了.而且，记得对向量进行标准化，假设输入向量为一个单位向量是很不明智的. for(unsigned int i = 0; i &lt; 10; i++)&#123; glm::mat4 model; model = glm::translate(model, cubePositions[i]); float angle = 20.0f * i; model = glm::rotate(model, glm::radians(angle), glm::vec3(1.0f, 0.3f, 0.5f)); lightingShader.setMat4(\"model\", model); glDrawArrays(GL_TRIANGLES, 0, 36);&#125; 同时，不要忘记定义光源的方向（注意我们将方向定义为从光源出发的方向，你可以很容易看到光的方向朝下）. lightingShader.setVec3(\"light.direction\", -0.2f, -1.0f, -0.3f); 我们一直将光的位置和位置向量定义为vec3，但一些人会喜欢将所有的向量都定义为vec4.当我们将位置向量定义为一个vec4时，很重要的一点是要将w分量设置为1.0，这样变换和投影才能正确应用。然而，当我们定义一个方向向量为vec4的时候，我们不想让位移有任何的效果（因为它仅仅代表的是方向），所以我们将w分量设置为0.0.方向向量就会像这样来表示：vec4(0.2f, 1.0f, 0.3f, 0.0f)。这也可以作为一个快速检测光照类型的工具：你可以检测w分量是否等于1.0，来检测它是否是光的位置向量；w分量等于0.0，则它是光的方向向量，这样就能根据这个来调整光照计算了：if(lightVector.w == 0.0) // 注意浮点数据类型的误差 // 执行定向光照计算else if(lightVector.w == 1.0) // 根据光源的位置做光照计算（与上一节一样） 点光源定向光对于照亮整个场景的全局光源是非常棒的，但除了定向光之外我们也需要一些分散在场景中的点光源(Point Light).点光源是处于世界中某一个位置的光源，它会朝着所有方向发光，但光线会随着距离逐渐衰减.想象作为投光物的灯泡和火把，它们都是点光源. 然而，我们定义的光源模拟的是永远不会衰减的光线，这看起来像是光源亮度非常的强.在大部分的3D模拟中，我们都希望模拟的光源仅照亮光源附近的区域而不是整个场景。 如果你将10个箱子加入到上一节光照场景中，你会注意到在最后面的箱子和在灯面前的箱子都以相同的强度被照亮，并没有定义一个公式来将光随距离衰减.我们希望在后排的箱子与前排的箱子相比仅仅是被轻微地照亮. 衰减下面这个公式根据片段距光源的距离计算了衰减值，之后我们会将它乘以光的强度向量：在这里d代表了片段距光源的距离。接下来为了计算衰减值，我们定义3个（可配置的）项：常数项Kc、一次项Kl和二次项Kq. 常数项通常保持为1.0，它的主要作用是保证分母永远不会比1小，否则的话在某些距离上它反而会增加强度，这肯定不是我们想要的效果. 一次项会与距离值相乘，以线性的方式减少强度. 二次项会与距离的平方相乘，让光源以二次递减的方式减少强度.二次项在距离比较小的时候影响会比一次项小很多，但当距离值比较大的时候它就会比一次项更大了. 由于二次项的存在，光线会在大部分时候以线性的方式衰退，直到距离变得足够大，让二次项超过一次项，光的强度会以更快的速度下降。这样的结果就是，光在近距离时亮度很高，但随着距离变远亮度迅速降低，最后会以更慢的速度减少亮度.下面这张图显示了在100的距离内衰减的效果： 选择正确的值正确地设定它们的值取决于很多因素：环境、希望光覆盖的距离、光的类型等.在大多数情况下，这都是经验的问题，以及适量的调整.下面这个表格显示了模拟一个（大概）真实的，覆盖特定半径（距离）的光源时，这些项可能取的一些值.第一列指定的是在给定的三项时光所能覆盖的距离.这些值是大多数光源很好的起始点，它们由Ogre3D的Wiki所提供：常数项Kc在所有的情况下都是1.0.一次项Kl为了覆盖更远的距离通常都很小，二次项Kq甚至更小.尝试对这些值进行实验，看看它们在你的实现中有什么效果.在我们的环境中，32到100的距离对大多数的光源都足够了. 实现衰减为了实现衰减，在片段着色器中我们还需要三个额外的值：也就是公式中的常数项、一次项和二次项.它们最好储存在之前定义的Light结构体中.注意我们使用上一节中计算lightDir的方法，而不是上面定向光部分的. struct Light &#123; vec3 position; vec3 ambient; vec3 diffuse; vec3 specular; float constant; float linear; float quadratic;&#125;; 然后我们将在OpenGL中设置这些项：我们希望光源能够覆盖50的距离，所以我们会使用表格中对应的常数项、一次项和二次项： lightingShader.setFloat(\"light.constant\", 1.0f);lightingShader.setFloat(\"light.linear\", 0.09f);lightingShader.setFloat(\"light.quadratic\", 0.032f); 在片段着色器中实现衰减还是比较直接的：我们根据公式计算衰减值，之后再分别乘以环境光、漫反射和镜面光分量. 我们仍需要公式中距光源的距离，还记得我们是怎么计算一个向量的长度的吗？我们可以通过获取片段和光源之间的向量差，并获取结果向量的长度作为距离项.我们可以使用GLSL内建的length函数来完成这一点： float distance = length(light.position - FragPos);float attenuation = 1.0 / (light.constant + light.linear * distance + light.quadratic * (distance * distance));ambient *= attenuation; diffuse *= attenuation;specular *= attenuation; 可以看到，只有前排的箱子被照亮的，距离最近的箱子是最亮的.后排的箱子一点都没有照亮，因为它们离光源实在是太远了. 聚光聚光(Spotlight)是位于环境中某个位置的光源，它只朝一个特定方向而不是所有方向照射光线.这样的结果就是只有在聚光方向的特定半径内的物体才会被照亮，其它的物体都会保持黑暗。聚光很好的例子就是路灯或手电筒. OpenGL中聚光是用一个世界空间位置、一个方向和一个切光角(Cutoff Angle)来表示的，切光角指定了聚光的半径（译注：是圆锥的半径不是距光源距离那个半径）.对于每个片段，我们会计算片段是否位于聚光的切光方向之间（也就是在锥形内），如果是的话，我们就会相应地照亮片段。下面这张图会让你明白聚光是如何工作的： LightDir：从片段指向光源的向量. SpotDir：聚光所指向的方向. Phiϕ：指定了聚光半径的切光角.落在这个角度之外的物体都不会被这个聚光所照亮. Thetaθ：LightDir向量和SpotDir向量之间的夹角.在聚光内部的话θ值应该比ϕ值小. 所以我们要做的就是计算LightDir向量和SpotDir向量之间的点积（还记得它会返回两个单位向量夹角的余弦值吗？），并将它与切光角ϕ值对比.你现在应该了解聚光究竟是什么了，下面我们将以手电筒的形式创建一个聚光. 手电筒手电筒(Flashlight)是一个位于观察者位置的聚光，通常它都会瞄准玩家视角的正前方.基本上说，手电筒就是普通的聚光，但它的位置和方向会随着玩家的位置和朝向不断更新. 所以，在片段着色器中我们需要的值有聚光的位置向量（来计算光的方向向量）、聚光的方向向量和一个切光角.我们可以将它们储存在Light结构体中：struct Light &#123; vec3 position; vec3 direction; float cutOff; ...&#125;; 接下来我们将合适的值传到着色器中： lightingShader.setVec3(\"light.position\", camera.Position);lightingShader.setVec3(\"light.direction\", camera.Front);lightingShader.setFloat(\"light.cutOff\", glm::cos(glm::radians(12.5f))); 你可以看到，我们并没有给切光角设置一个角度值，反而是用角度值计算了一个余弦值，将余弦结果传递到片段着色器中.这样做的原因是在片段着色器中，我们会计算LightDir和SpotDir向量的点积，这个点积返回的将是一个余弦值而不是角度值，所以我们不能直接使用角度值和余弦值进行比较.为了获取角度值我们需要计算点积结果的反余弦，这是一个开销很大的计算.所以为了节约一点性能开销，我们将会计算切光角对应的余弦值，并将它的结果传入片段着色器中.由于这两个角度现在都由余弦角来表示了，我们可以直接对它们进行比较而不用进行任何开销高昂的计算. 接下来就是计算θ值，并将它和切光角ϕ对比，来决定是否在聚光的内部： float theta = dot(lightDir, normalize(-light.direction));if(theta &gt; light.cutOff) &#123; // 执行光照计算&#125;else // 否则，使用环境光，让场景在聚光之外时不至于完全黑暗 color = vec4(light.ambient * vec3(texture(material.diffuse, TexCoords)), 1.0); 我们首先计算了lightDir和取反的direction向量（取反的是因为我们想让向量指向光源而不是从光源出发）之间的点积.记住要对所有的相关向量标准化. 这仍看起来有些假，主要是因为聚光有一圈硬边.当一个片段遇到聚光圆锥的边缘时，它会完全变暗，没有一点平滑的过渡.一个真实的聚光将会在边缘处逐渐减少亮度. 平滑/软化边缘为了创建一种看起来边缘平滑的聚光，我们需要模拟聚光有一个内圆锥(Inner Cone)和一个外圆锥(Outer Cone).我们可以将内圆锥设置为上一部分中的那个圆锥，但我们也需要一个外圆锥，来让光从内圆锥逐渐减暗，直到外圆锥的边界. 为了创建一个外圆锥，我们只需要再定义一个余弦值来代表聚光方向向量和外圆锥向量（等于它的半径）的夹角.然后，如果一个片段处于内外圆锥之间，将会给它计算出一个0.0到1.0之间的强度值.如果片段在内圆锥之内，它的强度就是1.0，如果在外圆锥之外强度值就是0.0. 我们可以用下面这个公式来计算这个值：这里ϵ(Epsilon)是内（ϕ）和外圆锥（γ）之间的余弦值差（ϵ=ϕ−γ）.最终的I值就是在当前片段聚光的强度. 很难去表现这个公式是怎么工作的，所以我们用一些实例值来看看：你可以看到，我们基本是在内外余弦值之间根据θ插值.如果你仍不明白发生了什么，不必担心，只需要记住这个公式就好了，在你更聪明的时候再回来看看。 我们现在有了一个在聚光外是负的，在内圆锥内大于1.0的，在边缘处于两者之间的强度值了.如果我们正确地约束(Clamp)这个值，在片段着色器中就不再需要if-else了，我们能够使用计算出来的强度值直接乘以光照分量： float theta = dot(lightDir, normalize(-light.direction));float epsilon = light.cutOff - light.outerCutOff;float intensity = clamp((theta - light.outerCutOff) / epsilon, 0.0, 1.0); ...// 将不对环境光做出影响，让它总是能有一点光diffuse *= intensity;specular *= intensity;... 注意我们使用了clamp函数，它把第一个参数约束(Clamp)在了0.0到1.0之间.这保证强度值不会在[0, 1]区间之外. 多光源为了在场景中使用多个光源，我们希望将光照计算封装到GLSL函数中.这样做的原因是，每一种光源都需要一种不同的计算方法，而一旦我们想对多个光源进行光照计算时，代码很快就会变得非常复杂.如果我们只在main函数中进行所有的这些计算，代码很快就会变得难以理解. 当我们在场景中使用多个光源时，通常使用以下方法：我们需要有一个单独的颜色向量代表片段的输出颜色.对于每一个光源，它对片段的贡献颜色将会加到片段的输出颜色向量上.所以场景中的每个光源都会计算它们各自对片段的影响，并结合为一个最终的输出颜色.大体的结构会像是这样： out vec4 FragColor;void main()&#123; // 定义一个输出颜色值 vec3 output; // 将定向光的贡献加到输出中 output += someFunctionToCalculateDirectionalLight(); // 对所有的点光源也做相同的事情 for(int i = 0; i &lt; nr_of_point_lights; i++) output += someFunctionToCalculatePointLight(); // 也加上其它的光源（比如聚光） output += someFunctionToCalculateSpotLight(); FragColor = vec4(output, 1.0);&#125; 实际的代码对每一种实现都可能不同，但大体的结构都是差不多的.我们定义了几个函数，用来计算每个光源的影响，并将最终的结果颜色加到输出颜色向量上.例如，如果两个光源都很靠近一个片段，那么它们所结合的贡献将会形成一个比单个光源照亮时更加明亮的片段. 定向光我们需要在片段着色器中定义一个函数来计算定向光对相应片段的贡献：它接受一些参数并计算一个定向光照颜色. 首先，我们需要定义一个定向光源最少所需要的变量.我们可以将这些变量储存在一个叫做DirLight的结构体中，并将它定义为一个uniform.需要的变量在上一节中都介绍过： struct DirLight &#123; vec3 direction; vec3 ambient; vec3 diffuse; vec3 specular;&#125;; uniform DirLight dirLight; 接下来我们可以将dirLight传入一个有着一下原型的函数: vec3 CalcDirLight(DirLight light, vec3 normal, vec3 viewDir); 你可以看到，这个函数需要一个DirLight结构体和其它两个向量来进行计算.vec3 CalcDirLight(DirLight light, vec3 normal, vec3 viewDir)&#123; vec3 lightDir = normalize(-light.direction); // 漫反射着色 float diff = max(dot(normal, lightDir), 0.0); // 镜面光着色 vec3 reflectDir = reflect(-lightDir, normal); float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); // 合并结果 vec3 ambient = light.ambient * vec3(texture(material.diffuse, TexCoords)); vec3 diffuse = light.diffuse * diff * vec3(texture(material.diffuse, TexCoords)); vec3 specular = light.specular * spec * vec3(texture(material.specular, TexCoords)); return (ambient + diffuse + specular);&#125; 点光源和定向光一样，我们也希望定义一个用于计算点光源对相应片段贡献，以及衰减的函数.同样，我们定义一个包含了点光源所需所有变量的结构体：struct PointLight &#123; vec3 position; float constant; float linear; float quadratic; vec3 ambient; vec3 diffuse; vec3 specular;&#125;; #define NR_POINT_LIGHTS 4uniform PointLight pointLights[NR_POINT_LIGHTS]; 点光源函数的原型如下： vec3 CalcPointLight(PointLight light, vec3 normal, vec3 fragPos, vec3 viewDir); 这个函数从参数中获取所需的所有数据，并返回一个代表该点光源对片段的颜色贡献的vec3. vec3 CalcPointLight(PointLight light, vec3 normal, vec3 fragPos, vec3 viewDir)&#123; vec3 lightDir = normalize(light.position - fragPos); // 漫反射着色 float diff = max(dot(normal, lightDir), 0.0); // 镜面光着色 vec3 reflectDir = reflect(-lightDir, normal); float spec = pow(max(dot(viewDir, reflectDir), 0.0), material.shininess); // 衰减 float distance = length(light.position - fragPos); float attenuation = 1.0 / (light.constant + light.linear * distance + light.quadratic * (distance * distance)); // 合并结果 vec3 ambient = light.ambient * vec3(texture(material.diffuse, TexCoords)); vec3 diffuse = light.diffuse * diff * vec3(texture(material.diffuse, TexCoords)); vec3 specular = light.specular * spec * vec3(texture(material.specular, TexCoords)); ambient *= attenuation; diffuse *= attenuation; specular *= attenuation; return (ambient + diffuse + specular);&#125; 在main函数中，我们只需要创建一个循环，遍历整个点光源数组，对每个点光源调用CalcPointLight就可以了. 合并结果void main()&#123; // 属性 vec3 norm = normalize(Normal); vec3 viewDir = normalize(viewPos - FragPos); // 第一阶段：定向光照 vec3 result = CalcDirLight(dirLight, norm, viewDir); // 第二阶段：点光源 for(int i = 0; i &lt; NR_POINT_LIGHTS; i++) result += CalcPointLight(pointLights[i], norm, FragPos, viewDir); // 第三阶段：聚光 //result += CalcSpotLight(spotLight, norm, FragPos, viewDir); FragColor = vec4(result, 1.0);&#125; 设置一个结构体数组的uniform和设置一个结构体的uniform是很相似的，但是这一次在访问uniform位置的时候，我们需要定义对应的数组下标值： lightingShader.setFloat(\"pointLights[0].constant\", 1.0f); 我们会定义另一个glm::vec3数组来包含点光源的位置：glm::vec3 pointLightPositions[] = &#123; glm::vec3( 0.7f, 0.2f, 2.0f), glm::vec3( 2.3f, -3.3f, -4.0f), glm::vec3(-4.0f, 2.0f, -12.0f), glm::vec3( 0.0f, 0.0f, -3.0f)&#125;; 接下来我们从pointLights数组中索引对应的PointLight，将它的position值设置为刚刚定义的位置值数组中的其中一个.同时我们还要保证现在绘制的是四个灯立方体而不是仅仅一个.只要对每个灯物体创建一个不同的模型矩阵就可以了，和我们之前对箱子的处理类似. 如果你还使用了手电筒的话，所有光源组合的效果将看起来和下图差不多：","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"/tags/OpenGL/"},{"name":"计算机图形学","slug":"计算机图形学","permalink":"/tags/计算机图形学/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"LearnOpenGL-入门","slug":"LearnOpenGL-入门","date":"2019-10-07T15:00:03.000Z","updated":"2019-10-07T15:00:06.867Z","comments":true,"path":"2019/10/07/LearnOpenGL-入门/","link":"","permalink":"/2019/10/07/LearnOpenGL-入门/","excerpt":"","text":"@[toc] OpenGL当我们使用一个对象时，通常看起来像如下一样（把OpenGL上下文看作一个大的结构体）： // OpenGL的状态struct OpenGL_Context &#123; ... object* object_Window_Target; ... &#125;; 这一小段代码展现了你以后使用OpenGL时常见的工作流。我们首先创建一个对象，然后用一个id保存它的引用（实际数据被储存在后台）。然后我们将对象绑定至上下文的目标位置（例子中窗口对象目标的位置被定义成GL_WINDOW_TARGET）。接下来我们设置窗口的选项。最后我们将目标位置的对象id设回0，解绑这个对象。设置的选项将被保存在objectId所引用的对象中，一旦我们重新绑定这个对象到GL_WINDOW_TARGET位置，这些选项就会重新生效。// 创建对象unsigned int objectId = 0;glGenObject(1, &amp;objectId);// 绑定对象至上下文glBindObject(GL_WINDOW_TARGET, objectId);// 设置当前绑定到 GL_WINDOW_TARGET 的对象的一些选项glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_WIDTH, 800);glSetObjectOption(GL_WINDOW_TARGET, GL_OPTION_WINDOW_HEIGHT, 600);// 将上下文对象设回默认glBindObject(GL_WINDOW_TARGET, 0); 创建窗口对于用GCC编译的Linux用户建议使用这个命令行选项-lGLEW -lglfw3 -lGL -lX11 -lpthread -lXrandr -lXi.没有正确链接相应的库会产生 undefined reference (未定义的引用) 这个错误。 你好,窗口配置注:glad.c需要放在项目文件夹下#include &lt;glad/glad.h&gt;#include &lt;GLFW/glfw3.h&gt;int main()&#123; glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); return 0;&#125; //CMakeLists.txtcmake_minimum_required(VERSION 3.14)project(hellow,windows)set(CMAKE_CXX_STANDARD 14)set(SOURCE_FILES main.cpp glad.c)add_executable(main $&#123;SOURCE_FILES&#125;)target_link_libraries(main glfw3 GL m Xrandr Xi X11 Xxf86vm pthread dl Xinerama Xcursor) 首先，我们在main函数中调用glfwInit函数来初始化GLFW，然后我们可以使用glfwWindowHint函数来配置GLFW。glfwWindowHint函数的第一个参数代表选项的名称，我们可以从很多以GLFW_开头的枚举值中选择；第二个参数接受一个整型，用来设置这个选项的值。该函数的所有的选项以及对应的值都可以在 GLFW’s window handling 这篇文档中找到。如果你现在编译你的cpp文件会得到大量的 undefined reference (未定义的引用)错误，也就是说你并未顺利地链接GLFW库. GLADGLAD是用来管理OpenGL的函数指针的，所以在调用任何OpenGL的函数之前我们需要初始化GLAD. if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress))&#123; std::cout &lt;&lt; \"Failed to initialize GLAD\" &lt;&lt; std::endl; return -1;&#125; 我们给GLAD传入了用来加载系统相关的OpenGL函数指针地址的函数。GLFW给我们的是glfwGetProcAddress，它根据我们编译的系统定义了正确的函数. 视口在我们开始渲染之前还有一件重要的事情要做，我们必须告诉OpenGL渲染窗口的尺寸大小，即视口(Viewport)，这样OpenGL才只能知道怎样根据窗口大小显示数据和坐标。我们可以通过调用glViewport函数来设置窗口的维度(Dimension)： glViewport(0, 0, 800, 600); glViewport函数前两个参数控制窗口左下角的位置。第三个和第四个参数控制渲染窗口的宽度和高度（像素）。我们实际上也可以将视口的维度设置为比GLFW的维度小，这样子之后所有的OpenGL渲染将会在一个更小的窗口中显示，这样子的话我们也可以将一些其它元素显示在OpenGL视口之外. OpenGL幕后使用glViewport中定义的位置和宽高进行2D坐标的转换，将OpenGL中的位置坐标转换为你的屏幕坐标。例如，OpenGL中的坐标(-0.5, 0.5)有可能（最终）被映射为屏幕中的坐标(200,450)。注意，处理过的OpenGL坐标范围只为-1到1，因此我们事实上将(-1到1)范围内的坐标映射到(0, 800)和(0, 600). 然而，当用户改变窗口的大小的时候，视口也应该被调整。我们可以对窗口注册一个回调函数(Callback Function)，它会在每次窗口大小被调整的时候被调用。这个回调函数的原型如下： void framebuffer_size_callback(GLFWwindow* window, int width, int height); 这个帧缓冲大小函数需要一个GLFWwindow作为它的第一个参数，以及两个整数表示窗口的新维度。每当窗口改变大小，GLFW会调用这个函数并填充相应的参数供你处理. void framebuffer_size_callback(GLFWwindow* window, int width, int height)&#123; glViewport(0, 0, width, height);&#125; 我们还需要注册这个函数，告诉GLFW我们希望每当窗口调整大小的时候调用这个函数： glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); 当窗口被第一次显示的时候framebuffer_size_callback也会被调用。对于视网膜(Retina)显示屏，width和height都会明显比原输入值更高一点。 我们还可以将我们的函数注册到其它很多的回调函数中。比如说，我们可以创建一个回调函数来处理手柄输入变化，处理错误消息等。我们会在创建窗口之后，渲染循环初始化之前注册这些回调函数。 准备好你的引擎我们可不希望只绘制一个图像之后我们的应用程序就立即退出并关闭窗口。我们希望程序在我们主动关闭它之前不断绘制图像并能够接受用户输入。因此，我们需要在程序中添加一个while循环，我们可以把它称之为渲染循环(Render Loop)，它能在我们让GLFW退出前一直保持运行。下面几行的代码就实现了一个简单的渲染循环： while(!glfwWindowShouldClose(window))&#123; glfwSwapBuffers(window); glfwPollEvents(); &#125; glfwWindowShouldClose函数在我们每次循环的开始前检查一次GLFW是否被要求退出，如果是的话该函数返回true然后渲染循环便结束了，之后为我们就可以关闭应用程序了. glfwPollEvents函数检查有没有触发什么事件（比如键盘输入、鼠标移动等）、更新窗口状态，并调用对应的回调函数(可以通过回调方法手动设置). glfwSwapBuffers函数会交换颜色缓冲（它是一个储存着GLFW窗口每一个像素颜色值的大缓冲），它在这一迭代中被用来绘制，并且将会作为输出显示在屏幕上. 双缓冲(Double Buffer)应用程序使用单缓冲绘图时可能会存在图像闪烁的问题。 这是因为生成的图像不是一下子被绘制出来的，而是按照从左到右，由上而下逐像素地绘制而成的。最终图像不是在瞬间显示给用户，而是通过一步一步生成的，这会导致渲染的结果很不真实。为了规避这些问题，我们应用双缓冲渲染窗口应用程序。前缓冲保存着最终输出的图像，它会在屏幕上显示；而所有的的渲染指令都会在后缓冲上绘制。当所有的渲染指令执行完毕后，我们交换(Swap)前缓冲和后缓冲，这样图像就立即呈显出来，之前提到的不真实感就消除了. 最后一件事当渲染循环结束后我们需要正确释放/删除之前的分配的所有资源。我们可以在main函数的最后调用glfwTerminate函数来完成: glfwTerminate();return 0; 这样便能清理所有的资源并正确地退出应用程序。现在你可以尝试编译并运行你的应用程序了，如果没做错的话，你将会看到如下的输出： 输入我们同样也希望能够在GLFW中实现一些输入控制，这可以通过使用GLFW的几个输入函数来完成。我们将会使用GLFW的glfwGetKey函数，它需要一个窗口以及一个按键作为输入。这个函数将会返回这个按键是否正在被按下。我们将创建一个processInput函数来让所有的输入代码保持整洁. void processInput(GLFWwindow *window)&#123; if(glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true);&#125; 这里我们检查用户是否按下了返回键(Esc)（如果没有按下，glfwGetKey将会返回GLFW_RELEASE.如果用户的确按下了返回键，我们将通过glfwSetwindowShouldClose使用把WindowShouldClose属性设置为 true的方法关闭GLFW.下一次while循环的条件检测将会失败，程序将会关闭.我们接下来在渲染循环的每一个迭代中调用processInput： while (!glfwWindowShouldClose(window))&#123; processInput(window); glfwSwapBuffers(window); glfwPollEvents();&#125; 这就给我们一个非常简单的方式来检测特定的键是否被按下，并在每一帧做出处理. 渲染我们要把所有的渲染(Rendering)操作放到渲染循环中，因为我们想让这些渲染指令在每次渲染循环迭代的时候都能被执行。代码将会是这样的： // 渲染循环while(!glfwWindowShouldClose(window))&#123; // 输入 processInput(window); // 渲染指令 ... // 检查并调用事件，交换缓冲 glfwPollEvents(); glfwSwapBuffers(window);&#125; 为了测试一切都正常工作，我们使用一个自定义的颜色清空屏幕。在每个新的渲染迭代开始的时候我们总是希望清屏，否则我们仍能看见上一次迭代的渲染结果（这可能是你想要的效果，但通常这不是）.我们可以通过调用glClear函数来清空屏幕的颜色缓冲，它接受一个缓冲位(Buffer Bit)来指定要清空的缓冲，可能的缓冲位有GL_COLOR_BUFFER_BIT，GL_DEPTH_BUFFER_BIT和GL_STENCIL_BUFFER_BIT。由于现在我们只关心颜色值，所以我们只清空颜色缓冲. glClearColor(0.2f, 0.3f, 0.3f, 1.0f);glClear(GL_COLOR_BUFFER_BIT); 注意，除了glClear之外，我们还调用了glClearColor来设置清空屏幕所用的颜色。当调用glClear函数，清除颜色缓冲之后，整个颜色缓冲都会被填充为glClearColor里所设置的颜色。在这里，我们将屏幕设置为了类似黑板的深蓝绿色. 你应该能够回忆起来我们在 OpenGL 这节教程的内容，glClearColor函数是一个状态设置函数，而glClear函数则是一个状态使用的函数，它使用了当前的状态来获取应该清除为的颜色 //CMakeLists.txtcmake_minimum_required(VERSION 3.14)project(hellow,windows)set(CMAKE_CXX_STANDARD 14)set(SOURCE_FILES main.cpp glad.c)add_executable(main $&#123;SOURCE_FILES&#125;)target_link_libraries(main glfw3 GL m Xrandr Xi X11 Xxf86vm pthread dl Xinerama Xcursor) 你好,三角形 在学习此节之前，建议将这三个单词先记下来：顶点数组对象：Vertex Array Object，VAO顶点缓冲对象：Vertex Buffer Object，VBO索引缓冲对象：Element Buffer Object，EBO或Index Buffer Object，IBO当指代这三个东西的时候，可能使用的是全称，也可能用的是英文缩写，翻译的时候和原文保持的一致。由于没有英文那样的分词间隔，中文全称的部分可能不太容易注意。但请记住，缩写和中文全称指代的是一个东西. 在OpenGL中，任何事物都在3D空间中，而屏幕和窗口却是2D像素数组，这导致OpenGL的大部分工作都是关于把3D坐标转变为适应你屏幕的2D像素。3D坐标转为2D坐标的处理过程是由OpenGL的图形渲染管线（Graphics Pipeline，大多译为管线，实际上指的是一堆原始图形数据途经一个输送管道，期间经过各种变化处理最终出现在屏幕的过程）管理的.图形渲染管线可以被划分为两个主要部分：第一部分把你的3D坐标转换为2D坐标，第二部分是把2D坐标转变为实际的有颜色的像素.这个教程里，我们会简单地讨论一下图形渲染管线，以及如何利用它创建一些漂亮的像素. 2D坐标和像素也是不同的，2D坐标精确表示一个点在2D空间中的位置，而2D像素是这个点的近似值，2D像素受到你的屏幕/窗口分辨率的限制 图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出.图形渲染管线可以被划分为几个阶段，每个阶段将会把前一个阶段的输出作为输入.所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且很容易并行执行.正是由于它们具有并行执行的特性，当今大多数显卡都有成千上万的小处理核心，它们在GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据.这些小程序叫做着色器(Shader). 有些着色器允许开发者自己配置，这就允许我们用自己写的着色器来替换默认的。这样我们就可以更细致地控制图形渲染管线中的特定部分了，而且因为它们运行在GPU上，所以它们可以给我们节约宝贵的CPU时间.OpenGL着色器是用OpenGL着色器语言(OpenGL Shading Language, GLSL)写成的，在下一节中我们再花更多时间研究它. 下面，你会看到一个图形渲染管线的每个阶段的抽象展示.要注意蓝色部分代表的是我们可以注入自定义的着色器的部分.首先，我们以数组的形式传递3个3D坐标作为图形渲染管线的输入，用来表示一个三角形，这个数组叫做顶点数据(Vertex Data)；顶点数据是一系列顶点的集合.一个顶点(Vertex)是一个3D坐标的数据的集合.而顶点数据是用顶点属性(Vertex Attribute)表示的，它可以包含任何我们想用的数据，但是简单起见，我们还是假定每个顶点只由一个3D位置(译注1)和一些颜色值组成的吧. 为了让OpenGL知道我们的坐标和颜色值构成的到底是什么，OpenGL需要你去指定这些数据所表示的渲染类型。我们是希望把这些数据渲染成一系列的点？一系列的三角形？还是仅仅是一个长长的线？做出的这些提示叫做图元(Primitive)，任何一个绘制指令的调用都将把图元传递给OpenGL.这是其中的几个：GL_POINTS、GL_TRIANGLES、GL_LINE_STRIP. 图形渲染管线的第一个部分是顶点着色器(Vertex Shader)，它把一个单独的顶点作为输入。顶点着色器主要的目的是把3D坐标转为另一种3D坐标（后面会解释），同时顶点着色器允许我们对顶点属性进行一些基本处理。 图元装配(Primitive Assembly)阶段将顶点着色器输出的所有顶点作为输入（如果是GL_POINTS，那么就是一个顶点），所有的点装配成指定图元的形状；本节例子中是一个三角形。 图元装配阶段的输出会传递给几何着色器(Geometry Shader).几何着色器把图元形式的一系列顶点的集合作为输入，它可以通过产生新顶点构造出新的（或是其它的）图元来生成其他形状。例子中，它生成了另一个三角形. 几何着色器的输出会被传入光栅化阶段(Rasterization Stage)，这里它会把图元映射为最终屏幕上相应的像素，生成供片段着色器(Fragment Shader)使用的片段(Fragment).在片段着色器运行之前会执行裁切(Clipping).裁切会丢弃超出你的视图以外的所有像素，用来提升执行效率. OpenGL中的一个片段是OpenGL渲染一个像素所需的所有数据. 片段着色器的主要目的是计算一个像素的最终颜色，这也是所有OpenGL高级效果产生的地方。通常，片段着色器包含3D场景的数据（比如光照、阴影、光的颜色等等），这些数据可以被用来计算最终像素的颜色。 在所有对应颜色值确定以后，最终的对象将会被传到最后一个阶段，我们叫做Alpha测试和混合(Blending)阶段。这个阶段检测片段的对应的深度（和模板(Stencil)）值（后面会讲），用它们来判断这个像素是其它物体的前面还是后面，决定是否应该丢弃.这个阶段也会检查alpha值（alpha值定义了一个物体的透明度）并对物体进行混合(Blend).所以，即使在片段着色器中计算出来了一个像素输出的颜色，在渲染多个三角形的时候最后的像素颜色也可能完全不同. 可以看到，图形渲染管线非常复杂，它包含很多可配置的部分.然而，对于大多数场合，我们只需要配置顶点和片段着色器就行了.几何着色器是可选的，通常使用它默认的着色器就行了. 在现代OpenGL中，我们必须定义至少一个顶点着色器和一个片段着色器（因为GPU中没有默认的顶点/片段着色器）.出于这个原因，刚开始学习现代OpenGL的时候可能会非常困难，因为在你能够渲染自己的第一个三角形之前已经需要了解一大堆知识了.在本节结束你最终渲染出你的三角形的时候，你也会了解到非常多的图形编程知识. 顶点输入开始绘制图形之前，我们必须先给OpenGL输入一些顶点数据.OpenGL是一个3D图形库，所以我们在OpenGL中指定的所有坐标都是3D坐标（x、y和z）.OpenGL不是简单地把所有的3D坐标变换为屏幕上的2D像素；OpenGL仅当3D坐标在3个轴（x、y和z）上都为-1.0到1.0的范围内时才处理它.所有在所谓的标准化设备坐标(Normalized Device Coordinates)范围内的坐标才会最终呈现在屏幕上（在这个范围以外的坐标都不会显示）. 由于我们希望渲染一个三角形，我们一共要指定三个顶点，每个顶点都有一个3D位置.我们会将它们以标准化设备坐标的形式（OpenGL的可见区域）定义为一个float数组. float vertices[] = &#123; -0.5f, -0.5f, 0.0f, 0.5f, -0.5f, 0.0f, 0.0f, 0.5f, 0.0f&#125;; 由于OpenGL是在3D空间中工作的，而我们渲染的是一个2D三角形，我们将它顶点的z坐标设置为0.0.这样子的话三角形每一点的深度(Depth)都是一样的，从而使它看上去像是2D的. 通常深度可以理解为z坐标，它代表一个像素在空间中和你的距离，如果离你远就可能被别的像素遮挡，你就看不到它了，它会被丢弃，以节省资源. 标准化设备坐标(Normalized Device Coordinates, NDC)一旦你的顶点坐标已经在顶点着色器中处理过，它们就应该是标准化设备坐标了，标准化设备坐标是一个x、y和z值在-1.0到1.0的一小段空间。任何落在范围外的坐标都会被丢弃/裁剪，不会显示在你的屏幕上。下面你会看到我们定义的在标准化设备坐标中的三角形(忽略z轴)： 与通常的屏幕坐标不同，y轴正方向为向上，(0, 0)坐标是这个图像的中心，而不是左上角。最终你希望所有(变换过的)坐标都在这个坐标空间中，否则它们就不可见了. 你的标准化设备坐标接着会变换为屏幕空间坐标(Screen-space Coordinates)，这是使用你通过glViewport函数提供的数据，进行视口变换(Viewport Transform)完成的.所得的屏幕空间坐标又会被变换为片段输入到片段着色器中. 定义这样的顶点数据以后，我们会把它作为输入发送给图形渲染管线的第一个处理阶段：顶点着色器.它会在GPU上创建内存用于储存我们的顶点数据，还要配置OpenGL如何解释这些内存，并且指定其如何发送给显卡.顶点着色器接着会处理我们在内存中指定数量的顶点. 我们通过顶点缓冲对象(Vertex Buffer Objects, VBO)管理这个内存，它会在GPU内存（通常被称为显存）中储存大量顶点.使用这些缓冲对象的好处是我们可以一次性的发送一大批数据到显卡上，而不是每个顶点发送一次.从CPU把数据发送到显卡相对较慢，所以只要可能我们都要尝试尽量一次性发送尽可能多的数据.当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点，这是个非常快的过程. 顶点缓冲对象有一个独一无二的ID，所以我们可以使用glGenBuffers函数和一个缓冲ID生成一个VBO对象:加粗样式unsigned int VBO;glGenBuffers(1, &amp;VBO); OpenGL有很多缓冲对象类型，顶点缓冲对象的缓冲类型是GL_ARRAY_BUFFER.OpenGL允许我们同时绑定多个缓冲，只要它们是不同的缓冲类型.我们可以使用glBindBuffer函数把新创建的缓冲绑定到GL_ARRAY_BUFFER目标上： glBindBuffer(GL_ARRAY_BUFFER, VBO); 从这一刻起，我们使用的任何（在GL_ARRAY_BUFFER目标上的）缓冲调用都会用来配置当前绑定的缓冲(VBO).然后我们可以调用glBufferData函数，它会把之前定义的顶点数据复制到缓冲的内存中： glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); glBufferData是一个专门用来把用户定义的数据复制到当前绑定缓冲的函数.它的第一个参数是目标缓冲的类型：顶点缓冲对象当前绑定到GL_ARRAY_BUFFER目标上.第二个参数指定传输数据的大小(以字节为单位)；用一个简单的sizeof计算出顶点数据大小就行.第三个参数是我们希望发送的实际数据. 第四个参数指定了我们希望显卡如何管理给定的数据。它有三种形式： GL_STATIC_DRAW ：数据不会或几乎不会改变. GL_DYNAMIC_DRAW：数据会被改变很多. GL_STREAM_DRAW ：数据每次绘制时都会改变. 三角形的位置数据不会改变，每次渲染调用时都保持原样，所以它的使用类型最好是GL_STATIC_DRAW.如果，比如说一个缓冲中的数据将频繁被改变，那么使用的类型就是GL_DYNAMIC_DRAW或GL_STREAM_DRAW，这样就能确保显卡把数据放在能够高速写入的内存部分。 现在我们已经把顶点数据储存在显卡的内存中，用VBO这个顶点缓冲对象管理.下面我们会创建一个顶点和片段着色器来真正处理这些数据.现在我们开始着手创建它们吧. 定点着色器顶点着色器(Vertex Shader)是几个可编程着色器中的一个.如果我们打算做渲染的话，现代OpenGL需要我们至少设置一个顶点和一个片段着色器.我们会简要介绍一下着色器以及配置两个非常简单的着色器来绘制我们第一个三角形.下一节中我们会更详细的讨论着色器. 我们需要做的第一件事是用着色器语言GLSL(OpenGL Shading Language)编写顶点着色器，然后编译这个着色器，这样我们就可以在程序中使用它了.下面你会看到一个非常基础的GLSL顶点着色器的源代码： #version 330 corelayout (location = 0) in vec3 aPos;void main()&#123; gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);&#125; 可以看到，GLSL看起来很像C语言。每个着色器都起始于一个版本声明.OpenGL 3.3以及和更高版本中，GLSL版本号和OpenGL的版本是匹配的（比如说GLSL 420版本对应于OpenGL 4.2）.我们同样明确表示我们会使用核心模式(core). 下一步，使用in关键字，在顶点着色器中声明所有的输入顶点属性(Input Vertex Attribute).现在我们只关心位置(Position)数据，所以我们只需要一个顶点属性.GLSL有一个向量数据类型，它包含1到4个float分量，包含的数量可以从它的后缀数字看出来.由于每个顶点都有一个3D坐标，我们就创建一个vec3输入变量aPos.我们同样也通过layout (location = 0)设定了输入变量的位置值(Location),你后面会看到为什么我们会需要这个位置值. 向量(Vector)在图形编程中我们经常会使用向量这个数学概念，因为它简明地表达了任意空间中的位置和方向，并且它有非常有用的数学属性。在GLSL中一个向量有最多4个分量，每个分量值都代表空间中的一个坐标，它们可以通过vec.x、vec.y、vec.z和vec.w来获取.注意vec.w分量不是用作表达空间中的位置的（我们处理的是3D不是4D），而是用在所谓透视除法(Perspective Division)上.我们会在后面的教程中更详细地讨论向量. 为了设置顶点着色器的输出，我们必须把位置数据赋值给预定义的gl_Position变量，它在幕后是vec4类型的.在main函数的最后，我们将gl_Position设置的值会成为该顶点着色器的输出.由于我们的输入是一个3分量的向量，我们必须把它转换为4分量的.我们可以把vec3的数据作为vec4构造器的参数，同时把w分量设置为1.0f（我们会在后面解释为什么）来完成这一任务. 当前这个顶点着色器可能是我们能想到的最简单的顶点着色器了，因为我们对输入数据什么都没有处理就把它传到着色器的输出了.在真实的程序里输入数据通常都不是标准化设备坐标，所以我们首先必须先把它们转换至OpenGL的可视区域内. 编译着色器我们已经写了一个顶点着色器源码（储存在一个C的字符串中），但是为了能够让OpenGL使用它，我们必须在运行时动态编译它的源码. 我们首先要做的是创建一个着色器对象，注意还是用ID来引用的.所以我们储存这个顶点着色器为unsigned int，然后用glCreateShader创建这个着色器： unsigned int vertexShader;vertexShader = glCreateShader(GL_VERTEX_SHADER); 我们把需要创建的着色器类型以参数形式提供给glCreateShader.由于我们正在创建一个顶点着色器，传递的参数是GL_VERTEX_SHADER. 下一步我们把这个着色器源码附加到着色器对象上，然后编译它： glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL);glCompileShader(vertexShader); glShaderSource函数把要编译的着色器对象作为第一个参数.第二参数指定了传递的源码字符串数量，这里只有一个.第三个参数是顶点着色器真正的源码，第四个参数我们先设置为NULL. 你可能会希望检测在调用glCompileShader后编译是否成功了，如果没成功的话，你还会希望知道错误是什么，这样你才能修复它们。检测编译时错误可以通过以下代码来实现： int success;char infoLog[512];glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success); 首先我们定义一个整型变量来表示是否成功编译，还定义了一个储存错误消息（如果有的话）的容器。然后我们用glGetShaderiv检查是否编译成功.如果编译失败，我们会用glGetShaderInfoLog获取错误消息，然后打印它. if(!success)&#123; glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout &lt;&lt; \"ERROR::SHADER::VERTEX::COMPILATION_FAILED\\n\" &lt;&lt; infoLog &lt;&lt; std::endl;&#125; 片段着色器片段着色器(Fragment Shader)是第二个也是最后一个我们打算创建的用于渲染三角形的着色器.片段着色器所做的是计算像素最后的颜色输出.为了让事情更简单，我们的片段着色器将会一直输出橘黄色. 在计算机图形中颜色被表示为有4个元素的数组：红色、绿色、蓝色和alpha(透明度)分量，通常缩写为RGBA.当在OpenGL或GLSL中定义一个颜色的时候，我们把颜色每个分量的强度设置在0.0到1.0之间.比如说我们设置红为1.0f，绿为1.0f，我们会得到两个颜色的混合色，即黄色.这三种颜色分量的不同调配可以生成超过1600万种不同的颜色！ #version 330 coreout vec4 FragColor;void main()&#123; FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);&#125; 片段着色器只需要一个输出变量，这个变量是一个4分量向量，它表示的是最终的输出颜色，我们应该自己将其计算出来。我们可以用out关键字声明输出变量，这里我们命名为FragColor。下面，我们将一个alpha值为1.0(1.0代表完全不透明)的橘黄色的vec4赋值给颜色输出。 编译片段着色器的过程与顶点着色器类似，只不过我们使用GL_FRAGMENT_SHADER常量作为着色器类型： unsigned int fragmentShader;fragmentShader = glCreateShader(GL_FRAGMENT_SHADER);glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL);glCompileShader(fragmentShader); 两个着色器现在都编译了，剩下的事情是把两个着色器对象链接到一个用来渲染的着色器程序(Shader Program)中. 着色器程序着色器程序对象(Shader Program Object)是多个着色器合并之后并最终链接完成的版本.如果要使用刚才编译的着色器我们必须把它们链接(Link)为一个着色器程序对象，然后在渲染对象的时候激活这个着色器程序。已激活着色器程序的着色器将在我们发送渲染调用的时候被使用. 当链接着色器至一个程序的时候，它会把每个着色器的输出链接到下个着色器的输入.当输出和输入不匹配的时候，你会得到一个连接错误. 创建一个程序对象很简单： unsigned int shaderProgram;shaderProgram = glCreateProgram(); glCreateProgram函数创建一个程序，并返回新创建程序对象的ID引用.现在我们需要把之前编译的着色器附加到程序对象上，然后用glLinkProgram链接它们： glAttachShader(shaderProgram, vertexShader);glAttachShader(shaderProgram, fragmentShader);glLinkProgram(shaderProgram); 代码应该很清楚，我们把着色器附加到了程序上，然后用glLinkProgram链接. 就像着色器的编译一样，我们也可以检测链接着色器程序是否失败，并获取相应的日志。与上面不同，我们不会调用glGetShaderiv和glGetShaderInfoLog，现在我们使用： glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success);if(!success) &#123; glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); ...&#125; 得到的结果就是一个程序对象，我们可以调用glUseProgram函数，用刚创建的程序对象作为它的参数，以激活这个程序对象： glUseProgram(shaderProgram); 在glUseProgram函数调用之后，每个着色器调用和渲染调用都会使用这个程序对象（也就是之前写的着色器)了. 对了，在把着色器对象链接到程序对象以后，记得删除着色器对象，我们不再需要它们了： glDeleteShader(vertexShader);glDeleteShader(fragmentShader); 现在，我们已经把输入顶点数据发送给了GPU，并指示了GPU如何在顶点和片段着色器中处理它.就快要完成了，但还没结束，OpenGL还不知道它该如何解释内存中的顶点数据，以及它该如何将顶点数据链接到顶点着色器的属性上。我们需要告诉OpenGL怎么做. 链接顶点属性顶点着色器允许我们指定任何以顶点属性为形式的输入.这使其具有很强的灵活性的同时，它还的确意味着我们必须手动指定输入数据的哪一个部分对应顶点着色器的哪一个顶点属性.所以，我们必须在渲染前指定OpenGL该如何解释顶点数据。 我们的顶点缓冲数据会被解析为下面这样子： 位置数据被储存为32位（4字节）浮点值 每个位置包含3个这样的值 在这3个值之间没有空隙（或其他值）,这几个值在数组中紧密排列(Tightly Packed)。 数据中第一个值在缓冲开始的位置 有了这些信息我们就可以使用glVertexAttribPointer函数告诉OpenGL该如何解析顶点数据（应用到逐个顶点属性上）了： glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0); glVertexAttribPointer函数的参数非常多，所以我会逐一介绍它们： 第一个参数指定我们要配置的顶点属性.还记得我们在顶点着色器中使用layout(location = 0)定义了position顶点属性的位置值(Location)吗？它可以把顶点属性的位置值设置为0.因为我们希望把数据传递到这一个顶点属性中，所以这里我们传入0. 第二个参数指定顶点属性的大小.顶点属性是一个vec3，它由3个值组成，所以大小是3. 第三个参数指定数据的类型，这里是GL_FLOAT(GLSL中vec*都是由浮点数值组成的). 下个参数定义我们是否希望数据被标准化(Normalize).如果我们设置为GL_TRUE，所有数据都会被映射到0（对于有符号型signed数据是-1）到1之间.我们把它设置为GL_FALSE. 第五个参数叫做步长(Stride)，它告诉我们在连续的顶点属性组之间的间隔.由于下个组位置数据在3个float之后，我们把步长设置为3 * sizeof(float).要注意的是由于我们知道这个数组是紧密排列的（在两个顶点属性之间没有空隙）我们也可以设置为0来让OpenGL决定具体步长是多少（只有当数值是紧密排列时才可用）.一旦我们有更多的顶点属性，我们就必须更小心地定义每个顶点属性之间的间隔，我们在后面会看到更多的例子（译注: 这个参数的意思简单说就是从这个属性第二次出现的地方到整个数组0位置之间有多少字节）. 最后一个参数的类型是void*，所以需要我们进行这个奇怪的强制类型转换。它表示位置数据在缓冲中起始位置的偏移量(Offset)。由于位置数据在数组的开头，所以这里是0.我们会在后面详细解释这个参数. 每个顶点属性从一个VBO管理的内存中获得它的数据，而具体是从哪个VBO（程序中可以有多个VBO）获取则是通过在调用glVertexAttribPointer时绑定到GL_ARRAY_BUFFER的VBO决定的.由于在调用glVertexAttribPointer之前绑定的是先前定义的VBO对象，顶点属性0现在会链接到它的顶点数据. 现在我们已经定义了OpenGL该如何解释顶点数据，我们现在应该使用glEnableVertexAttribArray，以顶点属性位置值作为参数，启用顶点属性；顶点属性默认是禁用的.自此，所有东西都已经设置好了：我们使用一个顶点缓冲对象将顶点数据初始化至缓冲中，建立了一个顶点和一个片段着色器，并告诉了OpenGL如何把顶点数据链接到顶点着色器的顶点属性上.在OpenGL中绘制一个物体，代码会像是这样：// 0. 复制顶点数组到缓冲中供OpenGL使用glBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);// 1. 设置顶点属性指针glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// 2. 当我们渲染一个物体时要使用着色器程序glUseProgram(shaderProgram);// 3. 绘制物体someOpenGLFunctionThatDrawsOurTriangle(); 每当我们绘制一个物体的时候都必须重复这一过程。这看起来可能不多，但是如果有超过5个顶点属性，上百个不同物体呢（这其实并不罕见）.绑定正确的缓冲对象，为每个物体配置所有顶点属性很快就变成一件麻烦事.有没有一些方法可以使我们把所有这些状态配置储存在一个对象中，并且可以通过绑定这个对象来恢复状态呢？ 顶点数组对象顶点数组对象(Vertex Array Object, VAO)可以像顶点缓冲对象那样被绑定，任何随后的顶点属性调用都会储存在这个VAO中.这样的好处就是，当配置顶点属性指针时，你只需要将那些调用执行一次，之后再绘制物体的时候只需要绑定相应的VAO就行了.这使在不同顶点数据和属性配置之间切换变得非常简单，只需要绑定不同的VAO就行了.刚刚设置的所有状态都将存储在VAO中. OpenGL的核心模式要求我们使用VAO，所以它知道该如何处理我们的顶点输入.如果我们绑定VAO失败，OpenGL会拒绝绘制任何东西. 一个顶点数组对象会储存以下这些内容： glEnableVertexAttribArray和glDisableVertexAttribArray的调用. 通过glVertexAttribPointer设置的顶点属性配置. 通过glVertexAttribPointer调用与顶点属性关联的顶点缓冲对象.创建一个VAO和创建一个VBO很类似：unsigned int VAO;glGenVertexArrays(1, &amp;VAO); 要想使用VAO，要做的只是使用glBindVertexArray绑定VAO.从绑定之后起，我们应该绑定和配置对应的VBO和属性指针，之后解绑VAO供之后使用.当我们打算绘制一个物体的时候，我们只要在绘制物体前简单地把VAO绑定到希望使用的设定上就行了.这段代码应该看起来像这样： // ..:: 初始化代码（只运行一次 (除非你的物体频繁改变)） :: ..// 1. 绑定VAOglBindVertexArray(VAO);// 2. 把顶点数组复制到缓冲中供OpenGL使用glBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);// 3. 设置顶点属性指针glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);[...]// ..:: 绘制代码（渲染循环中） :: ..// 4. 绘制物体glUseProgram(shaderProgram);glBindVertexArray(VAO);someOpenGLFunctionThatDrawsOurTriangle(); 就这么多了！前面做的一切都是等待这一刻，一个储存了我们顶点属性配置和应使用的VBO的顶点数组对象.一般当你打算绘制多个物体时，你首先要生成/配置所有的VAO（和必须的VBO及属性指针)，然后储存它们供后面使用.当我们打算绘制物体的时候就拿出相应的VAO，绑定它，绘制完物体后，再解绑VAO. 我们一直期待的三角形要想绘制我们想要的物体，OpenGL给我们提供了glDrawArrays函数，它使用当前激活的着色器，之前定义的顶点属性配置，和VBO的顶点数据（通过VAO间接绑定）来绘制图元.glUseProgram(shaderProgram);glBindVertexArray(VAO);glDrawArrays(GL_TRIANGLES, 0, 3); glDrawArrays函数第一个参数是我们打算绘制的OpenGL图元的类型.由于我们在一开始时说过，我们希望绘制的是一个三角形，这里传递GL_TRIANGLES给它。第二个参数指定了顶点数组的起始索引，我们这里填0。最后一个参数指定我们打算绘制多少个顶点，这里是3（我们只从我们的数据中渲染一个三角形，它只有3个顶点）. 现在尝试编译代码，如果弹出了任何错误，回头检查你的代码。如果你编译通过了，你应该看到下面的结果：三角形的源代码在这里. 索引缓冲对象在渲染顶点这一话题上我们还有最后一个需要讨论的东西——索引缓冲对象(Element Buffer Object，EBO，也叫Index Buffer Object，IBO)。要解释索引缓冲对象的工作方式最好还是举个例子：假设我们不再绘制一个三角形而是绘制一个矩形.我们可以绘制两个三角形来组成一个矩形（OpenGL主要处理三角形）.这会生成下面的顶点的集合： float vertices[] = &#123; // 第一个三角形 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, 0.5f, 0.0f, // 左上角 // 第二个三角形 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角&#125;; 可以看到，有几个顶点叠加了.我们指定了右下角和左上角两次！一个矩形只有4个而不是6个顶点，这样就产生50%的额外开销.当我们有包括上千个三角形的模型之后这个问题会更糟糕，这会产生一大堆浪费.更好的解决方案是只储存不同的顶点，并设定绘制这些顶点的顺序.这样子我们只要储存4个顶点就能绘制矩形了，之后只要指定绘制的顺序就行了.如果OpenGL提供这个功能就好了，对吧？ 很幸运，索引缓冲对象的工作方式正是这样的.和顶点缓冲对象一样，EBO也是一个缓冲，它专门储存索引，OpenGL调用这些顶点的索引来决定该绘制哪个顶点.所谓的索引绘制(Indexed Drawing)正是我们问题的解决方案.首先，我们先要定义（不重复的）顶点，和绘制出矩形所需的索引： float vertices[] = &#123; 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角&#125;;unsigned int indices[] = &#123; // 注意索引从0开始! 0, 1, 3, // 第一个三角形 1, 2, 3 // 第二个三角形&#125;; 你可以看到，当时用索引的时候，我们只定义了4个顶点，而不是6个。下一步我们需要创建索引缓冲对象： unsigned int EBO;glGenBuffers(1, &amp;EBO); 与VBO类似，我们先绑定EBO然后用glBufferData把索引复制到缓冲里.同样，和VBO类似，我们会把这些函数调用放在绑定和解绑函数调用之间，只不过这次我们把缓冲的类型定义为GL_ELEMENT_ARRAY_BUFFER. glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW); 要注意的是，我们传递了GL_ELEMENT_ARRAY_BUFFER当作缓冲目标.最后一件要做的事是用glDrawElements来替换glDrawArrays函数，来指明我们从索引缓冲渲染.使用glDrawElements时，我们会使用当前绑定的索引缓冲对象中的索引进行绘制： glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 第一个参数指定了我们绘制的模式，这个和glDrawArrays的一样.第二个参数是我们打算绘制顶点的个数，这里填6，也就是说我们一共需要绘制6个顶点.第三个参数是索引的类型，这里是GL_UNSIGNED_INT.最后一个参数里我们可以指定EBO中的偏移量（或者传递一个索引数组，但是这是当你不在使用索引缓冲对象的时候），但是我们会在这里填写0. glDrawElements函数从当前绑定到GL_ELEMENT_ARRAY_BUFFER目标的EBO中获取索引.这意味着我们必须在每次要用索引渲染一个物体时绑定相应的EBO，这还是有点麻烦.不过顶点数组对象同样可以保存索引缓冲对象的绑定状态.VAO绑定时正在绑定的索引缓冲对象会被保存为VAO的元素缓冲对象.绑定VAO的同时也会自动绑定EBO. 当目标是GL_ELEMENT_ARRAY_BUFFER的时候，VAO会储存glBindBuffer的函数调用.这也意味着它也会储存解绑调用，所以确保你没有在解绑VAO之前解绑索引数组缓冲，否则它就没有这个EBO配置了. 最后的初始化和绘制代码现在看起来像这样： // ..:: 初始化代码 :: ..// 1. 绑定顶点数组对象glBindVertexArray(VAO);// 2. 把我们的顶点数组复制到一个顶点缓冲中，供OpenGL使用glBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);// 3. 复制我们的索引数组到一个索引缓冲中，供OpenGL使用glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);// 4. 设定顶点属性指针glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);[...]// ..:: 绘制代码（渲染循环中） :: ..glUseProgram(shaderProgram);glBindVertexArray(VAO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0)glBindVertexArray(0); 运行程序会获得下面这样的图片的结果.左侧图片看应该起来很熟悉，而右侧的则是使用线框模式(Wireframe Mode)绘制的.线框矩形可以显示出矩形的确是由两个三角形组成的. 线框模式(Wireframe Mode)要想用线框模式绘制你的三角形，你可以通过glPolygonMode(GL_FRONT_AND_BACK, GL_LINE)函数配置OpenGL如何绘制图元.第一个参数表示我们打算将其应用到所有的三角形的正面和背面，第二个参数告诉我们用线来绘制.之后的绘制调用会一直以线框模式绘制三角形，直到我们用glPolygonMode(GL_FRONT_AND_BACK, GL_FILL)将其设置回默认模式. 如果你遇到任何错误，回头检查代码，看看是否遗漏了什么.同时，你可以在这里找到全部源码. Clion切换运行cpp#CMakeLists.txt trianglecmake_minimum_required(VERSION 3.14)project(hello,triangle)set(CMAKE_CXX_STANDARD 14)set(SOURCE_FILES main.cpp glad.c)add_executable(main $&#123;SOURCE_FILES&#125;)target_link_libraries(main glfw3 GL m Xrandr Xi X11 Xxf86vm pthread dl Xinerama Xcursor) #CMakeLists.txt rectanglecmake_minimum_required(VERSION 3.14)project(hello,triangle)set(CMAKE_CXX_STANDARD 14)set(SOURCE_FILES rectangle.cpp glad.c)add_executable(rectangle $&#123;SOURCE_FILES&#125;)target_link_libraries(rectangle glfw3 GL m Xrandr Xi X11 Xxf86vm pthread dl Xinerama Xcursor) 调试教程调试：这个教程中涉及到了很多步骤，如果你在哪卡住了，阅读一点调试的教程是非常值得的（只需要阅读到调试输出部分） 着色器GLSL一个典型的着色器有下面的结构： #version version_numberin type in_variable_name;in type in_variable_name;out type out_variable_name;uniform type uniform_name;int main()&#123; // 处理输入并进行一些图形操作 ... // 输出处理过的结果到输出变量 out_variable_name = weird_stuff_we_processed;&#125; 当我们特别谈论到顶点着色器的时候，每个输入变量也叫顶点属性(Vertex Attribute)。我们能声明的顶点属性是有上限的，它一般由硬件来决定。OpenGL确保至少有16个包含4分量的顶点属性可用，但是有些硬件或许允许更多的顶点属性，你可以查询GL_MAX_VERTEX_ATTRIBS来获取具体的上限： int nrAttributes;glGetIntegerv(GL_MAX_VERTEX_ATTRIBS, &amp;nrAttributes);std::cout &lt;&lt; \"Maximum nr of vertex attributes supported: \" &lt;&lt; nrAttributes &lt;&lt; std::endl; 向量GLSL中的向量是一个可以包含有1、2、3或者4个分量的容器，分量的类型可以是前面默认基础类型的任意一个。它们可以是下面的形式（n代表分量的数量）：一个向量的分量可以通过vec.x这种方式获取，这里x是指这个向量的第一个分量.你可以分别使用.x、.y、.z和.w来获取它们的第1、2、3、4个分量.GLSL也允许你对颜色使用rgba，或是对纹理坐标使用stpq访问相同的分量. 重组向量这一数据类型也允许一些有趣而灵活的分量选择方式，叫做重组(Swizzling)。重组允许这样的语法： vec2 someVec;vec4 differentVec = someVec.xyxx;vec3 anotherVec = differentVec.zyw;vec4 otherVec = someVec.xxxx + anotherVec.yxzy; 你可以使用上面4个字母任意组合来创建一个和原来向量一样长的（同类型）新向量，只要原来向量有那些分量即可；然而，你不允许在一个vec2向量中去获取.z元素(vec2只有2个维度).我们也可以把一个向量作为一个参数传给不同的向量构造函数，以减少需求参数的数量： vec2 vect = vec2(0.5, 0.7);vec4 result = vec4(vect, 0.0, 0.0);vec4 otherResult = vec4(result.xyz, 1.0); 输入输出GLSL定义了in和out关键字专门来实现数据交流和传递.每个着色器使用这两个关键字设定输入和输出，只要一个输出变量与下一个着色器阶段的输入匹配，它就会传递下去。但在顶点和片段着色器中会有点不同. 顶点着色器应该接收的是一种特殊形式的输入，否则就会效率低下.顶点着色器的输入特殊在，它从顶点数据中直接接收输入.为了定义顶点数据该如何管理，我们使用location这一元数据指定输入变量，这样我们才可以在CPU上配置顶点属性.我们已经在前面的教程看过这个了，layout (location = 0).顶点着色器需要为它的输入提供一个额外的layout标识，这样我们才能把它链接到顶点数据. 你也可以忽略layout (location = 0)标识符，通过在OpenGL代码中使用glGetAttribLocation查询属性位置值(Location)，但是我更喜欢在着色器中设置它们，这样会更容易理解而且节省你（和OpenGL）的工作量. 另一个例外是片段着色器，它需要一个vec4颜色输出变量，因为片段着色器需要生成一个最终输出的颜色。如果你在片段着色器没有定义输出颜色，OpenGL会把你的物体渲染为黑色（或白色）. 所以，如果我们打算从一个着色器向另一个着色器发送数据，我们必须在发送方着色器中声明一个输出，在接收方着色器中声明一个类似的输入.当类型和名字都一样的时候，OpenGL就会把两个变量链接到一起，它们之间就能发送数据了（这是在链接程序对象时完成的）.为了展示这是如何工作的，我们会稍微改动一下之前教程里的那个着色器，让顶点着色器为片段着色器决定颜色.顶点着色器 #version 330 corelayout (location = 0) in vec3 aPos; // 位置变量的属性位置值为0out vec4 vertexColor; // 为片段着色器指定一个颜色输出void main()&#123; gl_Position = vec4(aPos, 1.0); // 注意我们如何把一个vec3作为vec4的构造器的参数 vertexColor = vec4(0.5, 0.0, 0.0, 1.0); // 把输出变量设置为暗红色&#125; 片段着色器 #version 330 coreout vec4 FragColor;in vec4 vertexColor; // 从顶点着色器传来的输入变量（名称相同、类型相同）void main()&#123; FragColor = vertexColor;&#125; 结果如下： UniformUniform是一种从CPU中的应用向GPU中的着色器发送数据的方式，但uniform和顶点属性有些不同.首先,Uniform是全局的,在每个着色器程序中都是独一无二的,它可以被着色器程序的任意着色器在任意阶段访问.其次,无论你把uniform值设置成什么，uniform会一直保存它们的数据，直到它们被重置或更新. #version 330 coreout vec4 FragColor;uniform vec4 ourColor; // 在OpenGL程序代码中设定这个变量void main()&#123; FragColor = ourColor;&#125; 如果你声明了一个uniform却在GLSL代码中没用过，编译器会静默移除这个变量，导致最后编译出的版本中并不会包含它，这可能导致几个非常麻烦的错误，记住这点！ 下面这段程序可以让颜色随着时间变化而改变: float timeValue = glfwGetTime();float greenValue = (sin(timeValue) / 2.0f) + 0.5f;int vertexColorLocation = glGetUniformLocation(shaderProgram, \"ourColor\");glUseProgram(shaderProgram);glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f); 首先我们通过glfwGetTime()获取运行的秒数.然后我们使用sin函数让颜色在0.0到1.0之间改变，最后将结果储存到greenValue里. 接着，我们用glGetUniformLocation查询uniform ourColor的位置值.-1代表没找到.最后，我们可以通过glUniform4f函数设置uniform值.注意，查询uniform地址不要求你之前使用过着色器程序，但是更新一个uniform之前你必须先使用程序（调用glUseProgram)，因为它是在当前激活的着色器程序中设置uniform的. 因为OpenGL在其核心是一个C库，所以它不支持类型重载，在函数参数不同的时候就要为其定义新的函数；glUniform是一个典型例子.这个函数有一个特定的后缀，标识设定的uniform的类型。可能的后缀有：每当你打算配置一个OpenGL的选项时就可以简单地根据这些规则选择适合你的数据类型的重载函数。在我们的例子里，我们希望分别设定uniform的4个float值，所以我们通过glUniform4f传递我们的数据(注意，我们也可以使用fv版本). 下面的程序你会看到你的三角形逐渐由绿变黑再变回绿色.while(!glfwWindowShouldClose(window))&#123; // 输入 processInput(window); // 渲染 // 清除颜色缓冲 glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // 记得激活着色器 glUseProgram(shaderProgram); // 更新uniform颜色 float timeValue = glfwGetTime(); float greenValue = sin(timeValue) / 2.0f + 0.5f; int vertexColorLocation = glGetUniformLocation(shaderProgram, \"ourColor\"); glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f); // 绘制三角形 glBindVertexArray(VAO); glDrawArrays(GL_TRIANGLES, 0, 3); // 交换缓冲并查询IO事件 glfwSwapBuffers(window); glfwPollEvents();&#125; 完整代码点击此处 更多属性！我们将把颜色数据添加为3个float值至vertices数组。我们将把三角形的三个角分别指定为红色、绿色和蓝色： float vertices[] = &#123; // 位置 // 颜色 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, // 左下 0.0f, 0.5f, 0.0f, 0.0f, 0.0f, 1.0f // 顶部&#125;; 由于现在有更多的数据要发送到顶点着色器，我们有必要去调整一下顶点着色器，使它能够接收颜色值作为一个顶点属性输入。需要注意的是我们用layout标识符来把aColor属性的位置值设置为1： #version 330 corelayout (location = 0) in vec3 aPos; // 位置变量的属性位置值为 0 layout (location = 1) in vec3 aColor; // 颜色变量的属性位置值为 1out vec3 ourColor; // 向片段着色器输出一个颜色void main()&#123; gl_Position = vec4(aPos, 1.0); ourColor = aColor; // 将ourColor设置为我们从顶点数据那里得到的输入颜色&#125; 由于我们不再使用uniform来传递片段的颜色了，现在使用ourColor输出变量，我们必须再修改一下片段着色器： #version 330 coreout vec4 FragColor; in vec3 ourColor;void main()&#123; FragColor = vec4(ourColor, 1.0);&#125; 因为我们添加了另一个顶点属性，并且更新了VBO的内存，我们就必须重新配置顶点属性指针。更新后的VBO内存中的数据现在看起来像这样：知道了现在使用的布局，我们就可以使用glVertexAttribPointer函数更新顶点格式:// 位置属性glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// 颜色属性glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)(3* sizeof(float)));glEnableVertexAttribArray(1); 由于我们现在有了两个顶点属性，我们不得不重新计算步长值。为获得数据队列中下一个属性值（比如位置向量的下个x分量）我们必须向右移动6个float，其中3个是位置值，另外3个是颜色值.这使我们的步长值为6乘以float的字节数（=24字节）. 同样，这次我们必须指定一个偏移量。对于每个顶点来说，位置顶点属性在前，所以它的偏移量是0。颜色属性紧随位置数据之后，所以偏移量就是3 * sizeof(float)，用字节来计算就是12字节. 我们只设置了3个颜色,但却得到了而一个调色板,这是在片段着色器中进行的所谓片段插值(Fragment Interpolation)的结果.当渲染一个三角形时，光栅化(Rasterization)阶段通常会造成比原指定顶点更多的片段.光栅会根据每个片段在三角形形状上所处相对位置决定这些片段的位置.基于这些位置，它会插值(Interpolate)所有片段着色器的输入变量.比如说，我们有一个线段，上面的端点是绿色的，下面的端点是蓝色的。如果一个片段着色器在线段的70%的位置运行，它的颜色输入属性就会是一个绿色和蓝色的线性结合；更精确地说就是30%蓝 + 70%绿. 纹理为了能够把纹理映射(Map)到三角形上，我们需要指定三角形的每个顶点各自对应纹理的哪个部分.这样每个顶点就会关联着一个纹理坐标(Texture Coordinate)，用来标明该从纹理图像的哪个部分采样（译注：采集片段颜色）.之后在图形的其它片段上进行片段插值(Fragment Interpolation). 纹理坐标在x和y轴上，范围为0到1之间（注意我们使用的是2D纹理图像）.使用纹理坐标获取纹理颜色叫做采样(Sampling).纹理坐标起始于(0, 0)，也就是纹理图片的左下角，终始于(1, 1)，即纹理图片的右上角.下面的图片展示了我们是如何把纹理坐标映射到三角形上的.纹理坐标看起来就像这样： float texCoords[] = &#123; 0.0f, 0.0f, // 左下角 1.0f, 0.0f, // 右下角 0.5f, 1.0f // 上中&#125;; 纹理环绕方式纹理坐标的范围通常是从(0, 0)到(1, 1)，那如果我们把纹理坐标设置在范围之外会发生什么？OpenGL默认的行为是重复这个纹理图像（我们基本上忽略浮点纹理坐标的整数部分），但OpenGL提供了更多的选择：前面提到的每个选项都可以使用glTexParameter*函数对单独的一个坐标轴设置（s、t（如果是使用3D纹理那么还有一个r）它们和x、y、z是等价的）： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT); 第一个参数指定了纹理目标；我们使用的是2D纹理，因此纹理目标是GL_TEXTURE_2D.第二个参数需要我们指定设置的选项与应用的纹理轴.我们打算配置的是WRAP选项，并且指定S和T轴.最后一个参数需要我们传递一个环绕方式(Wrapping)，在这个例子中OpenGL会给当前激活的纹理设定纹理环绕方式为GL_MIRRORED_REPEAT. 如果我们选择GL_CLAMP_TO_BORDER选项，我们还需要指定一个边缘的颜色.这需要使用glTexParameter函数的fv后缀形式，用GL_TEXTURE_BORDER_COLOR作为它的选项，并且传递一个float数组作为边缘的颜色值： float borderColor[] = &#123; 1.0f, 1.0f, 0.0f, 1.0f &#125;;glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor); 纹理过滤纹理坐标不依赖于分辨率(Resolution)，它可以是任意浮点值，所以OpenGL需要知道怎样将纹理像素(Texture Pixel，也叫Texel，译注1)映射到纹理坐标.当你有一个很大的物体但是纹理的分辨率很低的时候这就变得很重要了.你可能已经猜到了，OpenGL也有对于纹理过滤(Texture Filtering)的选项.纹理过滤有很多个选项，但是现在我们只讨论最重要的两种：GL_NEAREST和GL_LINEAR. GL_NEAREST（也叫邻近过滤，Nearest Neighbor Filtering）是OpenGL默认的纹理过滤方式.当设置为GL_NEAREST的时候，OpenGL会选择中心点最接近纹理坐标的那个像素.下图中你可以看到四个像素，加号代表纹理坐标.左上角那个纹理像素的中心距离纹理坐标最近，所以它会被选择为样本颜色：GL_LINEAR（也叫线性过滤，(Bi)linear Filtering）它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色.一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大.下图中你可以看到返回的颜色是邻近像素的混合色：GL_NEAREST产生了颗粒状的图案，我们能够清晰看到组成纹理的像素，而GL_LINEAR能够产生更平滑的图案，很难看出单个的纹理像素.GL_LINEAR可以产生更真实的输出，但有些开发者更喜欢8-bit风格，所以他们会用GL_NEAREST选项. 当进行放大(Magnify)和缩小(Minify)操作的时候可以设置纹理过滤的选项，比如你可以在纹理被缩小的时候使用邻近过滤，被放大时使用线性过滤。我们需要使用glTexParameter*函数为放大和缩小指定过滤方式.这段代码看起来会和纹理环绕方式的设置很相似： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 多级渐远纹理想象一下，假设我们有一个包含着上千物体的大房间，每个物体上都有纹理。有些物体会很远，但其纹理会拥有与近处物体同样高的分辨率.由于远处的物体可能只产生很少的片段，OpenGL从高分辨率纹理中为这些片段获取正确的颜色值就很困难，因为它需要对一个跨过纹理很大部分的片段只拾取一个纹理颜色.在小物体上这会产生不真实的感觉，更不用说对它们使用高分辨率纹理浪费内存的问题了. OpenGL使用一种叫做多级渐远纹理(Mipmap)的概念来解决这个问题，它简单来说就是一系列的纹理图像，后一个纹理图像是前一个的二分之一.多级渐远纹理背后的理念很简单：距观察者的距离超过一定的阈值，OpenGL会使用不同的多级渐远纹理，即最适合物体的距离的那个.由于距离远，解析度不高也不会被用户注意到.同时，多级渐远纹理另一加分之处是它的性能非常好.让我们看一下多级渐远纹理是什么样子的：手工为每个纹理图像创建一系列多级渐远纹理很麻烦，幸好OpenGL有一个glGenerateMipmaps函数，在创建完一个纹理后调用它OpenGL就会承担接下来的所有工作了. 在渲染中切换多级渐远纹理级别(Level)时，OpenGL在两个不同级别的多级渐远纹理层之间会产生不真实的生硬边界.就像普通的纹理过滤一样，切换多级渐远纹理级别时你也可以在两个不同多级渐远纹理级别之间使用NEAREST和LINEAR过滤.为了指定不同多级渐远纹理级别之间的过滤方式，你可以使用下面四个选项中的一个代替原有的过滤方式：就像纹理过滤一样，我们可以使用glTexParameteri将过滤方式设置为前面四种提到的方法之一： glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 一个常见的错误是，将放大过滤的选项设置为多级渐远纹理过滤选项之一.这样没有任何效果，因为多级渐远纹理主要是使用在纹理被缩小的情况下的：纹理放大不会使用多级渐远纹理，为放大过滤设置多级渐远纹理的选项会产生一个GL_INVALID_ENUM错误代码. 加载与创建纹理使用一个支持多种流行格式的图像加载库来为我们解决图像加载的问题,比如说我们要用的stb_image.h库. stb_image.hstb_image.h可以在这里下载. #define STB_IMAGE_IMPLEMENTATION#include \"stb_image.h\" 通过定义STB_IMAGE_IMPLEMENTATION，预处理器会修改头文件，让其只包含相关的函数定义源码，等于是将这个头文件变为一个 .cpp 文件了.现在只需要在你的程序中包含stb_image.h并编译就可以了. int width, height, nrChannels;unsigned char *data = stbi_load(\"container.jpg\", &amp;width, &amp;height, &amp;nrChannels, 0); 这个函数首先接受一个图像文件的位置作为输入。接下来它需要三个int作为它的第二、第三和第四个参数，stb_image.h将会用图像的宽度、高度和颜色通道的个数填充这三个变量。我们之后生成纹理的时候会用到的图像的宽度和高度的. 生成纹理和之前生成的OpenGL对象一样，纹理也是使用ID引用的. unsigned int texture;glGenTextures(1, &amp;texture); glGenTextures函数首先需要输入生成纹理的数量，然后把它们储存在第二个参数的unsigned int数组中（我们的例子中只是单独的一个unsigned int），就像其他对象一样，我们需要绑定它，让之后任何的纹理指令都可以配置当前绑定的纹理： glBindTexture(GL_TEXTURE_2D, texture); 第一个参数指定了纹理目标(Target).设置为GL_TEXTURE_2D意味着会生成与当前绑定的纹理对象在同一个目标上的纹理（任何绑定到GL_TEXTURE_1D和GL_TEXTURE_3D的纹理不会受到影响）. 第二个参数为纹理指定多级渐远纹理的级别，如果你希望单独手动设置每个多级渐远纹理的级别的话.这里我们填0，也就是基本级别. 第三个参数告诉OpenGL我们希望把纹理储存为何种格式.我们的图像只有RGB值，因此我们也把纹理储存为RGB值. 第四个和第五个参数设置最终的纹理的宽度和高度.我们之前加载图像的时候储存了它们，所以我们使用对应的变量. 下个参数应该总是被设为0（历史遗留的问题）. 第七第八个参数定义了源图的格式和数据类型。我们使用RGB值加载这个图像，并把它们储存为char(byte)数组，我们将会传入对应值. 最后一个参数是真正的图像数据. 当调用glTexImage2D时，当前绑定的纹理对象就会被附加上纹理图像.然而，目前只有基本级别(Base-level)的纹理图像被加载了，如果要使用多级渐远纹理，我们必须手动设置所有不同的图像（不断递增第二个参数）.或者，直接在生成纹理之后调用glGenerateMipmap.这会为当前绑定的纹理自动生成所有需要的多级渐远纹理. 生成了纹理和相应的多级渐远纹理后，释放图像的内存是一个很好的习惯. stbi_image_free(data); 变换三维旋转公式利用旋转矩阵我们可以把任意位置向量沿一个单位旋转轴进行旋转。也可以将多个矩阵复合，比如先沿着x轴旋转再沿着y轴旋转.但是这会很快导致一个问题——万向节死锁（Gimbal Lock）.这样的一个（超级麻烦的）矩阵是存在的，见下面这个公式，其中(Rx,Ry,Rz)代表任意旋转轴：即使这样一个矩阵也不能完全解决万向节死锁问题（尽管会极大地避免）.避免万向节死锁的真正解决方案是使用四元数(Quaternion)，它不仅更安全，而且计算会更有效率。四元数可能会在后面的教程中讨论.相关资料:四元数万向节死锁万向节死锁的理解 矩阵的组合假设我们有一个顶点(x, y, z)，我们希望将其缩放2倍，然后位移(1, 2, 3)个单位.我们需要一个位移和缩放矩阵来完成这些变换.结果的变换矩阵看起来像这样： 坐标系统透视投影如果你曾经体验过实际生活给你带来的景象，你就会注意到离你越远的东西看起来更小.这个奇怪的效果称之为透视(Perspective).透视的效果在我们看一条无限长的高速公路或铁路时尤其明显，正如下面图片显示的那样：正如你看到的那样，由于透视，这两条线在很远的地方看起来会相交.这正是透视投影想要模仿的效果，它是使用透视投影矩阵来完成的.这个投影矩阵将给定的平截头体范围映射到裁剪空间，除此之外还修改了每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大.被变换到裁剪空间的坐标都会在-w到w的范围之间（任何大于这个范围的坐标都会被裁剪掉）.OpenGL要求所有可见的坐标都落在-1.0到1.0范围内，作为顶点着色器最后的输出，因此，一旦坐标在裁剪空间内之后，透视除法就会被应用到裁剪空间坐标上：顶点坐标的每个分量都会除以它的w分量，距离观察者越远顶点坐标就会越小.这是也是w分量非常重要的另一个原因，它能够帮助我们进行透视投影。最后的结果坐标就是处于标准化设备空间中的.如果你对正射投影矩阵和透视投影矩阵是如何计算的很感兴趣（且不会对数学感到恐惧的话）我推荐这篇由Songho写的文章.在GLM中可以这样创建一个透视投影矩阵： glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f); 同样，glm::perspective所做的其实就是创建了一个定义了可视空间的大平截头体，任何在这个平截头体以外的东西最后都不会出现在裁剪空间体积内，并且将会受到裁剪.一个透视平截头体可以被看作一个不均匀形状的箱子，在这个箱子内部的每个坐标都会被映射到裁剪空间上的一个点.下面是一张透视平截头体的图片：它的第一个参数定义了fov的值，它表示的是视野(Field of View)，并且设置了观察空间的大小.如果想要一个真实的观察效果，它的值通常设置为45.0f，但想要一个末日风格的结果你可以将其设置一个更大的值.第二个参数设置了宽高比，由视口的宽除以高所得.第三和第四个参数设置了平截头体的近和远平面。我们通常设置近距离为0.1f，而远距离设为100.0f.所有在近平面和远平面内且处于平截头体内的顶点都会被渲染. 当你把透视矩阵的 near 值设置太大时（如10.0f），OpenGL会将靠近摄像机的坐标（在0.0f和10.0f之间）都裁剪掉，这会导致一个你在游戏中很熟悉的视觉效果：在太过靠近一个物体的时候你的视线会直接穿过去. 当使用正射投影时，每一个顶点坐标都会直接映射到裁剪空间中而不经过任何精细的透视除法（它仍然会进行透视除法，只是w分量没有被改变（它保持为1），因此没有起作用）.因为正射投影没有使用透视，远处的物体不会显得更小，所以产生奇怪的视觉效果.由于这个原因，正射投影主要用于二维渲染以及一些建筑或工程的程序，在这些场景中我们更希望顶点不会被透视所干扰.某些如 Blender 等进行三维建模的软件有时在建模时也会使用正射投影，因为它在各个维度下都更准确地描绘了每个物体。下面你能够看到在Blender里面使用两种投影方式的对比：你可以看到，使用透视投影的话，远处的顶点看起来比较小，而在正射投影中每个顶点距离观察者的距离都是一样的. Z缓冲(深度缓冲)OpenGL存储深度信息在一个叫做Z缓冲(Z-buffer)的缓冲中，它允许OpenGL决定何时覆盖一个像素而何时不覆盖.通过使用Z缓冲，我们可以配置OpenGL来进行深度测试. GLFW会自动为你生成这样一个缓冲（就像它也有一个颜色缓冲来存储输出图像的颜色）.深度值存储在每个片段里面（作为片段的z值），当片段想要输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较，如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖.这个过程称为深度测试(Depth Testing)，它是由OpenGL自动完成的. glEnable和glDisable函数允许我们启用或禁用某个OpenGL功能.这个功能会一直保持启用/禁用状态，直到另一个调用来禁用/启用它.现在我们想启用深度测试，需要开启GL_DEPTH_TEST： glEnable(GL_DEPTH_TEST); 因为我们使用了深度测试，我们也想要在每次渲染迭代之前清除深度缓冲（否则前一帧的深度信息仍然保存在缓冲中）.就像清除颜色缓冲一样，我们可以通过在glClear函数中指定DEPTH_BUFFER_BIT位来清除深度缓冲： glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); 摄像机 摄像机方向摄像机的方向指的是摄像机指向哪个方向.现在我们让摄像机指向场景原点：(0, 0, 0).用场景原点向量减去摄像机位置向量的结果就是摄像机的指向向量.由于我们知道摄像机指向z轴负方向，但我们希望方向向量(Direction Vector)指向摄像机的z轴正方向.如果我们交换相减的顺序，我们就会获得一个指向摄像机正z轴方向的向量： glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget); 方向向量(Direction Vector)并不是最好的名字，因为它实际上指向从它到目标向量的相反方向（译注：注意看前面的那个图，蓝色的方向向量大概指向z轴的正方向，与摄像机实际指向的方向是正好相反的）. 右轴我们需要的另一个向量是一个右向量(Right Vector)，它代表摄像机空间的x轴的正方向.为获取右向量我们需要先使用一个小技巧：先定义一个上向量(Up Vector).接下来把上向量和第二步得到的方向向量进行叉乘.两个向量叉乘的结果会同时垂直于两向量，因此我们会得到指向x轴正方向的那个向量（如果我们交换两个向量叉乘的顺序就会得到相反的指向x轴负方向的向量）： glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection)); 上轴右向量和方向向量进行叉乘得到y轴正方形,即上轴. glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight); 对于想学到更多数学原理的读者，提示一下，在线性代数中这个处理叫做格拉姆—施密特正交化(Gram-Schmidt Process).使用这些摄像机向量我们就可以创建一个LookAt矩阵了，它在创建摄像机的时候非常有用. Look At使用矩阵的好处之一是如果你使用3个相互垂直（或非线性）的轴定义了一个坐标空间，你可以用这3个轴外加一个平移向量来创建一个矩阵，并且你可以用这个矩阵乘以任何向量来将其变换到那个坐标空间.这正是LookAt矩阵所做的，现在我们有了3个相互垂直的轴和一个定义摄像机空间的位置坐标，我们可以创建我们自己的LookAt矩阵了：其中R是右向量，U是上向量，D是方向向量P是摄像机位置向量.注意，位置向量是相反的，因为我们最终希望把世界平移到与我们自身移动的相反方向.把这个LookAt矩阵作为观察矩阵可以很高效地把所有世界坐标变换到刚刚定义的观察空间.LookAt矩阵就像它的名字表达的那样：它会创建一个看着(Look at)给定目标的观察矩阵. 幸运的是，GLM已经提供了这些支持.我们要做的只是定义一个摄像机位置，一个目标位置和一个表示世界空间中的上向量的向量（我们计算右向量使用的那个上向量）.接着GLM就会创建一个LookAt矩阵，我们可以把它当作我们的观察矩阵： glm::mat4 view;view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f)); 自由移动glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);glm::vec3 cameraFront = glm::vec3(0.0f, 0.0f, -1.0f);glm::vec3 cameraUp = glm::vec3(0.0f, 1.0f, 0.0f);view = glm::lookAt(cameraPos, cameraPos + cameraFront, cameraUp); 我们首先将摄像机位置设置为之前定义的cameraPos.方向是当前的位置加上我们刚刚定义的方向向量.这样能保证无论我们怎么移动，摄像机都会注视着目标方向.让我们摆弄一下这些向量，在按下某些按钮时更新cameraPos向量. 我们已经为GLFW的键盘输入定义过一个processInput函数了，我们来新添加几个需要检查的按键命令： void processInput(GLFWwindow *window)&#123; ... float cameraSpeed = 0.05f; // adjust accordingly if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS) cameraPos += cameraSpeed * cameraFront; if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS) cameraPos -= cameraSpeed * cameraFront; if (glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS) cameraPos -= glm::normalize(glm::cross(cameraFront, cameraUp)) * cameraSpeed; if (glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS) cameraPos += glm::normalize(glm::cross(cameraFront, cameraUp)) * cameraSpeed;&#125; 当我们按下WASD键的任意一个，摄像机的位置都会相应更新。如果我们希望向前或向后移动，我们就把位置向量加上或减去方向向量.如果我们希望向左右移动，我们使用叉乘来创建一个右向量(Right Vector)，并沿着它相应移动就可以了.这样就创建了使用摄像机时熟悉的横移(Strafe)效果. 注意，我们对右向量进行了标准化.如果我们没对这个向量进行标准化，最后的叉乘结果会根据cameraFront变量返回大小不同的向量.如果我们不对向量进行标准化，我们就得根据摄像机的朝向不同加速或减速移动了，但如果进行了标准化移动就是匀速的. 移动速度目前我们的移动速度是个常量.理论上没什么问题，但是实际情况下根据处理器的能力不同，有些人可能会比其他人每秒绘制更多帧，也就是以更高的频率调用processInput函数.结果就是，根据配置的不同，有些人可能移动很快，而有些人会移动很慢.当你发布你的程序的时候，你必须确保它在所有硬件上移动速度都一样. 图形程序和游戏通常会跟踪一个时间差(Deltatime)变量，它储存了渲染上一帧所用的时间.我们把所有速度都去乘以deltaTime值.结果就是，如果我们的deltaTime很大，就意味着上一帧的渲染花费了更多时间，所以这一帧的速度需要变得更高来平衡渲染所花去的时间.使用这种方法时，无论你的电脑快还是慢，摄像机的速度都会相应平衡，这样每个用户的体验就都一样了. 视角移动为了能够改变视角，我们需要根据鼠标的输入改变cameraFront向量.在此之前,我们需要学习相关的数学知识. 欧拉角欧拉角(Euler Angle)是可以表示3D空间中任何旋转的3个值，由莱昂哈德·欧拉(Leonhard Euler)在18世纪提出.一共有3种欧拉角：俯仰角(Pitch)、偏航角(Yaw)和滚转角(Roll)，下面的图片展示了它们的含义：对于我们的摄像机系统来说，我们只关心俯仰角和偏航角，所以我们不会讨论滚转角.给定一个俯仰角和偏航角，我们可以把它们转换为一个代表新的方向向量的3D向量.俯仰角和偏航角转换为方向向量的处理需要一些三角学知识，我们先从最基本的情况开始：如果我们把斜边边长定义为1，我们就能知道邻边的长度是cos x/h=cos x/1=cos x，它的对边是sin y/h=sin y/1=sin y.这样我们获得了能够得到x和y方向长度的通用公式，它们取决于所给的角度.我们使用它来计算方向向量的分量：这个三角形看起来和前面的三角形很像，所以如果我们想象自己在xz平面上，看向y轴，我们可以基于第一个三角形计算来计算它的长度/y方向的强度(Strength)（我们往上或往下看多少）.从图中我们可以看到对于一个给定俯仰角的y值等于sin θ： direction.y = sin(glm::radians(pitch)); // 注意我们先把角度转为弧度 这里我们只更新了y值，仔细观察x和z分量也被影响了.从三角形中我们可以看到它们的值等于： direction.x = cos(glm::radians(pitch));direction.z = cos(glm::radians(pitch)); 看看我们是否能够为偏航角找到需要的分量：就像俯仰角的三角形一样，我们可以看到x分量取决于cos(yaw)的值，z值同样取决于偏航角的正弦值.把这个加到前面的值中，会得到基于俯仰角和偏航角的方向向量： direction.x = cos(glm::radians(pitch)) * cos(glm::radians(yaw)); // 译注：direction代表摄像机的前轴(Front)，这个前轴是和本文第一幅图片的第二个摄像机的方向向量是相反的direction.y = sin(glm::radians(pitch));direction.z = cos(glm::radians(pitch)) * sin(glm::radians(yaw)); 这样我们就有了一个可以把俯仰角和偏航角转化为用来自由旋转视角的摄像机的3维方向向量了.你可能会奇怪：我们怎么得到俯仰角和偏航角？ 鼠标输入偏航角和俯仰角是通过鼠标（或手柄）移动获得的，水平的移动影响偏航角，竖直的移动影响俯仰角.它的原理就是，储存上一帧鼠标的位置，在当前帧中我们当前计算鼠标位置与上一帧的位置相差多少.如果水平/竖直差别越大那么俯仰角或偏航角就改变越大，也就是摄像机需要移动更多的距离. 首先我们要告诉GLFW，它应该隐藏光标，并捕捉(Capture)它.捕捉光标表示的是，如果焦点在你的程序上（译注：即表示你正在操作这个程序，Windows中拥有焦点的程序标题栏通常是有颜色的那个，而失去焦点的程序标题栏则是灰色的），光标应该停留在窗口中（除非程序失去焦点或者退出）.我们可以用一个简单地配置调用来完成： glfwSetInputMode(window, GLFW_CURSOR, GLFW_CURSOR_DISABLED); 为了计算俯仰角和偏航角，我们需要让GLFW监听鼠标移动事件.（和键盘输入相似）我们会用一个回调函数来完成，函数的原型如下： void mouse_callback(GLFWwindow* window, double xpos, double ypos); 这里的xpos和ypos代表当前鼠标的位置.当我们用GLFW注册了回调函数之后，鼠标一移动mouse_callback函数就会被调用： glfwSetCursorPosCallback(window, mouse_callback); 在处理FPS风格摄像机的鼠标输入的时候，我们必须在最终获取方向向量之前做下面这几步： 计算鼠标距上一帧的偏移量 把偏移量添加到摄像机的俯仰角和偏航角中 对偏航角和俯仰角进行最大和最小值的限制 计算方向向量 第一步是计算鼠标自上一帧的偏移量.我们必须先在程序中储存上一帧的鼠标位置，我们把它的初始值设置为屏幕的中心（屏幕的尺寸是800x600）： float lastX = 400, lastY = 300; 然后在鼠标的回调函数中我们计算当前帧和上一帧鼠标位置的偏移量： float xoffset = xpos - lastX;float yoffset = lastY - ypos; // 注意这里是相反的，因为y坐标是从底部往顶部依次增大的lastX = xpos;lastY = ypos;float sensitivity = 0.05f;xoffset *= sensitivity;yoffset *= sensitivity; 注意我们把偏移量乘以了sensitivity（灵敏度）值.如果我们忽略这个值，鼠标移动就会太大了；你可以自己实验一下，找到适合自己的灵敏度值. 接下来我们把偏移量加到全局变量pitch和yaw上： yaw += xoffset;pitch += yoffset; 第三步，我们需要给摄像机添加一些限制，这样摄像机就不会发生奇怪的移动了（这样也会避免一些奇怪的问题）.对于俯仰角，要让用户不能看向高于89度的地方（在90度时视角会发生逆转，所以我们把89度作为极限），同样也不允许小于-89度.这样能够保证用户只能看到天空或脚下，但是不能超越这个限制.我们可以在值超过限制的时候将其改为极限值来实现： if(pitch &gt; 89.0f) pitch = 89.0f;if(pitch &lt; -89.0f) pitch = -89.0f; 第四也是最后一步，就是通过俯仰角和偏航角来计算以得到真正的方向向量： glm::vec3 front;front.x = cos(glm::radians(pitch)) * cos(glm::radians(yaw));front.y = sin(glm::radians(pitch));front.z = cos(glm::radians(pitch)) * sin(glm::radians(yaw));cameraFront = glm::normalize(front); 计算出来的方向向量就会包含根据鼠标移动计算出来的所有旋转了.由于cameraFront向量已经包含在GLM的lookAt函数中，我们这就没什么问题了. 如果你现在运行代码，你会发现在窗口第一次获取焦点的时候摄像机会突然跳一下。这个问题产生的原因是，在你的鼠标移动进窗口的那一刻，鼠标回调函数就会被调用，这时候的xpos和ypos会等于鼠标刚刚进入屏幕的那个位置.这通常是一个距离屏幕中心很远的地方，因而产生一个很大的偏移量，所以就会跳了.我们可以简单的使用一个bool变量检验我们是否是第一次获取鼠标输入，如果是，那么我们先把鼠标的初始位置更新为xpos和ypos值，这样就能解决这个问题；接下来的鼠标移动就会使用刚进入的鼠标位置坐标来计算偏移量了： if(firstMouse) // 这个bool变量初始时是设定为true的&#123; lastX = xpos; lastY = ypos; firstMouse = false;&#125; 缩放注册滚轮回调函数 void scroll_callback(GLFWwindow* window, double xoffset, double yoffset)&#123; if(fov &gt;= 1.0f &amp;&amp; fov &lt;= 45.0f) fov -= yoffset; if(fov &lt;= 1.0f) fov = 1.0f; if(fov &gt;= 45.0f) fov = 45.0f;&#125; 当滚动鼠标滚轮的时候，yoffset值代表我们竖直滚动的大小.当scroll_callback函数被调用后，我们改变全局变量fov变量的内容.因为45.0f是默认的视野值，我们将会把缩放级别(Zoom Level)限制在1.0f到45.0f. 我们现在在每一帧都必须把透视投影矩阵上传到GPU，但现在使用fov变量作为它的视野： projection = glm::perspective(glm::radians(fov), 800.0f / 600.0f, 0.1f, 100.0f); 最后不要忘记注册鼠标滚轮的回调函数： glfwSetScrollCallback(window, scroll_callback); 注意，使用欧拉角的摄像机系统并不完美.根据你的视角限制或者是配置，你仍然可能引入万向节死锁问题.最好的摄像机系统是使用四元数(Quaternions)的，但我们将会把这个留到后面讨论.（译注：这里可以查看四元数摄像机的实现） 摄像机类和着色器对象一样，我们把摄像机类写在一个单独的头文件中.你可以在这里找到它，你现在应该能够理解所有的代码了.我们建议您至少看一看这个类，看看如何创建一个自己的摄像机类.","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"OpenGL","slug":"OpenGL","permalink":"/tags/OpenGL/"},{"name":"计算机图形学","slug":"计算机图形学","permalink":"/tags/计算机图形学/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"记录一下平常遇到的环境配置问题","slug":"记录一下平常遇到的环境配置问题","date":"2019-10-07T14:57:03.000Z","updated":"2019-10-07T14:58:25.943Z","comments":true,"path":"2019/10/07/记录一下平常遇到的环境配置问题/","link":"","permalink":"/2019/10/07/记录一下平常遇到的环境配置问题/","excerpt":"","text":"1.matlab对于比较无法保存比较大的mat文件，而服务器又没有图形化界面可以进行-v7.3设置，这时可以使用save(‘1.mat’,’data’,’-v7.3’)对数据进行保存.2.matlab调用jdbc的mysql使用5的老版本就行了，不要用8，jdk&gt;=1.8即可.3.clion中的glsl文件相对路径总是不对是因为程序在执行调用时用的是cmke-build-debug/bin目录下的glsl代码文件.4.opengl如果遇到运行闪白，关闭瞬间才显示的情况，这时应该注释掉版本信息的语句.5.linux系统静默安装matlab可参照这篇文章，安装步骤是对的，激活失败没关系，可以破解就行.6.hexo博客主题中的package.json记录的是依赖文件，可以通过cnpm i来自动安装该文件中的依赖.7.linux系统安装opengl安装有个坑，libglut.so网上的教程都说是在/usr/lib/i386-linux-gnu其实64位的机器好像是在x86-linux-gnu处，合理利用搜索功能就行了.8.torch版本对应不上可以先找whl，如果安装torhvision会强制更新torch，根据经验，torch0.4.1对应torchvision0.2.0.9.cuda可以多版本，修改链接即可.10.linux环境下显卡驱动直接通过run文件安装即可.11.windows下配置opengl需要找对应的编译文件(Mingw和vs的链接库文件后缀似乎是不同的).","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"环境配置","slug":"环境配置","permalink":"/tags/环境配置/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"数据结构-邓俊辉","slug":"数据结构-邓俊辉","date":"2019-09-18T10:56:52.000Z","updated":"2019-09-18T10:56:43.970Z","comments":true,"path":"2019/09/18/数据结构-邓俊辉/","link":"","permalink":"/2019/09/18/数据结构-邓俊辉/","excerpt":"","text":"@[toc] 去重讲解主要思想:先排序,然后找到不同的元素就将其放到前列 斐波那契查找在常系数意义上要优于二分查找拓展:符合语义要求的二分查找版本C 改进版冒泡排序解析前半部分(绿色)其实并不一定是无序的,而我们在冒泡的过程中其实已经”隐式”地检查过了.如果之前的冒泡没有交换过,证明前面的已经是有序的了.继续改进每次都记录下最后一次逆序对的位置,这样就可以不必对没有逆序的元素进行遍历,最好情况下可以到达O(n). 中缀表达式转逆波兰表达式(RPN)逆波兰表达式无括号,从头到尾计算 括号引理记录下dfs搜索过程的时间标签的作用 AVL树3+4重构下面的代码似乎有点错误: 伸展树利用了局部性原理,经过长时间的调整,常被访问的节点会靠近树根位置.Tanjarn双层调整改进算法 B-树分裂操作如果向上传播至根,那么B树木高度+1,这也是使得B树可以长高的唯一操作. 红黑树 散列函数的设计为什么是平方取中? 平方试探视频证明提高装填因子 优先级队列完全二叉树实现:根节点即最大元素常系数改进:不用每次都swap,先将最后一个节点备份,逐渐向上比较,每次只下移父节点,最后直接替换即可蛮力建堆:改进:自下而上的下滤深度和高度作为指标明明应该很接近,为什么在渐进的意义上会有这样的差别?越底层,节点数量越多.堆排序:堆合并:以上方法并没有利用到A和B两个堆原本的偏序信息.左式堆:右侧链:左式堆实例:视频实例插入即是合并删除亦是合并 串蛮力为何低效?只看原字符串,针对原字符串的每个字符,在最坏情况下,都需要和模式串的每个字符进行比对.不变性:KMP算法:next[]数组:选取最大的那个t,t越大,j-t越小,意味着越安全,可以避免回溯(暂未理解),也即跃过的部分确实是不必尝试匹配的.视频讲解j&lt;0也表示上一次失配的位置即首位置.构造next[]数组:递推公式:效率精确估计:KMP再改进:下一个进行匹配的至少不应该和原来一样,针对下面的案例,即至少不能再是0.注意第二行0下面都变成了-1.BM算法:坏字符更多地关注教训,加速失败,让更大的教训更早地出现.后面的字符可以排除更多的对齐位置.视频讲解BC表:但模式串中可能有多个’X’,那么要选用哪个’X’呢?此时应该巧选其一,避免回溯.选择shift位移量相对较小的,即选用最后的那个’X’.那如果模式串中没有’X’呢?此时应将模式串完整地移过这个位置.(第四行,利用通配哨兵字符)如果最后一个’X’的秩过大导致shift为负数,此时应该怎么办?直接+1.最好性能:最坏性能:视频讲解坏字符’1’的替代者’0’的最后位置太靠后,导致shifit为负数,因而只能整体移动一个位置.改进:GS:好后缀产生gs[]表:性能比较: 教材中有答案 排序快排:注意数字5有两个,可以看出快排的不稳定性.快排变种:随机交换是为了减少最坏情况的出现.选取众数:(不懂)快速选择:线性选择:希尔排序: TIP小于号对应区间判断的时候统一用&lt;号,这样可以直接对应区间,方便理解 位运算快速取模+为什么是素数(散列)蝉的哲学:S是天敌的生命周期,M是蝉的生命周期,经过长期的自然选择,蝉的生命周期都是素数,这样可以使得天敌在其生命周期的分布尽可能地均匀,这样才有利于蝉作为一个物种的繁衍生息. 双向平方探测用4k+3的素数(双平方定理)证明这里用的是反证法,n%M=0,n同时可以整除M的平方.","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"/tags/数据结构/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"零次学习入门","slug":"零次学习入门","date":"2019-09-18T10:51:52.000Z","updated":"2019-09-18T10:55:01.650Z","comments":true,"path":"2019/09/18/零次学习入门/","link":"","permalink":"/2019/09/18/零次学习入门/","excerpt":"","text":"原文链接 很久没有更文章了，主要是没有找到zero-shot learning(ZSL)方面我特别想要分享的文章，且中间有一段时间在考虑要不要继续做这个题目，再加上我懒 (￢_￢)，所以一直拖到了现在。最近科研没什么进展，就想着写一个ZSL的入门性的文章，目的是为了帮助完全没有接触过这方面，并有些兴趣的同学，能在较短的时间对ZSL有一定的认识，并且对目前的发展情况有一定的把握。在此之前，需要提到的是：无论是论文笔记，还是总结性的读物，都包含了作者自己的理解和二次加工，想要做出好的工作必定需要自己看论文和总结。零次学习（zero-shot learning）基本概念每次在实验室做工作汇报的时候，总会把ZSL的基本概念讲一遍，但是每次的效果都不是很好，工作都讲完了，提的第一个问题依然是：ZSL到底是什么？这让我一度认为我的表达能力有问题。。。。。。不过回忆起我第一次接触这个题目的时候，也花了挺长的时间才搞清楚到底在做一件什么事情，那篇入门的文章[1]看了很久才基本看懂。因此，我尽量用最简单的，不带任何公式的方式来讲一下这到底是个什么问题。假设小暗（纯粹因为不想用小明）和爸爸，到了动物园，看到了马，然后爸爸告诉他，这就是马；之后，又看到了老虎，告诉他：“看，这种身上有条纹的动物就是老虎。”；最后，又带他去看了熊猫，对他说：“你看这熊猫是黑白色的。”然后，爸爸给小暗安排了一个任务，让他在动物园里找一种他从没见过的动物，叫斑马，并告诉了小暗有关于斑马的信息：“斑马有着马的轮廓，身上有像老虎一样的条纹，而且它像熊猫一样是黑白色的。”最后，小暗根据爸爸的提示，在动物园里找到了斑马（意料之中的结局。。。）。上述例子中包含了一个人类的推理过程，就是利用过去的知识（马，老虎，熊猫和斑马的描述），在脑海中推理出新对象的具体形态，从而能对新对象进行辨认。（如图1所示）ZSL就是希望能够模仿人类的这个推理过程，使得计算机具有识别新事物的能力。图1 ZSL概念图[17]如今深度学习非常火热，使得纯监督学习在很多任务上都达到了让人惊叹的结果，但其限制是：往往需要足够多的样本才能训练出足够好的模型，并且利用猫狗训练出来的分类器，就只能对猫狗进行分类，其他的物种它都无法识别。这样的模型显然并不符合我们对人工智能的终极想象，我们希望机器能够像上文中的小暗一样，具有通过推理，识别新类别的能力。ZSL就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。这样的能力听上去很具有吸引力，那么到底是怎么实现的呢？假设我们的模型已经能够识别马，老虎和熊猫了，现在需要该模型也识别斑马，那么我们需要像爸爸一样告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。所以模型需要知道的信息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。将其转换为常规的机器学习，这里我们只讨论一般的图片分类问题：（1）训练集数据 及其标签 ，包含了模型需要学习的类别（马、老虎和熊猫），这里和传统的监督学习中的定义一致；（2）测试集数据 及其标签 ，包含了模型需要辨识的类别（斑马），这里和传统的监督学习中也定义一直；（3）训练集类别的描述 ，以及测试集类别的描述 ；我们将每一个类别 ，都表示成一个语义向量 的形式，而这个语义向量的每一个维度都表示一种高级的属性，比如“黑白色”、“有尾巴”、“有羽毛”等等，当这个类别包含这种属性时，那在其维度上被设置为非零值。对于一个数据集来说，语义向量的维度是固定的，它包含了能够较充分描述数据集中类别的属性。在ZSL中，我们希望利用 和 来训练模型，而模型能够具有识别 的能力，因此模型需要知道所有类别的描述 和 。ZSL这样的设置其实就是上文中小暗识别斑马的过程中，爸爸为他提供的条件。图2 ZSL设置图[16]如图2，可以较为直观地了解ZSL的设置。讲到这，很多同学可能会问：（1）类别的描述 到底是怎么获取的？答：有人工专家定义的，也有通过海量的附加数据集自动学习出来的，但前者的效果目前要好很多。（2）这样做让人觉得有点失望呀！我希望模型能够在没有斑马样本的情况下，识别斑马，而现在，虽然我不需要为模型提供斑马的样本，但是却要为每一个类别添加一种描述，更离谱的是我还需要斑马（测试集）的描述，这个过程并没有想象中智能诶！答：的确，在我们的想象中，我们期待的智能是：只给机器马、老虎和熊猫，然后它就可以识别斑马了，这样多爽，多神奇。但我们回过头去，再想想小暗的思考过程，如果爸爸不告诉小暗关于斑马的任何信息，那么当小暗看见斑马的时候，并不会知道它是什么，只是小暗能够描述它：“这是一匹有着黑白颜色条纹的马。”这里，有同学可能又会说：至少我们可以不用告诉小暗类别的描述呀，但是ZSL就不行。其实，我们是需要告诉小暗类别描述的，或者说小暗在之前就学习到了类别描述，比如怎样的图案是“条纹”，怎样的颜色称为“黑白色”，这样的属性定义。对于一个模型来说，它就像刚出生的婴儿，我们需要教会它这些属性的定义。（3）就算是这样，需要实现定义这个描述 还是很蛋疼的一件事情。答：（1）中就有提到，描述 可以自动学习，我们将小暗已经掌握的知识描述为一个知识库，这个知识库里就有对各种属性的定义；而能够模仿人类知识库的最好东西就是“百度百科”，“维基百科”等等各种百科，我们可以利用百科中的各种定义，生成类别的定义，这方面侧重于NLP，因此不进一步讨论。在此，我们小小总结一下ZSL问题的定义。利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效。目前的研究方式在上文中提到，要实现ZSL功能似乎需要解决两个部分的问题：第一个问题是获取合适的类别描述 ；第二个问题是建立一个合适的分类模型。目前大部分工作都集中在第二个问题上，而第一个问题的研究进展比较缓慢。个人认为的原因是， 目前 的获取主要集中于一些NLP的方法，而且难度较大；而第二个问题能够用的方法较多，比较容易出成果。因此，接下来的算法部分，也只介绍研究分类模型的方法。数据集介绍先介绍数据集，是因为希望在算法介绍部分，直接给出实例，让大家能够直接上手，这里顺便插个沐神 李沐 的感悟。虽然在我认识的人里，好些人能够读一篇论文或者听一个报告后就能问出很好的问题，然后就基本弄懂了。但我在这个上笨很多。读过的论文就像喝过的水，第二天就不记得了。一定是需要静下心来，从头到尾实现一篇，跑上几个数据，调些参数，才能心安地觉得懂了。例如在港科大的两年读了很多论文，但现在反过来看，仍然记得可能就是那两个老老实实动手实现过写过论文的模型了。即使后来在机器学习这个方向又走了五年，学习任何新东西仍然是要靠动手。——李沐（MXNet开发者）（1）Animal with Attributes（AwA）官网：Animals with Attributes提出ZSL定义的作者，给出的数据集，都是动物的图片，包括50个类别的图片，其中40个类别作为训练集，10个类别作为测试集，每个类别的语义为85维，总共有30475张图片。但是目前由于版权问题，已经无法获取这个数据集的图片了，作者便提出了AwA2，与前者类似，总共37322张图片。（2）Caltech-UCSD-Birds-200-2011（CUB）官网：Caltech-UCSD Birds-200-2011全部都是鸟类的图片，总共200类，150类为训练集，50类为测试集，类别的语义为312维，有11788张图片。（3）Sun database（SUN）官网：SUN Database总共有717个类别，每个类别20张图片，类别语义为102维。传统的分法是训练集707类，测试集10类。（4）Attribute Pascal and Yahoo dataset（aPY）官网：Describing Objects by their Attributes共有32个类，其中20个类作为训练集，12个类作为测试集，类别语义为64维，共有15339张图片。（5）ILSVRC2012/ILSVRC2010（ImNet-2）利用ImageNet做成的数据集，由ILSVRC2012的1000个类作为训练集，ILSVRC2010的360个类作为测试集，有254000张图片。它由 4.6M 的Wikipedia数据集训练而得到，共1000维。上述数据集中（1）-（4）都是较小型（small-scale）的数据集，（5）是大型（large-scale）数据集。虽然（1）-（4）已经提供了人工定义的类别语义，但是有些作者也会从维基语料库中自动提取出类别的语义表示，来检测自己的模型。这里给大家提供一些已经用GoogleNet提取好的数据集图片特征，大家可以比较方便地使用。Zero-Shot Learing问题数据集分享（GoogleNet 提取）基础算法介绍在此，只具体介绍最简单的方法，让大家可以快速上手。我们面对的是一个图片分类问题，即对测试集的样本 进行分类，而我们分类时需要借助类别的描述 ，由于每一个类别 ，都对应一个语义向量 ，因此我们现在可以忘掉 ，直接使用 。我们把 （利用深度网络提取的图片特征，比如GoogleNet提取为1024维）称为特征空间（visual feature space），把类别的语义表示 ，称为语义空间。我们要做的，其实就是建立特征空间与语义空间之间的映射。对于分类，我们能想到的最简单的形式就是岭回归（ridge regression），俗称均方误差加范数约束，具体形式为： (1)其中， 通常为2范数约束， 为超参，对 求导，并让导为0，即可求出 的值。测试时，利用 将 投影到语义空间中，并在该空间中寻找到离它最近的 ，则样本的类别为 所对应的标签 。简单写一个matlab实现。regression_lambda = 1.0;W = ridge_regression(param.train_set, param.train_class_attributes, regression_lambda , 1024);S_test = param.test_set W;[zsl_accuracy]= zsl_el(S_test, param.S_te, param);fprintf(‘AwA ZSL accuracy on test set: %.1f%%\\n’, zsl_accuracy100);我们使用AwA数据集，图片事先利用GoogleNet提取了特征（1024维），在测试集上可以得到59.1%的准确率。这样一个岭回归之所以有效，是因为训练集类别语义 与测试集类别语义 之间存在的密切联系。其实任何ZSL方法有效的基础，都是因为这两者之间具体的联系。仅仅利用如此naive的方式，得到的结果显然不能满足我们的要求，那么建立更好的模型，则需要进一步了解ZSL问题中，存在着哪些和传统监督分类的差异。ZSL中存在的问题在此，介绍一些目前ZSL中主要存在的问题，以便让大家了解目前ZS领域有哪些研究点。领域漂移问题（domain shift problem）该问题的正式定义首先由[2]提出。简单来说，就是同一种属性，在不同的类别中，视觉特征的表现可能很大。如图3所示，斑马和猪都有尾巴，因此在它的类别语义表示中，“有尾巴”这一项都是非0值，但是两者尾巴的视觉特征却相差很远。如果斑马是训练集，而猪是测试集，那么利用斑马训练出来的模型，则很难正确地对猪进行分类。图3 domain shift示意图，图中的prototype表示类别在语义空间中的位置[2]枢纽点问题（Hubness problem）这其实是高维空间中固有的问题：在高维空间中，某些点会成为大多数点的最近邻点。这听上去有些反直观，细节方面可以参考[3]。由于ZSL在计算最终的正确率时，使用的是K-NN，所以会受到hubness problem的影响，并且[4]中，证明了基于岭回归的方法会加重hubness problem问题。语义间隔（semantic gap）样本的特征往往是视觉特征，比如用深度网络提取到的特征，而语义表示却是非视觉的，这直接反应到数据上其实就是：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。（如图4所示）图4 流型不一致示意图[8]这使得直接学习两者之间的映射变得困难。还有其他的，比如semantic loss[5]问题，样本通过映射坍塌到一点[6]等，由于还不常研究，在此就不再讨论。在此，我们给出解决上述三个问题的基本方法，从而更加深度地了解这三个问题。（1）领域漂移由于样本的特征维度往往比语义的维度大，所以建立从 到 的映射往往会丢失信息，为了保留更多的信息，保持更多的丰富性，最流行的做法是将映射到语义空间中的样本，再重建回去，这样学习到的映射就能够得到保留更多的信息。因此，在原来简单岭回归[1]的基础上，可以将目标函数改为：[7] (2)从目标函数可以看出，这其实完成的是一个简易的自编码器过程，我们简称这个算法为SAE，利用matlab可以轻松对其实现。lambda1 = 800000;W = SAE(param.train_set‘, param.train_class_attributes’, lambda1);S_test = param.test_set NormalizeFea(W‘);[zsl_accuracy]= zsl_el(S_test, param.S_te, param);fprintf(‘AwA ZSL accuracy on test set: %.1f%%\\n’, zsl_accuracy100);依然是在AwA上进行测试，可以得到83.2%的准确率，比简单的岭回归(1)提高了24.1%。自编码器的这个结构目前在ZSL方法中非常流行，稍后我们还会提到。（2）枢纽点问题目前对于枢纽点问题的解决主要有两种方法：a. 如果模型建立的方式为岭回归，那么可以建立从语义空间到特征空间的映射，从而不加深hubness problem对结果的影响[4]，也就是说将目标函数（1）改为： (3)在AwA数据集上，这种简单的改变能够得到76.5%的正确率，比原本提高了17.4%。b.可以使用生成模型，比如自编码器、GAN等，生成测试集的样本，这样就变成了一个传统的监督分类问题，不存在K-NN的操作，所以不存在hubness problem的影响。（3）语义间隔问题语义间隔问题的本质是二者的流形结构不一致，因此，解决此问题的着手点就在于将两者的流形调整到一致，再学习两者之间的映射[8]。最简单的方法自然是将类别的语义表示调整到样本的流型上，即用类别语义表示的K近邻样本点，重新表示类别语义即可。有关ZSL的一些其他的概念这里将提到一些ZSL涉及到的其他概念。（1）直推式学习（Transductive setting）这里的直推式学习其实是指在训练模型的时候，我们可以拿到测试集的数据，只是不能拿到测试集的样本的标签，因此我们可以利用测试集数据，得到一些测试集类别的先验知识。这种设置在迁移学习中很常见。图5 非直推式（inductive）和直推式学习的区别[16]（2）泛化的ZSL（generalized ZSL）上文中提到的ZSL，在测试时使用K-NN进行正确率的评估时，只在测试类别中找最近邻的类别，但是在现实的问题中，拿到的样本也可能属于训练集类别，因此在测试时，同时加入训练集类别。[9]现在的很多方法都开始测试模型在这种设置下的能力。推荐阅读的论文我一直不想写ZSL的发展史，因为据我的经验，写了一大段发展史之后，往往大家的兴致不高，而且看完之后一般都不会有什么特别的感觉，基本也记不得什么东西。所以倒不如给大家推荐一些论文，从最早的到目前最新的，使得大家在短时间内能对ZSL的发展有一个大概的概念。（1）Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer[1]ZSL问题的开创性文章，当然是必读的喽，而且可以顺便看看别人是如何阐述一个新问题（挖坑）的。（2）An embarrassingly simple approach to zero-shot learning[10]有着很强的理论基础，算法简单、有效，虽然已经过去很多年了，但还是目前新工作需要进行对比的方法之一。（3）Transductive Multi-View Zero-Shot Learning[2]第一次定义了domain shift问题。（4）Zero-shot recognition using dual visualsemantic mapping paths[11]解决semantic gap问题的简单做法。（5）Predicting visual exemplars of unseen classes for zero-shot learning[12]从本质的角度出发，将ZSL问题，看作聚类问题，用最简单的方法直接建立映射。（6）Semantic Autoencoder for Zero-Shot Learning[7]引入自编码器结构的第一篇文章，直接导致现在出现的新方法大都具有这种结构。（7）Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly[14]综述性的文章，总结了17年底以前的方法，提出了新的评价标准，对当时领域发展比较混乱的地方做出了一些更标准的评估。（8）Zero-Shot Learning via Class-Conditioned Deep Generative Models[6]将[7]改造为深度模型，并加上一些其他的约束。（9）Preserving Semantic Relations for Zero-Shot Learning[13]在自编码器结构的基础上，显示地加入语义类别之间的关系约束。（10）Recent Advances in Zero-shot Recognition[15]综述性的文章，读起来很顺畅，可以看看别人是怎么写综述，中顶刊的。以上几篇文章，是我认为较有代表性，比较值得读的工作。代码有很多工作，作者都是提供代码的，我自己也实现了一些工作，如果有时间我会将其整理在一起，方便大家使用。我自己的看法我当初做这个课题，纯粹是因为项目的需要，再加上当时并没有想清楚自己要做什么，所以就做着试试了。目前这个领域属于很好发论文的阶段，而且并不需要十分深刻的理解，就能发不错等级的文章，比较容易能够看到它的发展趋势及下一步大家扎堆的地方，很多时候是在拼速度，而不是拼想法。但好发论文，并不代表它发展迅速，在我看来，真正有贡献的工作少之又少，且其对本质的研究发展缓慢。并且，该问题离实际应用还太远，很可能并不属于这个时代。基于这些原因，之前有一段时间很不想再继续这个课题。。。总结稍微总结一下，其实我也不知道要总结什么，只是习惯了每篇文章最后都要写个总结。花了大概一天的时间，写了这篇ZSL入门文章。写它一方面是因为希望能够有一篇ZSL的入门性质的读物，为大家提供便利；另一方面就是近期科研不顺，总是怀疑自己不是读书的料，写写文章让自己心情好些。希望大家阅读之后，能够得到一定的帮助吧！其他文章仓促之下写的，没有经过什么构思，就是想到哪，写到哪。后面我应该还会修改，添加一些其他的内容，如果大家有什么问题，欢迎评论或者私信。祝大家科研顺利！为人类理解这个世界做一点点贡献！参考文献[1]Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer[2]Transductive Multi-View Zero-Shot Learning.[3]Hubness and Pollution: Delving into Class-Space Mapping for Zero-Shot Learning.[4]Ridge Regression, Hubness, and Zero-Shot Learning.[5]Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding Network.[6]Zero-Shot Learning via Class-Conditioned Deep Generative Models.[7]Semantic Autoencoder for Zero-Shot Learning.[8]Zero-Shot Recognition using Dual Visual-Semantic Mapping Paths.[9]An Empirical Study and Analysis of Generalized Zero-Shot Learning for Object Recognition in the Wild.[10]An embarrassingly simple approach to zero-shot learning[11]Zero-shot recognition using dual visualsemantic mapping paths[12]Predicting visual exemplars of unseen classes for zero-shot learning[13]Preserving Semantic Relations for Zero-Shot Learning[14]Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly[15]Recent Advances in Zero-shot Recognition[16]http://people.duke.edu/~ww107/material/ZSL.pdf[17]Attribute-Based Synthetic Network (ABS-Net): Learning More From Pseudo Feature Representation","categories":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}],"tags":[{"name":"迁移学习","slug":"迁移学习","permalink":"/tags/迁移学习/"},{"name":"零次学习","slug":"零次学习","permalink":"/tags/零次学习/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}]},{"title":"hexo部署到服务器","slug":"hexo部署到服务器","date":"2019-09-01T14:13:01.000Z","updated":"2019-09-01T14:19:19.615Z","comments":true,"path":"2019/09/01/hexo部署到服务器/","link":"","permalink":"/2019/09/01/hexo部署到服务器/","excerpt":"","text":"原来是部署到 github 和 coding 上的，访问速度较慢，并且图床 七牛云 自 2018年 7月起，测试域名的生命周期只有 30个自然日，这让维护博客造成了很大的麻烦，于是便准备使用服务器来进行部署了。部署环境本地环境Windows10(64bit)环境：git，Node.js，hexo…生成本地静态网站服务器环境腾讯云主机(CentOS 7.5 64bit)环境：git，Nginx，创建 git 用户使用 git 自动化部署发布服务器配置1. 安装 Git (源码包安装)因为 yum 源仓库的 Git 版本更新不及时，所以采用源码包进行安装。1.1 安装依赖包yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develyum install gcc perl-ExtUtils-MakeMaker12通过命令 git –version 可以看到，Git 当前的版本号为 1.8.3.1，太过于陈旧，所以需要先把它移除了。1.2 卸载旧版本的 Gityum remove git11.3 下载并解压cd /usr/local/src // 选择文件保存位置wget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.19.0.tar.gz // 下载链接tar -zxvf git-2.19.0.tar.gz // 解压123git-2.19.0.tar.gz 是目前最新版本，其他版本以及之后版本可到此进行查看。解压后，会在当前目录下自动生成一个名为 git-2.19.0 的文件夹，里面就是解压出来的文件。可通过命令 ls 进行查看。1.4 编译安装cd git-2.19.0 // 进入文件夹make prefix=/usr/local/git all // 编译源码make prefix=/usr/local/git install // 安装至 /usr/local/git 路径123编译时，由机器配置决定速度，请耐心等待。打开环境变量配置文件。vim /etc/profile1在文件底部添加以下配置。PATH=$PATH:/usr/local/git/bin // git 的目录export PATH12两个语句都要加上。刷新环境变量。source /etc/profile1最后再使用 git –version 查看版本号，已经为 2.19.0。2. git 新用户及配置2.1 创建 git 用户adduser gitpasswd gitchmod 740 /etc/sudoersvim /etc/sudoers1234找到以下内容。## Allow root to run any commands anywhereroot ALL=(ALL) ALL12在它下面添加一行。git ALL=(ALL) ALL1保存并退出，将权限修改回来。chmod 400 /etc/sudoers12.2 密钥配置本地中，使用 Git Bash 创建密钥。# 本地 windows gitBashssh-keygen -t rsa12一路回车，直至如下图，即可。切换至 git 用户，创建 .ssh 文件夹以及 authorized_keys 文件并将本地的 id_rsa.pub 文件内容粘贴到里面。su gitmkdir ~/.sshvim ~/.ssh/authorized_keys123修改权限。cd ~chmod 600 .ssh/authorzied_keyschmod 700 .ssh1232.3 测试在本地 Windows 上，使用 Git Bash 测试是否能连接上服务器。ssh -v git@SERVER1其中 SERVER 为服务器 ip 地址。若出现以下错误提示，检查本地密钥位置是否存在 known_hosts 文件，将其删除重新测试。测试结果为，不需要密码直接进入。错误提示：2.4 创建网站目录创建一个目录用于作为网站的根目录。su rootmkdir /home/hexo # 此目录为网站的根目录12赋予权限。chown git:git -R /home/hexo13. 安装配置 Nginx注意需要 root 权限yum install -y nginx // 安装systemctl start nginx.service // 启动服务12使用 yum 安装的 nginx 在新版的 CentOS 中，需要使用 systemctl，而不是直接使用 service start nginx此时通过服务器的公网 IP 地址访问，可以看到 nginx 的欢迎页面，表示安装成功，如下图:3.2 配置 Nginx使用 nginx -t 命令查看位置，一般为 /etc/nginx/nginx.conf。使用 vim /etc/nginx/nginx.conf 命令进行编辑，修改配置文件如下：server { listen 80 default_server; listen [::]:80 default_server; server_name staunchkai.com; # 修改为自己的域名 root /home/hexo; # 修改为网站的根目录 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { }}1234567891011121314151617181920root 处的网站目录，需要自己创建，也就是部署上传的位置。注意使用 nginx -t 命令检查配置文件的语法是否出错。然后使用 systemctl restart nginx.service 命令重启服务即可。4. 自动化部署4.1 建立 git 裸库创建一个裸仓库，裸仓库就是只保存 git 信息的 Repository, 首先切换到 git 用户确保 git 用户拥有仓库所有权，一定要加 –bare，这样才是一个裸库。su rootcd /home/git # 在 git 用户目录下创建git init –bare blog.git123这时，git 用户的 ~ 目录下就存在一个 blog.git 文件夹，可使用 ls 命令查看。再修改 blog.git 的权限。chown git:git -R blog.git14.2 使用 git-hooks 同步网站根目录在这使用的是 post-receive 这个钩子，当 git 有收发的时候就会调用这个钩子。 在 blog.git 裸库的 hooks 文件夹中，新建 post-receive 文件。vim blog.git/hooks/post-receive1填入以下内容，其中 /home/hexo 为网站目录，根据自己的填入,保存退出。#!/bin/shgit –work-tree=/home/hexo –git-dir=/home/git/blog.git checkout -f12保存后，要赋予这个文件可执行权限。chmod +x /home/git/blog.git/hooks/post-receive1本地配置在本地中，和部署到 pages 服务一样，需要先 hexo g 命令生成静态文件，通过 hexo s 命令能够正常进行本地访问，并且确保已经安装了 hexo-deployer-git。配置 _config.ymlhexo 根目录下的 _config.yml 文件，找到 deploy。deploy: type: git repo: git@SERVER:/home/git/blog.git # repository url branch: master # 分支1234之后按照正常的流程进行部署即可。hexo cleanhexo ghexo d123常见错误git-receive-pack: 未找到命令hexo dbash: git-receive-pack: command not foundfatal: Could not read from remote repository.123解决办法：sudo ln -s /usr/local/git/bin/git-receive-pack /usr/bin/git-receive-pack1git-upload-pack: 未找到命令正克隆到 ‘blog’…bash: git-upload-pack: command not foundfatal: Could not read from remote repository.123解决办法：sudo ln -s /usr/local/git/bin/git-upload-pack /usr/bin/git-upload-pack1不是一个 git 仓库fatal: ‘XXXX/blog.git’ does not appear to be a git repositoryfatal: Could not read from remote repository.12解决办法：确保 _config.yml 文件中 deploy 处的 repo 路径填写正确。","categories":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}],"tags":[{"name":"技术","slug":"技术","permalink":"/tags/技术/"},{"name":"hexo","slug":"hexo","permalink":"/tags/hexo/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}]},{"title":"拉格朗日乘数法","slug":"拉格朗日乘数法","date":"2019-08-28T07:36:47.000Z","updated":"2019-09-01T13:15:40.167Z","comments":true,"path":"2019/08/28/拉格朗日乘数法/","link":"","permalink":"/2019/08/28/拉格朗日乘数法/","excerpt":"","text":"转自知乎-在高中的学习中，有哪一瞬间你觉得自己真正懂了一个对高考卷解题有大用的东西？ 14.若实数x，y满足，则当取得最大值时，的最大值为_【解析】首先我们设一个乘数λ，设函数.这是一个二元函数，但如果我们可以把y看作常数，x看作自变量，求导，并令导数等于0：……①同理，我们把x看作常数，y看作自变量，求导：……②观察这两个式子，让我们把乘数λ消掉：①②得，如果我们把带入，同样能得到；因此，.（偷偷看了一下答案，嗯，没算错）理论上是要检验存在性，但是高考填空题答案显然不可能不存在。（如果不存在，那是老师出错题目了）","categories":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}],"tags":[{"name":"数学","slug":"数学","permalink":"/tags/数学/"},{"name":"机器学习","slug":"机器学习","permalink":"/tags/机器学习/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}]},{"title":"朴素贝叶斯为何“朴素”？","slug":"朴素贝叶斯为何_朴素__","date":"2019-08-28T07:36:47.000Z","updated":"2019-09-01T13:14:24.072Z","comments":true,"path":"2019/08/28/朴素贝叶斯为何_朴素__/","link":"","permalink":"/2019/08/28/朴素贝叶斯为何_朴素__/","excerpt":"","text":"朴素贝叶斯（naive Bayes classifiers）是一种分类器，在机器学习中有着广泛的应用。相信很多人知道贝叶斯定理,即&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;所以，当我们有一组事件，我们想通过这组事件去估计一个事件C发生的概率，比如我们想估计水果的种类，如果有一组事件分别 黄，长，弯…那我们就可以判断这是一个香蕉。 尽管黄，长，弯几个事件之间可能会相互依赖，但是在朴素贝叶斯模型中，我们假设它们相互独立，这就是他的朴素之处。值得注意的是，这里的朴素对应英语单词naive，单纯的意思，所以也可以理解为很天真单纯的估计（把数据中的每个特征看作独立分布）。&nbsp;OK，现在我们具体看一下朴素贝叶斯的概率模型，其实就是一个条件概率的模型，在发生的条件下去估计事件C的概率，即计算&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;根据贝叶斯定理，我们有&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;我们可以看到, 如果每个特征F的取值至少有两个，然后有100个特征，那给定一组数据后，想要计算是几乎不可能的，因为你的联合分布中有种可能，这样计算机是无法扫描完所有的概率空间的，即使可以，在会出现大量的0（即不存在的某种组合）。为了解决这个问题，我们假设所有特征F之间相互独立，这样一来，我们的等式，即可写成&nbsp; &nbsp; 这样即可算出我们想要的结果。","categories":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}],"tags":[{"name":"数学","slug":"数学","permalink":"/tags/数学/"},{"name":"机器学习","slug":"机器学习","permalink":"/tags/机器学习/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}]},{"title":"莫烦-强化学习-DDPO","slug":"莫烦-强化学习-DPPO","date":"2019-08-24T13:24:02.000Z","updated":"2019-09-01T13:14:41.104Z","comments":true,"path":"2019/08/24/莫烦-强化学习-DPPO/","link":"","permalink":"/2019/08/24/莫烦-强化学习-DPPO/","excerpt":"","text":"本文转载自莫烦-强化学习-DPPOOpenAI:PPO 论文 Proximal Policy OptimizationGoogle DeepMind :DPPO 论文 Emergence of Locomotion Behaviours in Rich Environments 要点根据 OpenAI 的官方博客, PPO 已经成为他们在强化学习上的默认算法. 如果一句话概括 PPO: OpenAI 提出的一种解决 Policy Gradient 不好确定 Learning rate (或者 Step size) 的问题. 因为如果 step size 过大, 学出来的 Policy 会一直乱动, 不会收敛, 但如果 Step Size 太小, 对于完成训练, 我们会等到绝望. PPO 利用 New Policy 和 Old Policy 的比例, 限制了 New Policy 的更新幅度, 让 Policy Gradient 对稍微大点的 Step size 不那么敏感. 算法PPO 的前生是 OpenAI 发表的 Trust Region Policy Optimization, 但是 Google DeepMind 看过 OpenAI 关于 Trust Region Policy Optimization 的 conference 后, 却抢在 OpenAI 前面 (2017年7月7号) 把 Distributed PPO给先发布了. 我觉得 DeepMind 有点抢, 这让 OpenAI 有点难堪. 不过 OpenAI 还是在 2017年7月20号 发表了一份拿得出手的 PPO 论文 (估计是突然看到了 Google 抢了自己的东西, 所以赶紧把自己的也发了). OpenAI PPO 论文里给出的算法… 写得也太简单了 (注意他们这个 PPO 算法应该算是单线程的):看了上面的主结构, 觉得少了很多东西. 这让我直接跑去 DeepMind 的 Paper 看他们总结 OpenAI conference 上的 PPO 的代码:总的来说 PPO 是一套 Actor-Critic 结构, Actor 想最大化 J_PPO, Critic 想最小化 L_BL. Critic 的 loss 好说, 就是减小 TD error. 而 Actor 的就是在 old Policy 上根据 Advantage (TD error) 修改 new Policy, advantage 大的时候, 修改幅度大, 让 new Policy 更可能发生. 而且他们附加了一个 KL Penalty (惩罚项, 不懂的同学搜一下 KL divergence), 简单来说, 如果 new Policy 和 old Policy 差太多, 那 KL divergence 也越大, 我们不希望 new Policy 比 old Policy 差太多, 如果会差太多, 就相当于用了一个大的 Learning rate, 这样是不好的, 难收敛. 关于 DeepMind 在这篇 paper 中提出的 DPPO 算法, 和怎么样把 OpenAI 的 PPO 多线程. 我们之后在下面细说, 我们先把简单的 PPO 算法给实现. 简单 PPO 的主结构我们用 Tensorflow 搭建神经网络, tensorboard 中可以看清晰的看到我们是如果搭建的:图中的 pi 就是我们的 Actor 了. 每次要进行 PPO 更新 Actor 和 Critic 的时候, 我们有需要将 pi 的参数复制给 oldpi. 这就是 update_oldpi 这个 operation 在做的事. Critic 和 Actor 的内部结构, 我们不会打开细说了. 因为就是一堆的神经网络而已. 这里的 Actor 使用了 normal distribution 正态分布输出动作. 这个 PPO 我们可以用一个 Python 的 class 代替： class PPO(object): def __init__(self): # 建 Actor Critic 网络 # 搭计算图纸 graph def update(self, s, a, r): # 更新 PPO def choose_action(self, s): # 选动作 def get_v(self, s): # 算 state value 而这个 PPO 和 env 环境的互动可以简化成这样. ppo = PPO()for ep in range(EP_MAX): s = env.reset() buffer_s, buffer_a, buffer_r = [], [], [] for t in range(EP_LEN): env.render() a = ppo.choose_action(s) s_, r, done, _ = env.step(a) buffer_s.append(s) buffer_a.append(a) buffer_r.append((r+8)/8) # normalize reward, 发现有帮助 s = s_ # 如果 buffer 收集一个 batch 了或者 episode 完了 if (t+1) % BATCH == 0 or t == EP_LEN-1: # 计算 discounted reward v_s_ = ppo.get_v(s_) discounted_r = [] for r in buffer_r[::-1]: v_s_ = r + GAMMA * v_s_ discounted_r.append(v_s_) discounted_r.reverse() bs, ba, br = batch(buffer_s, buffer_a, discounted_r) # 清空 buffer buffer_s, buffer_a, buffer_r = [], [], [] ppo.update(bs, ba, br) # 更新 PPO 了解了这些更新步骤, 我们就来看看如何更新我们的 PPO. 我们更新 Critic 的时候是根据 刚刚计算的 discounted_r 和自己分析出来的 state value 这两者的差 (advantage). 然后最小化这个差值： class PPO: def __init__(self): self.advantage = self.tfdc_r - self.v # discounted reward - Critic 出来的 state value self.closs = tf.reduce_mean(tf.square(self.advantage)) self.ctrain_op = tf.train.AdamOptimizer(C_LR).minimize(self.closs) 在更新 Actor 的时候, 其实有两种方式, 一种是用之前提到的 KL penalty 来更新.我在代码中也写上的这种方式的计算图纸要怎么搭, 不过还有一种是 OpenAI 在 PPO 这篇 paper 中提到的 clipped surrogate objective, surrogate objective 就是这个 surrogate. 他们实验中得出的结论说: clipped surrogate objective 要比 KL penalty 形式好. 那 clipped surrogate objective 到底是什么呢? 其实就是限制了 surrogate 的变化幅度, 和 KL 的规则差不多.这里的 r(theta) 是 (New Policy/Old Policy) 的比例, 和前面的公式一样. class PPO: def __init__(self): self.tfa = tf.placeholder(tf.float32, [None, A_DIM], &apos;action&apos;) self.tfadv = tf.placeholder(tf.float32, [None, 1], &apos;advantage&apos;) with tf.variable_scope(&apos;loss&apos;): with tf.variable_scope(&apos;surrogate&apos;): ratio = pi.prob(self.tfa) / oldpi.prob(self.tfa) surr = ratio * self.tfadv # surrogate objective if METHOD[&apos;name&apos;] == &apos;kl_pen&apos;: # 如果用 KL penatily self.tflam = tf.placeholder(tf.float32, None, &apos;lambda&apos;) kl = kl_divergence(oldpi, pi) self.kl_mean = tf.reduce_mean(kl) self.aloss = -(tf.reduce_mean(surr - self.tflam * kl)) else: # 如果用 clipping 的方式 self.aloss = -tf.reduce_mean(tf.minimum( surr, tf.clip_by_value(ratio, 1.-METHOD[&apos;epsilon&apos;], 1.+METHOD[&apos;epsilon&apos;])*self.tfadv)) with tf.variable_scope(&apos;atrain&apos;): self.atrain_op = tf.train.AdamOptimizer(A_LR).minimize(self.aloss) 好了, 接下来就是最重要的更新 PPO 时间了.注意的是, 这个 update 的步骤里, 我们用 for loop 更新了很多遍 Actor 和 Critic, 在 loop 之前, pi 和 old pi 是一样的, 每次 loop 的之后, pi 会变动, 而 old pi 不变, 这样这个 surrogate 就会开始变动了. 这就是 PPO 的精辟. class PPO: def update(self, s, a, r): # 先要将 oldpi 里的参数更新 pi 中的 self.sess.run(self.update_oldpi_op) # 更新 Actor 时, kl penalty 和 clipping 方式是不同的 if METHOD[&apos;name&apos;] == &apos;kl_pen&apos;: # 如果用 KL penalty for _ in range(A_UPDATE_STEPS): _, kl = self.sess.run( [self.atrain_op, self.kl_mean], &#123;self.tfs: s, self.tfa: a, self.tfadv: adv, self.tflam: METHOD[&apos;lam&apos;]&#125;) # 之后根据 kl 的值, 调整 METHOD[&apos;lam&apos;] 这个参数 else: # 如果用 clipping 的方法 [self.sess.run(self.atrain_op, &#123;self.tfs: s, self.tfa: a, self.tfadv: adv&#125;) for _ in range(A_UPDATE_STEPS)] # 更新 Critic 的时候, 他们是一样的 [self.sess.run(self.ctrain_op, &#123;self.tfs: s, self.tfdc_r: r&#125;) for _ in range(C_UPDATE_STEPS)] 最后我们看一张学习的效果图：接下来我们看看怎么样把这个单线程的 PPO 变到多线程去 (Distributed PPO). Distributed PPOGoogle DeepMind 提出来了一套和 A3C类似的并行 PPO 算法. 看了他们 paper 中的这个 DPPO 算法后, 我觉得….不好编! 取而代之, 我觉得如果采用 OpenAI 的思路, 用他那个 “简陋” 伪代码, 但是弄成并行计算倒是好弄点. 所以我就结合了 DeepMind 和 OpenAI, 取他们的精华, 写下了这份 DPPO 的代码. 总结一下我是怎么写的. 用 OpenAI 提出的 Clipped Surrogate Objective 使用多个线程 (workers) 平行在不同的环境中收集数据 workers 共享一个 Global PPO workers 不会自己算 PPO 的 gradients, 不会像 A3C 那样推送 Gradients 给 Global net workers 只推送自己采集的数据给 Global PPO Global PPO 拿到多个 workers 一定批量的数据后进行更新 (更新时 worker 停止采集) 更新完后, workers 用最新的 Policy 采集数据 不过有些细节我想提前提一下, 方便你们 看代码： 我用到了 python threading 当中的 Event 功能, 用来控制 PPO 的更新时间和 worker 停止工作的时间 使用了 threading 中的 Queue 来存放 worker 收集的数据, 发现用 python 的列表也可以达到一样效果, 计算时间上没太多差别. 更新 PPO 的时候, 我采用的是 DeepMind 的 for loop 形式.","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"/tags/强化学习/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"莫烦-强化学习-A3C","slug":"莫烦-强化学习-A3C","date":"2019-08-24T13:24:02.000Z","updated":"2019-09-01T13:14:02.483Z","comments":true,"path":"2019/08/24/莫烦-强化学习-A3C/","link":"","permalink":"/2019/08/24/莫烦-强化学习-A3C/","excerpt":"","text":"本文转载自莫烦-强化学习-A3C相关论文：Asynchronous Methods for Deep Reinforcement Learning 今天我们会来说说强化学习中的一种有效利用计算资源, 并且能提升训练效用的算法, Asynchronous Advantage Actor-Critic, 简称 A3C. 什么是 Asynchronous Advantage Actor-Critic (A3C)平行宇宙我们先说说没什么关系的,大家知道平行宇宙这回事. 想像现在有三个平行宇宙, 那么就意味着这3个平行宇宙上存在3个你, 而你可能在电脑前呆了很久, 对, 说的就是你! 然后你会被我催促起来做运动~ 接着你 和 你 还有 你, 就无奈地在做着不同的运动, 油~ 我才不想知道你在做什么样的运动呢. 不过这3个你 都开始活动胫骨啦. 假设3个你都能互相通信, 告诉对方, “我这个动作可以有效缓解我的颈椎病”, “我做那个动作后, 腰就不痛了 “, “我活动了手臂, 肩膀就不痛了”. 这样你是不是就同时学到了对身体好的三招. 这样是不是感觉特别有效率. 让你看看更有效率的, 那就想想3个你同时在写作业, 一共3题, 每人做一题, 只用了1/3 的时间就把作业做完了. 感觉棒棒的. 哈, 你看出来了, 如果把这种方法用到强化学习, 岂不是 “牛逼lity”.平行训练这就是传说中的 A3C.A3C 其实只是这种平行方式的一种而已, 它采用的是我们之前提到的 Actor-Critic 的形式. 为了训练一对 Actor 和 Critic, 我们将它复制多份红色的, 然后同时放在不同的平行宇宙当中, 让他们各自玩各的. 然后每个红色副本都悄悄告诉黑色的 Actor-Critic 自己在那边的世界玩得怎么样, 有哪些经验值得分享. 然后还能从黑色的 Actor-Critic 这边再次获取综合考量所有副本经验后的通关秘籍. 这样一来一回, 形成了一种有效率的强化学习方式.多核训练我们知道目前的计算机多半是有双核, 4核, 甚至 6核, 8核. 一般的学习方法, 我们只能让机器人在一个核上面玩耍. 但是如果使用 A3C 的方法, 我们可以给他们安排去不同的核, 并行运算. 实验结果就是, 这样的计算方式往往比传统的方式快上好多倍. 那我们也多用用这样的红利吧. A3C一句话概括 A3C: Google DeepMind 提出的一种解决 Actor-Critic 不收敛问题的算法. 它会创建多个并行的环境, 让多个拥有副结构的 agent 同时在这些并行环境上更新主结构中的参数. 并行中的 agent 们互不干扰, 而主结构的参数更新受到副结构提交更新的不连续性干扰, 所以更新的相关性被降低, 收敛性提高. 算法A3C 的算法实际上就是将 Actor-Critic 放在了多个线程中进行同步训练. 可以想象成几个人同时在玩一样的游戏, 而他们玩游戏的经验都会同步上传到一个中央大脑. 然后他们又从中央大脑中获取最新的玩游戏方法. 这样, 对于这几个人, 他们的好处是: 中央大脑汇集了所有人的经验, 是最会玩游戏的一个, 他们能时不时获取到中央大脑的必杀招, 用在自己的场景中. 对于中央大脑的好处是: 中央大脑最怕一个人的连续性更新, 不只基于一个人推送更新这种方式能打消这种连续性. 使中央大脑不必有用像 DQN, DDPG 那样的记忆库也能很好的更新. 为了达到这个目的, 我们要有两套体系, 可以看作中央大脑拥有 global net 和他的参数, 每位玩家有一个 global net 的副本 local net, 可以定时向 global net 推送更新, 然后定时从 global net 那获取综合版的更新.如果在 tensorboard 中查看我们今天要建立的体系, 这就是你会看到的.W_0 就是第0个 worker, 每个 worker 都可以分享 global_net.如果我们调用 sync 中的 pull, 这个 worker 就会从 global_net 中获取到最新的参数.如果我们调用 sync 中的 push, 这个 worker 就会将自己的个人更新推送去 global_net. 主结构我们用 Tensorflow 搭建神经网络, 对于我们的 Actor, tensorboard 中可以看清晰的看到我们是如果搭建的:我们使用了 Normal distribution 来选择动作, 所以在搭建神经网络的时候, actor 这边要输出动作的均值和方差. 然后放入 Normal distribution 去选择动作. 计算 actor loss 的时候我们还需要使用到 critic 提供的 TD error 作为 gradient ascent 的导向. critic 很简单啦, 只需要得到他对于 state 的价值就好了. 用于计算 TD error. Actor Critic 网络其搭建的代码部分在这：这些只是在创建网络而已, worker 还有属于自己的 class, 用来执行在每个线程里的工作.# 这个 class 可以被调用生成一个 global net.# 也能被调用生成一个 worker 的 net, 因为他们的结构是一样的,# 所以这个 class 可以被重复利用.class ACNet(object): def __init__(self, globalAC=None): # 当创建 worker 网络的时候, 我们传入之前创建的 globalAC 给这个 worker if 这是 global: # 判断当下建立的网络是 local 还是 global with tf.variable_scope(&apos;Global_Net&apos;): self._build_net() else: with tf.variable_scope(&apos;worker&apos;): self._build_net() # 接着计算 critic loss 和 actor loss # 用这两个 loss 计算要推送的 gradients with tf.name_scope(&apos;sync&apos;): # 同步 with tf.name_scope(&apos;pull&apos;): # 更新去 global with tf.name_scope(&apos;push&apos;): # 获取 global 参数 def _build_net(self): # 在这里搭建 Actor 和 Critic 的网络 return 均值, 方差, state_value def update_global(self, feed_dict): # 进行 push 操作 def pull_global(self): # 进行 pull 操作 def choose_action(self, s): # 根据 s 选动作 Worker每个 worker 有自己的 class, class 里面有他的工作内容 work. class Worker(object): def __init__(self, name, globalAC): self.env = gym.make(GAME).unwrapped # 创建自己的环境 self.name = name # 自己的名字 self.AC = ACNet(name, globalAC) # 自己的 local net, 并绑定上 globalAC def work(self): # s, a, r 的缓存, 用于 n_steps 更新 buffer_s, buffer_a, buffer_r = [], [], [] while not COORD.should_stop() and GLOBAL_EP &lt; MAX_GLOBAL_EP: s = self.env.reset() for ep_t in range(MAX_EP_STEP): a = self.AC.choose_action(s) s_, r, done, info = self.env.step(a) buffer_s.append(s) # 添加各种缓存 buffer_a.append(a) buffer_r.append(r) # 每 UPDATE_GLOBAL_ITER 步 或者回合完了, 进行 sync 操作 if total_step % UPDATE_GLOBAL_ITER == 0 or done: # 获得用于计算 TD error 的 下一 state 的 value if done: v_s_ = 0 # terminal else: v_s_ = SESS.run(self.AC.v, &#123;self.AC.s: s_[np.newaxis, :]&#125;)[0, 0] buffer_v_target = [] # 下 state value 的缓存, 用于算 TD for r in buffer_r[::-1]: # 进行 n_steps forward view v_s_ = r + GAMMA * v_s_ buffer_v_target.append(v_s_) buffer_v_target.reverse() buffer_s, buffer_a, buffer_v_target = np.vstack(buffer_s), np.vstack(buffer_a), np.vstack(buffer_v_target) feed_dict = &#123; self.AC.s: buffer_s, self.AC.a_his: buffer_a, self.AC.v_target: buffer_v_target, &#125; self.AC.update_global(feed_dict) # 推送更新去 globalAC buffer_s, buffer_a, buffer_r = [], [], [] # 清空缓存 self.AC.pull_global() # 获取 globalAC 的最新参数 s = s_ if done: GLOBAL_EP += 1 # 加一回合 break # 结束这回合 Worker 并行工作这里才是真正的重点! Worker 的并行计算.with tf.device(&quot;/cpu:0&quot;): GLOBAL_AC = ACNet(GLOBAL_NET_SCOPE) # 建立 Global AC workers = [] for i in range(N_WORKERS): # 创建 worker, 之后在并行 workers.append(Worker(GLOBAL_AC)) # 每个 worker 都有共享这个 global ACCOORD = tf.train.Coordinator() # Tensorflow 用于并行的工具worker_threads = []for worker in workers: job = lambda: worker.work() t = threading.Thread(target=job) # 添加一个工作线程 t.start() worker_threads.append(t)COORD.join(worker_threads) # tf 的线程调度 我的电脑里可以建立 4个 worker, 也就可以把它们放在4个线程中并行探索更新. 最后的学习结果可以用这个获取 moving average 的 reward 的图来概括. multiprocessing + A3C除此之外, 我心里一直有一个疙瘩, 因为这个 A3C 中, 我用的是 python 的 threading, 懂 python 的朋友知道, threading 有 GIL, 运算速度是问题, 我的 CPU 都不是满格的. 我一直想把这个 A3C 代码移植去 multiprocessing, 提高效率. 但是 Tensorflow 的 session 就是和 multiprocessing 不兼容, Global Net 做不好. 怎么办? Distributed Tensorflow 是一个备选方案. 但是这个要求你是在计算机集群上做, 不然速度上还不如这个 threading 的 A3C. 这时, 我不爽了, 到在知乎上抱怨了一番. 和知友们聊了会, 然后我想出了下面这个方案. 和 Tensorflow 一样, 我做过一些 Pytorch 的教程, pytorch 也是做神经网络的. 但是它是支持 multiprocessing 的. 我专门开了一个 repo, 把 Pytorch + multiprocessing 的代码分享了出来. 这会儿, CPU 满格, 心情舒畅多了~","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"/tags/强化学习/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"莫烦-强化学习-Actor Critic","slug":"莫烦-强化学习-Actor Critic","date":"2019-08-24T12:39:03.000Z","updated":"2019-09-01T13:14:37.732Z","comments":true,"path":"2019/08/24/莫烦-强化学习-Actor Critic/","link":"","permalink":"/2019/08/24/莫烦-强化学习-Actor Critic/","excerpt":"","text":"Actor Critic本文转载自莫烦-强化学习-Actor Critic今天我们会来说说强化学习中的一种结合体 Actor Critic (演员评判家), 它合并了 以值为基础 (比如 Q learning) 和 以动作概率为基础 (比如 Policy Gradients) 两类强化学习算法. 为什么要有Actor和Critic？我们有了像 Q-learning 这么伟大的算法, 为什么还要瞎折腾出一个 Actor-Critic? 原来 Actor-Critic 的 Actor 的前生是 Policy Gradients, 这能让它毫不费力地在连续动作中选取合适的动作, 而 Q-learning 做这件事会瘫痪. 那为什么不直接用 Policy Gradients 呢? 原来 Actor Critic 中的 Critic 的前生是 Q-learning 或者其他的 以值为基础的学习法 , 能进行单步更新, 而传统的 Policy Gradients 则是回合更新, 这降低了学习效率. Actor和Critic的分工现在我们有两套不同的体系, Actor 和 Critic, 他们都能用不同的神经网络来代替 . 在 Policy Gradients 的影片中提到过, 现实中的奖惩会左右 Actor 的更新情况. Policy Gradients 也是靠着这个来获取适宜的更新. 那么何时会有奖惩这种信息能不能被学习呢? 这看起来不就是 以值为基础的强化学习方法做过的事吗. 那我们就拿一个 Critic 去学习这些奖惩机制, 学习完了以后. 由 Actor 来指手画脚, 由 Critic 来告诉 Actor 你的那些指手画脚哪些指得好, 哪些指得差, Critic 通过学习环境和奖励之间的关系, 能看到现在所处状态的潜在奖励, 所以用它来指点 Actor 便能使 Actor 每一步都在更新, 如果使用单纯的 Policy Gradients, Actor 只能等到回合结束才能开始更新.但是事物终有它坏的一面, Actor-Critic 涉及到了两个神经网络, 而且每次都是在连续状态中更新参数, 每次参数更新前后都存在相关性, 导致神经网络只能片面的看待问题, 甚至导致神经网络学不到东西. Google DeepMind 为了解决这个问题, 修改了 Actor Critic 的算法. 改进版 Deep Deterministic Policy Gradient (DDPG)将之前在电动游戏 Atari 上获得成功的 DQN 网络加入进 Actor Critic 系统中, 这种新算法叫做 Deep Deterministic Policy Gradient, 成功的解决的在连续动作预测上的学不到东西问题. 所以之后, 我们再来说说什么是这种高级版本的 Deep Deterministic Policy Gradient 吧. 一句话概括 Actor Critic 方法:结合了 Policy Gradient (Actor) 和 Function Approximation (Critic) 的方法. Actor 基于概率选行为, Critic 基于 Actor 的行为评判行为的得分, Actor 根据 Critic 的评分修改选行为的概率. Actor Critic 方法的优势: 可以进行单步更新, 比传统的 Policy Gradient 要快. Actor Critic 方法的劣势:取决于 Critic 的价值判断, 但是 Critic 难收敛, 再加上 Actor 的更新, 就更难收敛. 为了解决收敛问题, Google Deepmind 提出了 Actor Critic 升级版 Deep Deterministic Policy Gradient. 后者融合了 DQN 的优势, 解决了收敛难的问题. 我们之后也会要讲到 Deep Deterministic Policy Gradient. 不过那个是要以 Actor Critic 为基础, 懂了 Actor Critic, 后面那个就好懂了. 算法这套算法是在普通的 Policy gradient 算法上面修改的, 对这套算法打个比方如下:Actor 修改行为时就像蒙着眼睛一直向前开车, Critic 就是那个扶方向盘改变 Actor 开车方向的.或者说详细点, 就是 Actor 在运用 Policy Gradient 的方法进行 Gradient ascent 的时候, 由 Critic 来告诉他, 这次的 Gradient ascent 是不是一次正确的 ascent, 如果这次的得分不好, 那么就不要 ascent 那么多. 代码下面是Actor神经网络的结构接下来是Actor的代码结构：class Actor(object): def __init__(self, sess, n_features, n_actions, lr=0.001): # 用 tensorflow 建立 Actor 神经网络, # 搭建好训练的 Graph. def learn(self, s, a, td): # s, a 用于产生 Gradient ascent 的方向, # td 来自 Critic, 用于告诉 Actor 这方向对不对. def choose_action(self, s): # 根据 s 选 行为 a 下面是Critic神经网络的结构：下面是Critic的代码结构： class Critic(object): def __init__(self, sess, n_features, lr=0.01): # 用 tensorflow 建立 Critic 神经网络, # 搭建好训练的 Graph. def learn(self, s, r, s_): # 学习 状态的价值 (state value), 不是行为的价值 (action value), # 计算 TD_error = (r + v_) - v, # 用 TD_error 评判这一步的行为有没有带来比平时更好的结果, # 可以把它看做 Advantage return # 学习时产生的 TD_error Actor和Critic的学习方式Actor 想要最大化期望的 reward, 在 Actor Critic 算法中, 我们用 “比平时好多少” (TD error) 来当做 reward, 所以就是: with tf.variable_scope(&apos;exp_v&apos;): log_prob = tf.log(self.acts_prob[0, self.a]) # log 动作概率 self.exp_v = tf.reduce_mean(log_prob * self.td_error) # log 概率 * TD 方向with tf.variable_scope(&apos;train&apos;): # 因为我们想不断增加这个 exp_v (动作带来的额外价值), # 所以我们用过 minimize(-exp_v) 的方式达到 # maximize(exp_v) 的目的 self.train_op = tf.train.AdamOptimizer(lr).minimize(-self.exp_v) Critic 的更新很简单, 就是像 Q learning 那样更新现实和估计的误差 (TD error) 就好了.with tf.variable_scope(&apos;squared_TD_error&apos;): self.td_error = self.r + GAMMA * self.v_ - self.v self.loss = tf.square(self.td_error) # TD_error = (r+gamma*V_next) - V_evalwith tf.variable_scope(&apos;train&apos;): self.train_op = tf.train.AdamOptimizer(lr).minimize(self.loss) 每回合算法for i_episode in range(MAX_EPISODE): s = env.reset() t = 0 track_r = [] # 每回合的所有奖励 while True: if RENDER: env.render() a = actor.choose_action(s) s_, r, done, info = env.step(a) if done: r = -20 # 回合结束的惩罚 track_r.append(r) td_error = critic.learn(s, r, s_) # Critic 学习 gradient=grad[r+gamma*V(s_)-V(s)] actor.learn(s, a, td_error) # Actor 学习 true_gradient=grad[logP(s,a)*td_error] s = s_ t += 1 if done or t &gt;= MAX_EP_STEPS: # 回合结束, 打印回合累积奖励 ep_rs_sum = sum(track_r) if &apos;running_reward&apos; not in globals(): running_reward = ep_rs_sum else: running_reward = running_reward * 0.95 + ep_rs_sum * 0.05 if running_reward &gt; DISPLAY_REWARD_THRESHOLD: RENDER = True # rendering print(&quot;episode:&quot;, i_episode, &quot; reward:&quot;, int(running_reward)) break","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"/tags/强化学习/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"莫烦-强化学习-Policy Gradients","slug":"莫烦-强化学习-Policy Gradients","date":"2019-08-24T12:00:05.000Z","updated":"2019-09-01T13:14:46.808Z","comments":true,"path":"2019/08/24/莫烦-强化学习-Policy Gradients/","link":"","permalink":"/2019/08/24/莫烦-强化学习-Policy Gradients/","excerpt":"","text":"本文转载自莫烦-强化学习系列-Policy Gradients强化学习是一个通过奖惩来学习正确行为的机制. 家族中有很多种不一样的成员, 有学习奖惩值, 根据自己认为的高价值选行为, 比如 Q learning, Deep Q Network, 也有不通过分析奖励值, 直接输出行为的方法, 这就是今天要说的 Policy Gradients 了. 甚至我们可以为 Policy Gradients 加上一个神经网络来输出预测的动作. 对比起以值为基础的方法, Policy Gradients 直接输出动作的最大好处就是, 它能在一个连续区间内挑选动作, 而基于值的, 比如 Q-learning, 它如果在无穷多的动作中计算价值, 从而选择行为, 这, 它可吃不消. 更新的不同之处有了神经网络当然方便, 但是, 我们怎么进行神经网络的误差反向传递呢? Policy Gradients 的误差又是什么呢? 答案是! 哈哈, 没有误差! 但是他的确是在进行某一种的反向传递. 这种反向传递的目的是让这次被选中的行为更有可能在下次发生. 但是我们要怎么确定这个行为是不是应当被增加被选的概率呢? 这时候我们的老朋友, reward 奖惩正可以在这时候派上用场. 具体更新步骤现在我们来演示一遍, 观测的信息通过神经网络分析, 选出了左边的行为, 我们直接进行反向传递, 使之下次被选的可能性增加, 但是奖惩信息却告诉我们, 这次的行为是不好的, 那我们的动作可能性增加的幅度随之被减低. 这样就能靠奖励来左右我们的神经网络反向传递. 我们再来举个例子, 假如这次的观测信息让神经网络选择了右边的行为, 右边的行为随之想要进行反向传递, 使右边的行为下次被多选一点, 这时, 奖惩信息也来了, 告诉我们这是好行为, 那我们就在这次反向传递的时候加大力度, 让它下次被多选的幅度更猛烈! 这就是 Policy Gradients 的核心思想了. 很简单吧. 算法更新我们介绍的 policy gradient 的第一个算法是一种基于 整条回合数据 的更新, 也叫 REINFORCE 方法. 这种方法是 policy gradient 的最基本方法, 有了这个的基础, 我们再来做更高级的.delta(log(Policy(s,a))*V) 表示在 状态 s 对所选动作 a 的吃惊度, 如果 Policy(s,a) 概率越小, 反向的 log(Policy(s,a)) (即 -log(P)) 反而越大. 如果在 Policy(s,a) 很小的情况下, 拿到了一个 大的 R, 也就是 大的 V, 那 -delta(log(Policy(s, a))*V) 就更大, 表示更吃惊, (我选了一个不常选的动作, 却发现原来它能得到了一个好的 reward, 那我就得对我这次的参数进行一个大幅修改). 这就是吃惊度的物理意义啦. 代码理解因为这是强化学习, 所以神经网络中并没有我们熟知的监督学习中的 y label. 取而代之的是我们选的 action. class PolicyGradient: def __init__(self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95, output_graph=False): ... def _build_net(self): with tf.name_scope(&apos;inputs&apos;): self.tf_obs = tf.placeholder(tf.float32, [None, self.n_features], name=&quot;observations&quot;) # 接收 observation self.tf_acts = tf.placeholder(tf.int32, [None, ], name=&quot;actions_num&quot;) # 接收我们在这个回合中选过的 actions self.tf_vt = tf.placeholder(tf.float32, [None, ], name=&quot;actions_value&quot;) # 接收每个 state-action 所对应的 value (通过 reward 计算) # fc1 layer = tf.layers.dense( inputs=self.tf_obs, units=10, # 输出个数 activation=tf.nn.tanh, # 激励函数 kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.3), bias_initializer=tf.constant_initializer(0.1), name=&apos;fc1&apos; ) # fc2 all_act = tf.layers.dense( inputs=layer, units=self.n_actions, # 输出个数 activation=None, # 之后再加 Softmax kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.3), bias_initializer=tf.constant_initializer(0.1), name=&apos;fc2&apos; ) self.all_act_prob = tf.nn.softmax(all_act, name=&apos;act_prob&apos;) # 激励函数 softmax 出概率 with tf.name_scope(&apos;loss&apos;): # 最大化 总体 reward (log_p * R) 就是在最小化 -(log_p * R), 而 tf 的功能里只有最小化 loss neg_log_prob = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=all_act, labels=self.tf_acts) # 所选 action 的概率 -log 值 # 下面的方式是一样的: # neg_log_prob = tf.reduce_sum(-tf.log(self.all_act_prob)*tf.one_hot(self.tf_acts, self.n_actions), axis=1) loss = tf.reduce_mean(neg_log_prob * self.tf_vt) # (vt = 本reward + 衰减的未来reward) 引导参数的梯度下降 with tf.name_scope(&apos;train&apos;): self.train_op = tf.train.AdamOptimizer(self.lr).minimize(loss) 这里有必要解释一下为什么我们使用的loss= -log(prob)*vt当做 loss, 因为下面有很多评论说这里不理解. 简单来说, 上面提到了两种形式来计算 neg_log_prob, 这两种形式是一模一样的, 只是第二个是第一个的展开形式. 如果你仔细看第一个形式, 这不就是在神经网络分类问题中的 cross-entropy 嘛! 使用 softmax 和神经网络的最后一层 logits 输出和真实标签 (self.tf_acts) 对比的误差. 并将神经网络的参数按照这个真实标签改进. 这显然和一个分类问题没有太多区别. 我们能将这个 neg_log_prob 理解成 cross-entropy 的分类误差. 分类问题中的标签是真实 x 对应的 y, 而我们 Policy gradient 中, x 是 state, y 就是它按照这个 x 所做的动作号码. 所以也可以理解成, 它按照 x 做的动作永远是对的 (出来的动作永远是正确标签), 它也永远会按照这个 “正确标签” 修改自己的参数. 可是事实却不是这样, 他的动作不一定都是 “正确标签”, 这就是强化学习(Policy gradient)和监督学习(classification)的不同. 为了确保这个动作真的是 “正确标签”, 我们的 loss 在原本的 cross-entropy 形式上乘以 vt, 用 vt 来告诉这个 cross-entropy 算出来的梯度是不是一个值得信任的梯度. 如果 vt 小, 或者是负的, 就说明这个梯度下降是一个错误的方向, 我们应该向着另一个方向更新参数, 如果这个 vt 是正的, 或很大, vt 就会称赞 cross-entropy 出来的梯度, 并朝着这个方向梯度下降. 下面有一张从 karpathy 大神 网页上扣下来的图, 也正是阐述的这个思想.而不明白为什么是 loss=-log(prob)*vt 而不是 loss=-prob*vt 的朋友们, 下面留言有很多问道这个问题. 原因是这里的 prob 是从 softmax 出来的, 而计算神经网络里的所有参数梯度, 使用到的就是 cross-entropy, 然后将这个梯度乘以 vt 来控制梯度下降的方向和力度. 而我上面使用 neg_log_prob 这个名字只是为了区分这不是真正意义上的 cross-entropy, 因为标签不是真标签. 我在下面提供一些扩展链接. Loss 的定义 karpathy 大神的 PG 算法说明 David Silver 的 PG 课件 选行为这个行为不再是用 Q value 来选定的, 而是用概率来选定. 即使不用 epsilon-greedy, 也具有一定的随机性. class PolicyGradient: def __init__(self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95, output_graph=False): ... def _build_net(self): ... def choose_action(self, observation): prob_weights = self.sess.run(self.all_act_prob, feed_dict=&#123;self.tf_obs: observation[np.newaxis, :]&#125;) # 所有 action 的概率 action = np.random.choice(range(prob_weights.shape[1]), p=prob_weights.ravel()) # 根据概率来选 action return action 存储行为这一部很简单, 就是将这一步的 observation, action, reward 加到列表中去. 因为本回合完毕之后要清空列表, 然后存储下一回合的数据, 所以我们会在 learn() 当中进行清空列表的动作. class PolicyGradient: def __init__(self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95, output_graph=False): ... def _build_net(self): ... def choose_action(self, observation): ... def store_transition(self, s, a, r): self.ep_obs.append(s) self.ep_as.append(a) self.ep_rs.append(r) 学习本节的 learn() 很简单, 首先我们要对这回合的所有 reward 动动手脚, 使他变得更适合被学习. 第一就是随着时间推进, 用 gamma 衰减未来的 reward, 然后为了一定程度上减小 policy gradient 回合 variance, 我们标准化回合的 state-action value 依据在 Andrej Karpathy 的 blog. class PolicyGradient: def __init__(self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95, output_graph=False): ... def _build_net(self): ... def choose_action(self, observation): ... def store_transition(self, s, a, r): ... def learn(self): # 衰减, 并标准化这回合的 reward discounted_ep_rs_norm = self._discount_and_norm_rewards() # 功能再面 # train on episode self.sess.run(self.train_op, feed_dict=&#123; self.tf_obs: np.vstack(self.ep_obs), # shape=[None, n_obs] self.tf_acts: np.array(self.ep_as), # shape=[None, ] self.tf_vt: discounted_ep_rs_norm, # shape=[None, ] &#125;) self.ep_obs, self.ep_as, self.ep_rs = [], [], [] # 清空回合 data return discounted_ep_rs_norm # 返回这一回合的 state-action value 我们再来看看这个 discounted_ep_rs_norm 到底长什么样, 不知道大家还记不记得上节内容的这一段: vt = RL.learn() # 学习, 输出 vt, 我们下节课讲这个 vt 的作用if i_episode == 0: plt.plot(vt) # plot 这个回合的 vt plt.xlabel(&apos;episode steps&apos;) plt.ylabel(&apos;normalized state-action value&apos;) plt.show() 我们看看这一段的输出, vt 也就是 discounted_ep_rs_norm, 看他是怎么样诱导我们的 gradient descent.可以看出, 左边一段的 vt 有较高的值, 右边较低, 这就是 vt 在说: “请重视我这回合开始时的一系列动作, 因为前面一段时间杆子还没有掉下来. 而且请惩罚我之后的一系列动作, 因为后面的动作让杆子掉下来了” 或者是 “我每次都想让这个动作在下一次增加被做的可能性 (grad(log(Policy))), 但是增加可能性的这种做法是好还是坏呢? 这就要由 vt 告诉我了, 所以后段时间的 *“增加可能性” 做法并没有被提倡, 而前段时间的 “增加可能性”* 做法是被提倡的.” 这样 vt 就能在这里 loss = tf.reduce_mean(log_prob * self.tf_vt) 诱导 gradient descent 朝着正确的方向发展了. 如果你玩了下 MountainCar 的模拟程序, 你会发现 MountainCar 模拟程序中的 vt 长这样:这张图在说: “请重视我这回合最后的一系列动作, 因为这一系列动作让我爬上了山. 而且请惩罚我开始的一系列动作, 因为这些动作没能让我爬上山”. 也是通过这些 vt 来诱导梯度下降的方向. 最后是如何用算法实现对未来 reward 的衰减. class PolicyGradient: def __init__(self, n_actions, n_features, learning_rate=0.01, reward_decay=0.95, output_graph=False): ... def _build_net(self): ... def choose_action(self, observation): ... def store_transition(self, s, a, r): ... def learn(self): ... def _discount_and_norm_rewards(self): # discount episode rewards discounted_ep_rs = np.zeros_like(self.ep_rs) running_add = 0 for t in reversed(range(0, len(self.ep_rs))): running_add = running_add * self.gamma + self.ep_rs[t] discounted_ep_rs[t] = running_add # normalize episode rewards discounted_ep_rs -= np.mean(discounted_ep_rs) discounted_ep_rs /= np.std(discounted_ep_rs) return discounted_ep_rs","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"/tags/强化学习/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"莫烦-强化学习-DQN","slug":"莫烦-强化学习-DQN","date":"2019-08-24T07:31:07.000Z","updated":"2019-09-01T13:14:43.874Z","comments":true,"path":"2019/08/24/莫烦-强化学习-DQN/","link":"","permalink":"/2019/08/24/莫烦-强化学习-DQN/","excerpt":"","text":"(本文为莫烦强化学习系列的转载，原链接) 什么是DQN?DQN即深度神经网络+Q-Learning当数据量大起来之后存表和查找都会变得相当慢，这时可以训练一个神经网络读取输入状态，预测相应的动作 Experience replay：随机抽取之前的经历进行学习，打乱了经历之间的相关性Fixed Q-targets：这样就会用到两个神经网络，一个是过去的神经网络Q’，一个是最新的神经网络 DQN伪代码整个算法乍看起来很复杂, 不过我们拆分一下, 就变简单了. 也就是个 Q learning 主框架上加了些装饰.这些装饰包括: 记忆库 (用于重复学习) 神经网络计算 Q 值 暂时冻结 q_target 参数 (切断相关性) P17代码待理解Double DQN我们知道 DQN 的神经网络部分可以看成一个 最新的神经网络 + 老神经网络, 他们有相同的结构, 但内部的参数更新却有时差. 而它的 Q现实 部分是这样的:因为我们的神经网络预测 Qmax 本来就有误差, 每次也向着最大误差的 Q现实 改进神经网络, 就是因为这个 Qmax 导致了 overestimate. 所以 Double DQN 的想法就是引入另一个神经网络来打消一些最大误差的影响. 而 DQN 中本来就有两个神经网络, 我们何不利用一下这个优势呢. 所以, 我们用 Q估计 的神经网络估计 Q现实 中 Qmax(s’, a’) 的最大动作值. 然后用这个被 Q估计 估计出来的动作来选择 Q现实 中的 Q(s’).总结一下:有两个神经网络: Q_eval (Q估计中的), Q_next (Q现实中的).原本的 Q_next = max(Q_next(s’, a_all)).Double DQN 中的 Q_next = Q_next(s’, argmax(Q_eval(s’, a_all))). 也可以表达成下面那样. Prioritized replay DQN这一次还是使用 MountainCar 来进行实验, 因为这次我们不需要重度改变他的 reward 了. 所以只要是没有拿到小旗子, reward=-1, 拿到小旗子时, 我们定义它获得了 +10 的 reward. 比起之前 DQN 中, 这个 reward 定义更加准确. 如果使用这种 reward 定义方式, 可以想象 Natural DQN 会花很久的时间学习, 因为记忆库中只有很少很少的 +10 reward 可以学习. 正负样本不一样. 而使用 Prioritized replay, 就会重视这种少量的, 但值得学习的样本. 伪代码这一套算法重点就在我们 batch 抽样的时候并不是随机抽样, 而是按照 Memory 中的样本优先级来抽. 所以这能更有效地找到我们需要学习的样本. 那么样本的优先级是怎么定的呢? 原来我们可以用到 TD-error, 也就是 Q现实 - Q估计 来规定优先学习的程度. 如果 TD-error 越大, 就代表我们的预测精度还有很多上升空间, 那么这个样本就越需要被学习, 也就是优先级 p 越高. 有了 TD-error 就有了优先级 p, 那我们如何有效地根据 p 来抽样呢? 如果每次抽样都需要针对 p 对所有样本排序, 这将会是一件非常消耗计算能力的事. 好在我们还有其他方法, 这种方法不会对得到的样本进行排序. 这就是这篇 paper 中提到的 SumTree. SumTree 是一种树形结构, 每片树叶存储每个样本的优先级 p, 每个树枝节点只有两个分叉, 节点的值是两个分叉的合, 所以 SumTree 的顶端就是所有 p 的合. 正如下面图片(来自Jaromír Janisch), 最下面一层树叶存储样本的 p, 叶子上一层最左边的 13 = 3 + 10, 按这个规律相加, 顶层的 root 就是全部 p 的合了.抽样时, 我们会将 p 的总合 除以 batch size, 分成 batch size 那么多区间, (n=sum(p)/batch_size). 如果将所有 node 的 priority 加起来是42的话, 我们如果抽6个样本, 这时的区间拥有的 priority 可能是这样.[0-7], [7-14], [14-21], [21-28], [28-35], [35-42] 然后在每个区间里随机选取一个数. 比如在第区间 [21-28] 里选到了24, 就按照这个 24 从最顶上的42开始向下搜索. 首先看到最顶上 42 下面有两个 child nodes, 拿着手中的24对比左边的 child 29, 如果 左边的 child 比自己手中的值大, 那我们就走左边这条路, 接着再对比 29 下面的左边那个点 13, 这时, 手中的 24 比 13 大, 那我们就走右边的路, 并且将手中的值根据 13 修改一下, 变成 24-13 = 11. 接着拿着 11 和 13 左下角的 12 比, 结果 12 比 11 大, 那我们就选 12 当做这次选到的 priority, 并且也选择 12 对应的数据. 可以看到Prioritized-Replay可以有效减少trainning的时间 Dueling DQN转载自莫烦-Dueling DQN只要稍稍修改 DQN 中神经网络的结构, 就能大幅提升学习效果, 加速收敛. 这种新方法叫做 Dueling DQN. 用一句话来概括 Dueling DQN 就是. 它将每个动作的 Q 拆分成了 state 的 Value 加上 每个动作的 Advantage. 上一个 Paper 中的经典解释图片, 上者是一般的 DQN 的 Q值 神经网络. 下者就是 Dueling DQN 中的 Q值 神经网络了. 那具体是哪里不同了呢?下面这个公式解释了不同之处. 原来 DQN 神经网络直接输出的是每种动作的 Q值, 而 Dueling DQN 每个动作的 Q值 是有下面的公式确定的.它分成了这个 state 的值, 加上每个动作在这个 state 上的 advantage. 因为有时候在某种 state, 无论做什么动作, 对下一个 state 都没有多大影响. 比如 paper 中的这张图.这是开车的游戏, 左边是 state value, 发红的部分证明了 state value 和前面的路线有关, 右边是 advantage, 发红的部分说明了 advantage 很在乎旁边要靠近的车子, 这时的动作会受更多 advantage 的影响. 发红的地方左右了自己车子的移动原则.DQN和Dueling DQN的网络结构差异： 结果对比这次我们看看累积奖励 reward, 杆子立起来的时候奖励 = 0, 其他时候都是负值, 所以当累积奖励没有在降低时, 说明杆子已经被成功立了很久了.我们发现当可用动作越高, 学习难度就越大, 不过 Dueling DQN 还是会比 Natural DQN 学习得更快. 收敛效果更好.","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"/tags/强化学习/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"莫烦-强化学习-Q-Learning和Sarsa","slug":"莫烦-强化学习-Q-Learning和Sarsa","date":"2019-08-23T08:34:19.000Z","updated":"2019-09-01T13:14:49.663Z","comments":true,"path":"2019/08/23/莫烦-强化学习-Q-Learning和Sarsa/","link":"","permalink":"/2019/08/23/莫烦-强化学习-Q-Learning和Sarsa/","excerpt":"","text":"P2: 强化学习分类不理解环境 Model-Free理解环境 Model-Based 先对现实世界建模基于概率每个都有一定概率被选中 优势是可以处理连续动作 基于价值选择最高价值 对连续动作无能为力 回合更新(Monte-Carlo update)单步更新(Temporal-Difference update)在线学习 On-Policy本人边玩边学习 离线学习 Off-Policy可以自己玩，也可以看着别人玩(经验)，或者先玩，再学习 p9: Q-Learning和SarsaQ-Learning：取maxQ代表到了s2的时候想象自己的行为 Q(s1,a2)现实：R+γ*maxQ(s2) Q(s1,a2)估计：Q(s1,a2) 差距=现实-估计 新Q(s1,a2)=老Q(s1,a2)+α*差距 α是学习效率注意这里更新的是s1的Q表，尽管现在已经是s2Sarsa算法：同样, 我们会经历正在写作业的状态 s1, 然后再挑选一个带来最大潜在奖励的动作 a2, 这样我们就到达了 继续写作业状态 s2, 而在这一步, 如果你用的是 Q learning, 你会观看一下在 s2 上选取哪一个动作会带来最大的奖励, 但是在真正要做决定时, 却不一定会选取到那个带来最大奖励的动作, Q-learning 在这一步只是估计了一下接下来的动作值. 而 Sarsa 是实践派, 他说到做到, 在 s2 这一步估算的动作也是接下来要做的动作. 所以 Q(s1, a2) 现实的计算值, 我们也会稍稍改动, 去掉maxQ, 取而代之的是在 s2 上我们实实在在选取的 a2 的 Q 值. 最后像 Q learning 一样, 求出现实和估计的差距 并更新 Q 表里的 Q(s1, a2). Q-Learning和Sarsa的区别Q-Learning预选一个a，但是不一定这样执行(Q表改变了)，但Sarsa是行动派，他一定执行a。但Sarsa比较胆小，会选择比较安全的行为，也就是原先的Q表里奖励较高的行为。 Sarsa(λ)Sarsa(0)相当于单步更新，下图认为只有离宝藏最近的脚印才是需要更新的Sarsa(1)相当于回合更新，认为所有的脚印都需要被更新Sarsa(λ)则认为离宝藏越近的脚印比离宝藏越远脚印更重要 Sarsa(λ)伪代码下图是针对于一个state-action值按经历次数的变化图。最上面是经历state-action的时间点，第二张图是使用这种方式所带来的 “不可或缺性值”: self.eligibility_trace.ix[s, a] += 1 下面图是使用这种方法带来的 “不可或缺性值”: self.eligibility_trace.ix[s, :] *= 0; self.eligibility_trace.ix[s, a] = 1","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"强化学习","slug":"强化学习","permalink":"/tags/强化学习/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Markdown语法示例","slug":"MarkDown语法示例","date":"2019-08-20T02:28:13.000Z","updated":"2019-09-01T13:01:09.463Z","comments":true,"path":"2019/08/20/MarkDown语法示例/","link":"","permalink":"/2019/08/20/MarkDown语法示例/","excerpt":"","text":"序号 黄瓜 玉米 茄子 黄瓜 玉米 茄子 黄瓜 玉米 茄子 黄瓜 玉米 茄子 如果在单一列表项中包含了多个段落,为了保证渲染正常，*与段落首字母之间必须保留四个空格 段落一 小段一 段落二 小段二 另外，如果在列表中加入了区块引用，区域引用标记符也需要缩进4个空格 段落一 区块标记一 段落二 区块标记二 这里是斜体这里是斜体 这里是加粗这里是加粗 ###插入代码段###反引号（Esc键下方） 包裹在一对```之间即代码段fun (x: Int, y: Int): Int &#123; return x + y&#125; 表头 条目一 条目二 项目 项目一 项目二 注：三个短斜杠左右的冒号用于控制对齐方式，只放置左边冒号表示文字居左，只放置右边冒号表示文字居右，如果两边都放置冒号表示文字居中。 Markdown使用反斜杠\\插入语法中用到的特殊符号。在Markdown中，主要有以下几种特殊符号需要处理：\\\\ 反斜线\\` 反引号\\* 星号\\_ 底线\\&#123;\\&#125; 花括号[\\\\] 方括号\\(\\) 括弧\\# 井字号\\+ 加号\\- 减号\\. 英文句点\\! 惊叹号 如何给文字上色此处用#使用标题格式 插入图片或链接[点击跳转至百度](http://www.baidu.com)![图片](https://upload-images.jianshu.io/upload_images/703764-605e3cc2ecb664f6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](6.jpg) 点击跳转至百度 ###文字###&lt;font color=#0099ff size=5 face=&quot;黑体&quot;&gt;color=#0099ff size=5 face=&quot;黑体&quot;&lt;/font&gt;&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#FF4500&gt;这里的背景色是：OrangeRed， 十六进制颜色值：#FF4500， rgb(255, 69, 0)&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; color=#0099ff size=5 face=”黑体” 这里的背景色是：OrangeRed， 十六进制颜色值：#FF4500， rgb(255, 69, 0)","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"技术","slug":"技术","permalink":"/tags/技术/"},{"name":"hexo","slug":"hexo","permalink":"/tags/hexo/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Linux的常用命令","slug":"linux常用命令(长期更新)","date":"2019-08-20T02:28:13.000Z","updated":"2019-09-01T13:01:03.543Z","comments":true,"path":"2019/08/20/linux常用命令(长期更新)/","link":"","permalink":"/2019/08/20/linux常用命令(长期更新)/","excerpt":"","text":"cd / 根目录rm C -r 删除C这个非空目录rmdir C 删除空目录 代码交叉跳转： 在程序根目录下ctags-R，ctrl+]即可实现跳转,ctrl+T跳转回去 统计当前文件夹文件数：ls -l|grep “^-“| wc -lgrep “^d”表示目录，”^-“表示文件 虚拟机挂载目录： 开机手动挂载：mount -t vboxsf shares /mnt/Share putty： 利用putty传输文件：pscp svd_parse.py 974102371@172.31.111.23:2017133026 远程训练：https://www.cnblogs.com/godarrow/p/7771839.html nohup python3 -u main.py –input_height 96 –output_height 48 –dataset faces –crop True –train True –epoch 10 &amp;&gt;nohup.out&amp; nohup python3 -u word2vec_parse3.py &amp;&gt; word2vec_parse3.out&amp; 指定GPU: os.environ[‘CUDA_VISIBLE_DEVICES’] = ‘1’ 服务器校园网登录： curl -d “DDDDD=296375&amp;upass=***&amp;0MKKey=” https://drcom.szu.edu.cn conda： conda create -n law python=3.6 创建一个名为tf的py3.6环境conda activate tfconda deactivatesource activate python2 切换环境conda install –yes –file requirements.txt 查看GPU信息： nvidia-smi 查看gpu版本信息cat /usr/local/cuda/version.txt 查看cuda版本信息https://tensorflow.google.cn/install/source 查看gpu版本对应","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"如何感性地理解EM算法？","slug":"如何感性地理解EM算法","date":"2019-08-20T02:28:13.000Z","updated":"2019-09-01T13:03:31.484Z","comments":true,"path":"2019/08/20/如何感性地理解EM算法/","link":"","permalink":"/2019/08/20/如何感性地理解EM算法/","excerpt":"如何感性地理解EM算法？","text":"如何感性地理解EM算法？ 如果使用基于最大似然估计的模型，模型中存在隐变量，就要用EM算法做参数估计。个人认为，理解EM算法背后的idea，远比看懂它的数学推导重要。idea会让你有一个直观的感受，从而明白算法的合理性，数学推导只是将这种合理性用更加严谨的语言表达出来而已。打个比方，一个梨很甜，用数学的语言可以表述为糖分含量90%，但只有亲自咬一口，你才能真正感觉到这个梨有多甜，也才能真正理解数学上的90%的糖分究竟是怎么样的。如果EM是个梨，本文的目的就是带领大家咬一口。001、一个非常简单的例子假设现在有两枚硬币1和2，,随机抛掷后正面朝上概率分别为P1，P2。为了估计这两个概率，做实验，每次取一枚硬币，连掷5下，记录下结果，如下：硬币结果统计1正正反正反3正-2反2反反正正反2正-3反1正反反反反1正-4反2正反反正正3正-2反1反正正反反2正-3反可以很容易地估计出P1和P2，如下：P1 = （3+1+2）/ 15 = 0.4P2= （2+3）/10 = 0.5到这里，一切似乎很美好，下面我们加大难度。010、加入隐变量z还是上面的问题，现在我们抹去每轮投掷时使用的硬币标记，如下：硬币结果统计Unknown正正反正反3正-2反Unknown反反正正反2正-3反Unknown正反反反反1正-4反Unknown正反反正正3正-2反Unknown反正正反反2正-3反好了，现在我们的目标没变，还是估计P1和P2，要怎么做呢？显然，此时我们多了一个隐变量z，可以把它认为是一个5维的向量（z1,z2,z3,z4,z5)，代表每次投掷时所使用的硬币，比如z1，就代表第一轮投掷时使用的硬币是1还是2。但是，这个变量z不知道，就无法去估计P1和P2，所以，我们必须先估计出z，然后才能进一步估计P1和P2。但要估计z，我们又得知道P1和P2，这样我们才能用最大似然概率法则去估计z，这不是鸡生蛋和蛋生鸡的问题吗，如何破？答案就是先随机初始化一个P1和P2，用它来估计z，然后基于z，还是按照最大似然概率法则去估计新的P1和P2，如果新的P1和P2和我们初始化的P1和P2一样，请问这说明了什么？（此处思考1分钟）这说明我们初始化的P1和P2是一个相当靠谱的估计！就是说，我们初始化的P1和P2，按照最大似然概率就可以估计出z，然后基于z，按照最大似然概率可以反过来估计出P1和P2，当与我们初始化的P1和P2一样时，说明是P1和P2很有可能就是真实的值。这里面包含了两个交互的最大似然估计。如果新估计出来的P1和P2和我们初始化的值差别很大，怎么办呢？就是继续用新的P1和P2迭代，直至收敛。这就是下面的EM初级版。011、EM初级版我们不妨这样，先随便给P1和P2赋一个值，比如：P1 = 0.2P2 = 0.7然后，我们看看第一轮抛掷最可能是哪个硬币。如果是硬币1，得出3正2反的概率为 0.20.20.20.80.8 = 0.00512如果是硬币2，得出3正2反的概率为0.70.70.70.30.3=0.03087然后依次求出其他4轮中的相应概率。做成表格如下：轮数若是硬币1若是硬币210.005120.0308720.020480.0132330.081920.0056740.005120.0308750.020480.01323按照最大似然法则：第1轮中最有可能的是硬币2第2轮中最有可能的是硬币1第3轮中最有可能的是硬币1第4轮中最有可能的是硬币2第5轮中最有可能的是硬币1我们就把上面的值作为z的估计值。然后按照最大似然概率法则来估计新的P1和P2。P1 = （2+1+2）/15 = 0.33P2=（3+3）/10 = 0.6设想我们是全知的神，知道每轮抛掷时的硬币就是如本文第001部分标示的那样，那么，P1和P2的最大似然估计就是0.4和0.5（下文中将这两个值称为P1和P2的真实值）。那么对比下我们初始化的P1和P2和新估计出的P1和P2：初始化的P1估计出的P1真实的P1初始化的P2估计出的P2真实的P20.20.330.40.70.60.5看到没？我们估计的P1和P2相比于它们的初始值，更接近它们的真实值了！可以期待，我们继续按照上面的思路，用估计出的P1和P2再来估计z，再用z来估计新的P1和P2，反复迭代下去，就可以最终得到P1 = 0.4，P2=0.5，此时无论怎样迭代，P1和P2的值都会保持0.4和0.5不变，于是乎，我们就找到了P1和P2的最大似然估计。这里有两个问题：1、新估计出的P1和P2一定会更接近真实的P1和P2？答案是：没错，一定会更接近真实的P1和P2，数学可以证明，但这超出了本文的主题，请参阅其他书籍或文章。2、迭代一定会收敛到真实的P1和P2吗？答案是：不一定，取决于P1和P2的初始化值，上面我们之所以能收敛到P1和P2，是因为我们幸运地找到了好的初始化值。100、EM进阶版下面，我们思考下，上面的方法还有没有改进的余地？我们是用最大似然概率法则估计出的z值，然后再用z值按照最大似然概率法则估计新的P1和P2。也就是说，我们使用了一个最可能的z值，而不是所有可能的z值。如果考虑所有可能的z值，对每一个z值都估计出一个新的P1和P2，将每一个z值概率大小作为权重，将所有新的P1和P2分别加权相加，这样的P1和P2应该会更好一些。所有的z值有多少个呢？显然，有2^5=32种，需要我们进行32次估值？？不需要，我们可以用期望来简化运算。轮数若是硬币1若是硬币210.005120.0308720.020480.0132330.081920.0056740.005120.0308750.020480.01323利用上面这个表，我们可以算出每轮抛掷中使用硬币1或者使用硬币2的概率。比如第1轮，使用硬币1的概率是：0.00512/(0.00512+0.03087)=0.14使用硬币2的概率是1-0.14=0.86依次可以算出其他4轮的概率，如下：轮数z_i=硬币1z_i=硬币210.140.8620.610.3930.940.0640.140.8650.610.39上表中的右两列表示期望值。看第一行，0.86表示，从期望的角度看，这轮抛掷使用硬币2的概率是0.86。相比于前面的方法，我们按照最大似然概率，直接将第1轮估计为用的硬币2，此时的我们更加谨慎，我们只说，有0.14的概率是硬币1，有0.86的概率是硬币2，不再是非此即彼。这样我们在估计P1或者P2时，就可以用上全部的数据，而不是部分的数据，显然这样会更好一些。这一步，我们实际上是估计出了z的概率分布，这步被称作E步。结合下表：硬币结果统计Unknown正正反正反3正-2反Unknown反反正正反2正-3反Unknown正反反反反1正-4反Unknown正反反正正3正-2反Unknown反正正反反2正-3反我们按照期望最大似然概率的法则来估计新的P1和P2：以P1估计为例，第1轮的3正2反相当于0.143=0.42正0.142=0.28反依次算出其他四轮，列表如下：轮数正面反面10.420.2821.221.8330.943.7640.420.2851.221.83总计4.227.98P1=4.22/(4.22+7.98)=0.35可以看到，改变了z值的估计方法后，新估计出的P1要更加接近0.4。原因就是我们使用了所有抛掷的数据，而不是之前只使用了部分的数据。这步中，我们根据E步中求出的z的概率分布，依据最大似然概率法则去估计P1和P2，被称作M步。101、总结以上，我们用一个实际的小例子，来实际演示了EM算法背后的idea，共性存于个性之中，通过这个例子，我们可以对EM算法究竟在干什么有一个深刻感性的认识，掌握EM算法的思想精髓。Reference:http://pan.baidu.com/s/1i4NfvP7","categories":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}],"tags":[{"name":"数学","slug":"数学","permalink":"/tags/数学/"},{"name":"机器学习","slug":"机器学习","permalink":"/tags/机器学习/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}]},{"title":"Git的基本使用","slug":"Git的基本使用","date":"2019-07-25T15:38:23.000Z","updated":"2019-09-01T13:00:19.809Z","comments":true,"path":"2019/07/25/Git的基本使用/","link":"","permalink":"/2019/07/25/Git的基本使用/","excerpt":"","text":"本地仓库git init：创建空的版本库(.git目录不要修改！！！) git add 1.py：把文件添加到仓库 git commit -m “注释信息” git status：查看仓库当前状态 git diff：查看修改的内容 git log：查看所有提交日志 git log –pretty=oneline：查看所有提交日志(只有编号和注释信息) git reset –hard HEAD^：回退到上一个版本 git reset –hard HEAD^^：回退到上上个版本 git reset –hard HEAD~100：回退到前100个版本 git reset –hard 具体版本号：回退到某一个版本 git reflog：记录所有命令 git checkout – fileName：撤销，就是让这个fileName回退到最后一次commit或add的状态 远程仓库1.创建ssh key：ssh-keygen -t rsa -C “Github账号”，记下.ssh的目录，然后一直回车 2.进入到.ssh的目录","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Django06-爱鲜蜂(未完)","slug":"Django06-爱鲜蜂(未完)","date":"2019-07-25T14:35:23.000Z","updated":"2019-09-01T13:00:23.153Z","comments":true,"path":"2019/07/25/Django06-爱鲜蜂(未完)/","link":"","permalink":"/2019/07/25/Django06-爱鲜蜂(未完)/","excerpt":"","text":"python manage.py runserver 8001 //设置8001端口启动","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Django03-视图","slug":"Django03-视图","date":"2019-07-22T01:14:50.000Z","updated":"2019-09-01T13:00:30.230Z","comments":true,"path":"2019/07/22/Django03-视图/","link":"","permalink":"/2019/07/22/Django03-视图/","excerpt":"","text":"响应包括网页和JSON数据，而网页又包括重定向和错误视图。 url配置配置流程： 1.制定根级url配置文件(setting.py文件中的ROOT_URLCONF = ‘project.urls’,一般不用修改) 2.urlpatterns(一个url实例列表和url对象(正则表达式、视图名称、名称)) 匹配正则的注意事项： 1.如果想要从url中获取一个值，需要对正则加小括号 2.匹配正则前不需要加反斜杆 3.正则前要加r表示字符串不转义 引入其他url配置： 在应用目录中创建urls.py文件，定义本应用的url配置，在工程目录下的urls.py文件中使用include()方法 urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^',include('myapp.urls'))] url反向解析： 概述：如果在视图、模板中使用了硬编码链接，在url配置发生改变时，动态生成链接的地址 解决：在使用链接时，通过url配置的名称，动态生成url地址 作用：使用url模板 视图函数定义视图： 视图的本质是一个函数 视图参数：1.一个HttpRequest的实例(浏览器发送的内容) 2.通过正则表达式获取的参数 位置：一般在views.py文件下定义 错误视图：404视图(找不到网页时返回即url匹配不成功，在templates目录下定义404.html request_path是导致错误的网址)、400视图(错误出现在客户的操作 爬虫 cookie等)、500视图(在视图代码中出现错误(服务器diamante))等 配置settings.py： DEBUG = True #为True表示永远不会调用404.html页面 404.html一定要写在templates目录下而不是myapp目录下ALLOWED_HOSTS = ['*'] HTTPRequest对象概述：服务器接收到htpp请求后会根据报文创建HTTPRequestt对象，视图的第一个参数就是HttpRequest对象，是由Django创建的，之后调用视图时传递给视图 属性： path：请求的完整路径(但不包括域名和端口) method：请求的方式，常用的有GET、POST encoding：浏览器提交的数据编码方式 GET：类似于字典的对象，包含了get请求的所有参数(其实就是?a=45&amp;b=dsaf那些) POST：类似字典的对象，包含了post请求的所有参数(表单数据) FILES：类似字典的对象，包含了所有上传的文件 COOKIES：字典，包含了所有的cookie session：类似字典的对象，表示当前会话 方法：is_ajax()：如果是通过XMLHTTPRequest发起的，返回True 如果是ajax，一般返回的是json数据 QueryDict对象request对象中的GET、POST都属于QueryDict对象 方法： get()：根据键获取值，只能获取一个值 getlist()：将键的值以列表的形式返回，可以获取多个值 GET属性#urls.pyurl(r'^get1',views.get1)url(r'^get2',views.get2)#views.pydef get1(request): a=request.GET.get('a') b=request.GET.get('b') c=request.GET.get('c') return HttpResponse(a+\" \"+b+\" \"+c)def get2(request): a = request.GET.getlist('a') a0=a[0] a1=a[1] c = request.GET.get('c') return HttpResponse(a0 + \" \" + a1 + \" \" + c) POST属性//regist.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;注册&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"regist/\" method=\"post\"&gt; 姓名：&lt;input type=\"text\" name=\"name\" value=\"\"/&gt; &lt;hr/&gt; 性别：&lt;input type=\"radio\" name=\"gender\" value=\"1\"/&gt;男 &lt;input type=\"radio\" name=\"gender\" value=\"0\"/&gt;女 &lt;hr/&gt; 年龄：&lt;input type=\"text\" name=\"age\" value=\"\"/&gt; &lt;hr/&gt; 爱好：&lt;input type=\"checkbox\" name=\"hobby\" value=\"money\"/&gt;金钱 &lt;input type=\"checkbox\" name=\"hobby\" value=\"girl\"/&gt;美女 &lt;hr/&gt; &lt;input type=\"submit\" value=\"注册\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; #关闭csrf 即注释掉 否则点击注册后会因为跨站攻击添加的网址内容位置不正确#视频似乎有错误 并没有解决问题1MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', #'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware',] #POSTdef showregist(request): return render(request,'myapp/regist.html')def regist(request): name=request.POST.get(\"name\") gender=request.POST.get(\"gender\") age=request.POST.get(\"age\") hobby=request.POST.getlist(\"hobby\") print(name) print(gender) print(age) print(hobby) return HttpResponse(\"post\") HttpResponse对象render方法： 原型：render(request,templateName,[,context]) 属性： content：表示返回的内容 charset：编码格式 status_code：响应状态码 content-type：指定输出的MIME类型 方法： init：使用页面内容实例化HttpResponse对象 write：以文件形式写入 flush：以文件形式输出缓冲区 set_cookie(key,value=’’,max_age=None,expirses=None)：设置cookie delete_cookie(key)：删除cookie 如果删除不存在的key，就当什么都没发生 子类HttpResponseRedirect#views.py#重定向 输入1的时候跳转到2的页面from django.http import HttpResponseRedirectdef redirect1(request): return HttpResponseRedirect('/redirect2')def redirect2(request): return HttpResponse(\"我是重定向后的视图\")#简写 redirect方法from django.shortcuts import redirectdef redirect1(request): return redirect('/redirect2')def redirect2(request): return HttpResponse(\"我是重定向后的视图\") 子类JsonResponse返回json数据，一般用于异步请求(ajax) data：字典对象 注意：Content-type类型为application/json 状态保持概述：http协议是无状态协议，每次请求都是一次新的请求，不记得以前的请求(登录状态没有记录)；客户端与服务器端的一次通信就是一次会话；实现状态保持，在客户端或者服务器端存储有关会话的数据； 存储方式：cookie(不适用cookie原因：所有数据存储在客户端，不要存敏感的数据)或session(所有数据存储在服务器端，在客户端用cookie存储session_id，对应的值存储在服务器端) 目的：在一段时间内跟踪请求者的状态，可以使用跨页面访问当前请求者的数据 注意：不同的请求者之间不会共享这个数据，与请求者一一对应 启用session：默认启用 #settings.pyMIDDLEWARE = [ ... 'django.contrib.sessions.middleware.SessionMiddleware', ...] 使用session： 启用session后，每个HTTPRequest对象都有一个session属性，就是一个类似字典的对象 get(key,default=None)：根据键获取session值 clear()：清空所有会话 flush()：删除当前会话并删除会话的cookie //login.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"/showmain/\" method=\"post\"&gt; &lt;input type=\"text\" name=\"username\"/&gt; &lt;input type=\"submit\" value=\"登录\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 用到的数据： insert into myapp_grades(gname,gdate,ggirlnum,gboynum,isDelete) values(“python01”,”2017-2-4”,10,50,0),(“python02”,”2017-5-4”,10,20,0),(“python03”,”2018-8-5”,50,50,0),(“python04”,”2018-6-15”,10,42,0); insert into myapp_students(sname,sgender,scontend,isDelete,sgrade_id,sage) values(“蔡徐坤”,0,”我叫蔡徐坤”,0,4,20), (“刘德华”,0,”我叫刘德华”,0,1,25), (“陈瑞豪”,0,”我叫陈瑞豪”,0,3,18), (“黑雪姬”,1,”我叫黑雪姬”,0,2,14), (“有田春雪”,0,”我叫有田春雪”,0,2,13);","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Django04-模板","slug":"Django04-模板","date":"2019-07-22T01:14:50.000Z","updated":"2019-09-01T13:00:29.079Z","comments":true,"path":"2019/07/22/Django04-模板/","link":"","permalink":"/2019/07/22/Django04-模板/","excerpt":"","text":"每次删掉0001_initial.py，然后修改settings.py中的数据库，重新执行迁移。 变量视图传递给模板的数据；要遵守标识符规则；语法： 注意： 1.如果使用的变量不存在，则插入的是空字符串 2.在模板中使用点语法(stu.sname) 字典查询 属性或者方法 数字索引 3.在模板中不能传递参数(stu.getname) 标签语法：&#123;% tag %&#125; 作用： 1.在输出中创建文本 2.控制逻辑和循环 if：语句3 for： forloop.counter：循环进行的次数 empty：表示列表为空的情况 //students.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;学生列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;学生列表&lt;/h1&gt; &lt;ul&gt; &#123;% for stu in students %&#125; &lt;li&gt; &#123;&#123;forloop.counter&#125;&#125;--&#123;&#123;stu.sname&#125;&#125;--&#123;&#123;stu.sgrade&#125;&#125; &lt;/li&gt; &#123;% empty %&#125; &lt;li&gt;目前没有学生&lt;/li&gt; &#123;% endfor%&#125; &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; comment：注释 &#123;% comment %&#125; 多行注释&#123;% endcomment %&#125;&#123;# 单行注释 #&#125; ifequal/ifnotequal： &#123;% ifequal 值1 值2 %&#125; 值1==值2&#123;% endifequal %&#125; include：架子啊模板并以标签内的参数渲染 &#123;% include 模板目录 参数1 参数2 %&#125; url：反向解析 &#123;% url &apos;namespace:name&apos; 参数1 参数2 %&#125; csrf_token：用于跨站请求伪造保护 &#123;% csrf_token %&#125; block/extends：用于模板的继承 autoescape：用于HTML的转义 过滤器语法：&#123;&#123;% var|过滤器%&#125;&#125; 作用：在变量被显示前修改它 &lt;h1&gt;&#123;&#123;str|upper&#125;&#125;&lt;/h1&gt; //可以让str的字母转成大写再显示 过滤器可以传递参数，参数用引号引起来 &lt;h1&gt;&#123;&#123;list|join:'#'&#125;&#125;&lt;/h1&gt; 如果一个没有被提供，或者值为false、空，可以使用默认值 &#123;&#123; var|default:'没有' &#125;&#125; 根据给定格式转换日期为字符串： &#123;&#123; datevalue|date:'y-m-d' &#125;&#125; HTML转义：escape 加减乘除取模： &#123;&#123; num|add:10 &#125;&#125;&#123;&#123; num|add:-5 &#125;&#125;&lt;!--num/1*5--&gt;&#123;&#123;% widthratio: num 1 5%&#125;&#125;&lt;!--num/5*1--&gt;&#123;&#123;% widthratio: num 5 1%&#125;&#125;&lt;!--num%2--&gt;&#123;&#123;% num|divisibleby:2 %&#125;&#125; 反向解析#project/urls.pyurl(r'^sunck/',include('myapp.urls',namespace='app'))#myapp/urls.pyurl(r'^good/(\\d+)$',views.good,name='good')#index.html&lt;a href=\"&#123;% url 'app:good' 1 %&#125;\"&gt;链接&lt;/a&gt;#其实反向解析相当于把sunck/代进app，把good/代进good，然后正则匹配的(/d+)在这里对应1 模板继承作用：可以减少页面内容的重复定义，实现页面的重用 block标签：在父模板中预留区域，子模板去填充 语法：&#123;% block 标签名 %&#125; &#123;% endblock 标签名 %&#125; extends标签：继承模板，需要写在模板文件的第一行 语法：&#123;% extends 父模板路径 %&#125; //base.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;style&gt; #header&#123; width:100%; height:100px; background-color:red; &#125; #footer&#123; width:100%; height:100px; background-color:blue; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"header\"&gt;header&lt;/div&gt; &lt;div id=\"main\"&gt; &#123;% block main%&#125; &#123;% endblock main%&#125; &lt;/div&gt; &lt;div id=\"footer\"&gt;footer&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; //main.html&#123;% extends 'myapp/base.html'%&#125;&#123;% block main %&#125; &lt;h1&gt;sunck is a good man&lt;/h1&gt;&#123;% endblock main %&#125; HTML转义return render(request,'myapp/index.html', &#123;\"stu\":student,\"str\":\"hello world\", \"list\":[\"good\",\"nice\",\"handsome\"], 'code':'&lt;h1&gt;sunck is a very good man&lt;/h1&gt;'&#125;)&#123;&#123;code&#125;&#125; //此处的code被当作普通字符串渲染&#123;&#123;code|safe&#125;&#125; //此处的code被当作html渲染&#123;% autoescape off %&#125; &#123;&#123;code&#125;&#125; //此处的code被当作html渲染&#123;% endautoescape %&#125;&#123;% autoescape on %&#125; &#123;&#123;code&#125;&#125; //此处的code被当作普通字符串渲染&#123;% endautoescape %&#125; CSRF跨站请求伪造概述：某些恶意网站包含链接、表单、按钮、js利用登录用户在浏览器中认证，从而攻击服务器(如下面的实例中,攻击者拷贝网页源代码，然后将改为即可进行恶意攻击) 防止CSRF:1.在settings.py文件中的MDIILEWARE增加&apos;django.middleware.csrf.CsrfViewMiddleware&apos;2.在表单中增加&#123;% csrf_token%&#125;，其实就是加了验证，并没有绝对的安全，需要隐藏 //postfile.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"/showinfo/\" method=\"post\"&gt; &#123;% csrf_token %&#125; 姓名：&lt;input type=\"text\" name=\"username\"/&gt; &lt;hr/&gt; 密码：&lt;input type=\"password\" name=\"passwd\"/&gt; &lt;hr/&gt; &lt;input type=\"submit\" value=\"登录\"/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; //showinfo.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;name:&#123;&#123;username&#125;&#125;&lt;/h1&gt; &lt;h1&gt;password:&#123;&#123;passwd&#125;&#125;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; #views.pydef postfile(request): return render(request,'myapp/postfile.html')def showinfo(request): name=request.POST.get('username') pwd = request.POST.get('passwd') return render(request,'myapp/showinfo.html', &#123;\"username\":name, \"passwd\":pwd&#125;) 验证码作用： 1.防止暴力请求 2.防止csrf的一种方式 用到的数据： insert into myapp_grades(gname,gdate,ggirlnum,gboynum,isDelete) values(“python01”,”2017-2-4”,10,50,0),(“python02”,”2017-5-4”,10,20,0),(“python03”,”2018-8-5”,50,50,0),(“python04”,”2018-6-15”,10,42,0); insert into myapp_students(sname,sgender,scontend,isDelete,sgrade_id,sage) values(“蔡徐坤”,0,”我叫蔡徐坤”,0,4,20), (“刘德华”,0,”我叫刘德华”,0,1,25), (“陈瑞豪”,0,”我叫陈瑞豪”,0,3,18), (“黑雪姬”,1,”我叫黑雪姬”,0,2,14), (“有田春雪”,0,”我叫有田春雪”,0,2,13);","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Django05-高级扩展(celery未讲完)","slug":"Django05-高级扩展(celery未讲完)","date":"2019-07-22T01:14:50.000Z","updated":"2019-09-01T13:00:27.233Z","comments":true,"path":"2019/07/22/Django05-高级扩展(celery未讲完)/","link":"","permalink":"/2019/07/22/Django05-高级扩展(celery未讲完)/","excerpt":"","text":"静态文件css、js、图片、json文件、字体文件等 static目录是创建在最外层的project下的，也就是和templates是同级的 配置settings.py： STATIC_URL = '/static/'STATICFILES_DIRS = [ os.path.join(BASE_DIR, \"static\")] &#123;% load static from staticfiles %&#125;&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;首页&lt;/title&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/static/myapp/css/style.css\"/&gt; &lt;script type=\"text/javascript\" src=\"/static/myapp/js/sunck.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;sunck is a good man&lt;/h1&gt; &lt;img src=\"/static/myapp/img/56464486_p0.png\"/&gt; &lt;img src=\"&#123;% static 'myapp/img/56464486_p0.png' %&#125;\"&gt; //static拿到的是STATIC_URL&lt;/body&gt;&lt;/html&gt; 中间件概述：一个轻量级、底层的插件，可以介入Django的请求和响应 方法： __init__：不需要传参，服务器响应第一个请求时自动调用，用于确定是否启用该中间件 process_request(self,request)：在执行视图之前被调用(分配url匹配视图前)，每个请求都会调用，返回None或者HttpResponse对象 process_view(self,request,view_func,view_args,view_kwargs)：调用视图之前，每个请求都会调用，返回None或者HttpREsponse对象 process_template_response(self,request,response)：在视图刚好执行完后调用，每个请求都会调用，返回None或者HttpREsponse对象；使用render process_reponse(self,request,response)：所有响应返回浏览器前调用，每个请求都会调用，返回HttpREsponse对象 process_exception(self,request,exception)：当视图抛出异常时调用，返回HttpREsponse对象 自定义中间件：在工程目录project下创建middleware目录，再创建myapp目录 #settings.py MIDDLEMARE中添加我们定义的中间件MIDDLEWARE = [ ... 'middleware.myapp.mymiddle.MyMiddle'] #mymiddle.pyfrom django.utils.deprecation import MiddlewareMixinclass MyMiddle(MiddlewareMixin): def process_request(self,request): print(\"get参数为：\",request.GET.get(\"a\")) 上传图片概述：文件上传时，文件数据存储在request.FILES属性中 存储路径：在static目录下创建upfile目录 注意：form表单要上爱吃文件需要加上enctype=”multipart/form-data”;上传文件必须是POST请求 #配置settings.py 上传文件目录MEDIA_ROOT=os.path.join(BASE_DIR,r'static\\upfile') #upfile.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form method=\"post\" action=\"/savefile/\" enctype=\"multipart/form-data\"&gt; &#123;%csrf_token%&#125; &lt;input type=\"file\" name=\"file1\"&gt; &lt;input type=\"submit\" value=\"上传\"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; #views.pydef upfile(request): return render(request,'myapp/upfile.html')def savefile(request): if request.method==\"POST\": f=request.FILES[\"file1\"] #文件在服务器端的路径 filePath=os.path.join(settings.MEDIA_ROOT,f.name) with open(filePath,'wb') as fp: for info in f.chunks(): #如果文件太大 fp.write(info) return HttpResponse(\"上传成功\") else: return HttpResponse(\"上传失败\") 分页Paginator对象： 创建对象： 格式：Paginator(列表,每页个数) 返回值：返回分页对象 属性： count：对象总数 num_pages：页面总数 page_ranges：页码列表(页码从1开始) 方法： page(num)：获得一个Page对象，如果提供的页码不存在会抛出”InvalidPage”异常 异常： InvalidPage：无效页码 PageNotAnInteger：page()传递的参数不是一个整数 EmptyPage：当page()传递有效值但该页面没有数据输出时 Page对象： 属性： object_list：当前页上所有的数据列表 number：当前页的页码值 paginator：当前page对象关联的paginator对象 方法： has_next()：判断是否有下一页 has_previous()：判断是否有上一页 has_other_pages()：判断是否有上一页或下一页 next_page_number()：返回下一页的页码，如果下一页不存在抛出InvalidPage异常 previous_page_number()：返回上一页的页码，如果下一页不存在抛出InvalidPage异常 len()：返回当前页的数据个数 #views.pyfrom .models import Studentsfrom django.core.paginator import Paginatordef studentpage(request,pageid): allList=Students.objects.all() paginator=Paginator(allList,2) page=paginator.page(pageid) return render(request,'myapp/studentpage.html', &#123;\"students\":page&#125;) #studentpage.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;学生分页显示&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;ul&gt; &#123;% for stu in students %&#125; &lt;li&gt; &#123;&#123;stu.sname&#125;&#125;--&#123;&#123;stu.sgrade&#125;&#125; &lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; &lt;ul&gt; &#123;% for index in students.paginator.page_range %&#125; &#123;% ifequal index students.number %&#125; &lt;li&gt; &#123;&#123;index&#125;&#125; &lt;/li&gt; &#123;% else %&#125; &lt;li&gt; &lt;a href=\"/studentpage/&#123;&#123;index&#125;&#125;/\"&gt;&#123;&#123;index&#125;&#125;&lt;/a&gt; &lt;/li&gt; &#123;% endifequal %&#125; &#123;% endfor%&#125; &lt;/ul&gt;&lt;/body&gt;&lt;/html&gt; Ajax#sunck.js$(document).ready(function()&#123; document.getElementById(\"btn\").onclick= function()&#123; $.ajax(&#123; type:\"get\", url:\"/studentsinfo/\", dataType:\"json\", success:function(data,status)&#123; console.log(data) var d=data[\"data\"] for(var i=0;i&lt;d.length;i++)&#123; document.write('&lt;p&gt;'+d[i][0]+'&lt;/p&gt;') &#125; &#125; &#125;) &#125;&#125;) #ajaxstudents.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"/static/myapp/js/jquery-3.1.1.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;学生信息列表&lt;/h1&gt; &lt;button id=\"btn\"&gt;显示学生信息&lt;/button&gt; &lt;script type=\"text/javascript\" src=\"/static/myapp/js/sunck.js\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; #views.pydef ajaxstudents(request): return render(request, 'myapp/ajaxstudents.html')from django.http import JsonResponsedef studentsinfo(request): stus=Students.objects.all() list=[] for stu in stus: list.append([stu.sname,stu.sage]) return JsonResponse(&#123;\"data\":list&#125;)#urls.pyurl(r'^studentsinfo/$',views.studentsinfo) 富文本首先安装django-tinymce,配置完后需要重新执行迁移 1.在admin站点中使用： 配置settings.py #settings.pyINSTALLED_APPS = [ ... 'tinymce']#富文本 文字加粗等TINYMCE_DEFAULT_CONFIG=&#123; 'theme':'advanced', 'width':600, 'height':400,&#125; #model.pyfrom tinymce.models import HTMLFieldclass Text(models.Model): str=HTMLField() #admin.pyfrom .models import Textadmin.site.register(Text) 2.在自定义视图中使用 #edit.html&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;富文本&lt;/title&gt; &lt;script type=\"text/javascript\" src=\"/static/tiny_mce/tiny_mce.js\"&gt;&lt;/script&gt; //这里会自动添加 不需要自己手动添加js文件 &lt;script type=\"text/javascript\"&gt; tinyMCE.init(&#123; 'mode':'textareas', 'theme':'advanced', 'width':800, 'height':600 &#125;) &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"/saveedit/\" method=\"post\"&gt; &lt;textarea name=\"str\"&gt;sunck is a good man&lt;/textarea&gt; &lt;input type=\"submit\" value=\"提交\"/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; #views.pydef edit(request): return render(request,'myapp/edit.html') celery问题： 1.用户发起request，并且要等待response返回，但是视图中有一些很耗时的操作(如发邮件)，导致用户体验很差 2.每隔一段时间要同步一次数据，但http请求是需要触发的 解决： 1.将耗时的操作放到celery中执行 2.使用celery定时执行 celery： 任务：将耗时操作封装成一个函数 队列：将要执行的任务放入队列 工人：负责执行队列中的任务 代理：负责调度，在步数环境中使用redis 配置环境： pip install celerypip install celery-with-redispip install django-celery 配置settings.py #settings.pyINSTALLED_APPS = [ ... 'djcelery']#celeryimport djcelerydjcelery.setup_loader() #初始化BROKER_URL='redis://123456@127.0.0.1:6379/0' #BROKER:代理密码 主机地址 redis的第0个库CELERY_IMPORTS='myapp.task' 然后再project/myapp目录下创建task.py文件，然后直接迁移(不用生成迁移文件，即直接migrate) 在工程文件project目录中的project目录下(和settings.py同目录)创建celery.py文件 #celery.pyimport osfrom celery import Celeryfrom django.conf import settingsos.environ.setdefault('DJANGO_SETTINGS_MODULE','whthas_home.settings')app=Celery('portal')app.config_from_object('django.conf:settings')app.autodiscover_tasks(lambda:settings.INSTALLED_APPS)@app.task(bind=True)def def_task(self): print('Request:&#123;0!r&#125;'.format(self.request)) #project/project/__init__.py中添加from .celery import app as celery_app","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Django02-模型","slug":"Django02-模型","date":"2019-07-21T13:20:01.000Z","updated":"2019-09-01T13:14:54.832Z","comments":true,"path":"2019/07/21/Django02-模型/","link":"","permalink":"/2019/07/21/Django02-模型/","excerpt":"","text":"模型、属性、表、字段之间的关系：一个模型类在数据库中对应一张表，在模型类中定义的属性，对应该模型对照表中的一个字段 属性定义属性时，需要的字段类型，都被定义在django.db.models.fields目录下，为方便使用，导入到django.db.models 逻辑删除对于重要的数据作逻辑删除，不做物理删除，实现方法是定义isdDelete属性，类型为BooleanField,默认值为False 字段类型AutoField： 一个根据实际ID自动增长的IntegerField，通常不指定，如果不指定，一个主键字段将自动添加到模型中 CharField(max_length=字符长度): 字符串，默认的表单样式是TextInput TextField: 大文本字段，一般超过4000使用，默认的表单控件是Textarea IntegerField： 整数字段 DecimalField(max_digits=None,decimal_places=None)： 使用python的Decimal实例表示的十进制浮点数，max_digits表示位数总数，decimal_places表示小数点后的数字位数 FloatField： 使用python的float实例来表示浮点数 BooleanField： True/Flase,默认表单控制是CheckboxInput NullBooleanField： 支持null、True、Flase三种值 DateField(auto_now=False,auto_now_add=False): 使用python中的datetime.date实例表示的日期，auto_now表示每次保存对象时，自动设置该字段为当前时间，用于“最后一次修改”的时间戳，它总是当前日期。auto_now_add表示当对象第一次被创建时自动设置当前时间，用于创建时的时间戳，它总是使用当前日期。 TimeField、DateTimeField、FileField、ImageField sage = models.IntegerField(db_column='age') #db_column修改字段名称，如果不设置则默认是属性名称#null:如果为True，Django将空值以NULL存储到数据库中，默认值为False#blanke：如果为True，则该字段允许为空白，默认值为False null是数据库范畴的概念，blank是表单验证范畴的#db_column:字段的名称#db_index:若值为True，则表中会为此字段创建索引#default:默认值#primary_key:若为True，则该字段会成为模型的主键字段#unique:如果为True，该字段在表中必须有唯一值 元选项在模型类中定义Meta类，用于设置元信息 class Students(models.Model): ... ... class Meta: db_table=\"students\" #定义数据表名，推荐使用小写字母，数据表名默认为项目名小写_类名小写 ordering=['id'] #对象的默认排序字段，获取对象列表时使用 ['-id']代表降序 插入数据#cmd mysqlinsert into grades(gname,gdate,ggirlnum,gboyuym,isDelete) values(&quot;python01&quot;,&quot;2017-2-4&quot;,10,50,0),values(&quot;python01&quot;,&quot;2017-2-4&quot;,10,50,0); #查看某条数据select *from students limit2; 自定义模型管理器如果定义模型类没有指定，则默认是objects stuObj=models.Mangaer();#有了上面的定义，则原Students.objects.get(pk=1)-&gt;Students.stuObj.get(pk=1),此时objects就不存在了 自定义管理器Manager类模型管理器是Django的模型进行与数据库进行交互的接口，一个模型可以有多个模型管理器 作用:向管理器类中添加额外的方法；修改管理器返回的原始查询集(重写get_queryset()方法) class StudentsManager(models.Manager): def get_queryset(self): return super(StudentsManager,self).get_queryset().filter(isDelete=False) #super(StudentsManager,self).get_queryset()得到原来的全集 创建对象#方法1#models.py@classmethod def createStudent(cls,name,age,gender,contend,grade, lastT,createT,isD=False): stu=cls(sname=name,sage=age,sgender=gender, scontend=contend,sgrade=grade,lastTime=lastT, createTime=createT,isDelete=isD) return stu #views.pydef addstudent(request): grade=Grades.objects.get(pk=1) stu=Students.createStudent(\"刘德华\",34,True,\"Hello\",grade,\"2017-8-10\",\"2017-8-11\") stu.save() return HttpResponse(\"添加成功\") #方法2#models.pyclass StudentsManager(models.Manager): def get_queryset(self): return super(StudentsManager, self).get_queryset(). filter(isDelete=False) def createStudent(self,name,age,gender,contend,grade, lastT,createT,isD=False): stu=self.model() stu.sname=name stu.sage=age stu.sgender=gender stu.scontend=contend stu.lastTime=lastT stu.createTime=createT return stu#views.pydef addstudent2(request): grade=Grades.objects.get(pk=1) stu=Students.stuObj2.createStudent(\"刘德华\",34,True,\"Hello\", grade,\"2017-8-10\",\"2017-8-11\") stu.save() return HttpResponse(\"添加成功\") 模型查询查询集表示从数据库中获取的对象集合，查询集可以有多个过滤器，过滤器就是一个函数，基于所给的参数限制查询集结果，从sql角度来说，查询集合select语句等价，过滤器就像where条件 在管理器上调用过滤器方法返回查询集，查询集经过过滤器筛选后返回新的查询集，所以可以写成链式调用； 惰性执行：创建查询集不会带来任何数据的访问，直到调用数据时，才会访问数据 返回查询集的方法(过滤器):all(),filter(key=value).filter(key=value)…,exclude()过滤掉符合条件的数据,order_by()排序,values()一条数据就是一个对象(字典)，多条数据就是一个列表 返回单个数据:get(),count(),first(),last(),exists() get()没找到或者有多个对象都会引发异常 count()返回查询集中的对象个数 first()/last()返回查询集第一/最后一个对象 exists()判断查询集中是否有数据，如果有数据返回True 限制查询集： #返回前5条studentList=Students.stuObj2.all()[0:5] #注意：这里的下标不能是负数 #urls.pyurl(r'^stu/(\\d+)/$',views.stupage)#views.py#分页显示def stupage(request,page): page=int(page) studentList=Students.stuObj2.all()[(page-1)*5:page*5] return render(request,'myapp/students.html', &#123;'students':studentList&#125;) 查询集的缓存： 概述：每个查询集都包含一个缓存，来最小化的对数据库访问 字段查询： 概述：实现了sql中的where，作为方法filter()、exclude()、get()的参数 语法：属性名称_比较运算符=值 外键：属性名_id 转义：类似sql中的like语句，like语句中使用%是为了匹配占位 如果要匹配数据中的%(where like ‘\\%’) 比较运算符： exact：判断，大小写敏感 contains：是否包含，大小写敏感 #views.py#名字中包含孙的def studentsearch(request): studentsList=Students.stuObj.filter(sname__contains=\"孙\") return render(request,\"myapp/students.html\",&#123;\"student\":studentsList&#125;) startwith、endwith:以value开头或结尾，大小写敏感 以上4个在前面加上i就表示大小写不敏感，iexact、icontains… isnull、isnotnull：是否为空/非空 in：是否包含在范围内 pk__in=[2,4,6,8,10] gt、gte、lt、lte：大于、大于等于、小于、小于等于 year、month、day、week_day、hour、minute、second 跨关联查询：(视频中暂时出错) 处理join查询：模型类名__属性名__比较运算符 gradeList=Grades.stuObj2.all().filter(students__contend__contains='刘德华') #Grades-班级里的 students__contend__contains-学生contend中包含#学生描述中包含有“刘德华”这三个字的数据是属于哪个班级的 查询快捷：pk 代表的主键 聚合函数需要先导入相应的函数 from django.db.models import Max 使用aggregate()函数返回聚合函数的值 Avg、Count、Max、Min、Sum maxAge=Students.stuObj2.aggregate(Max('age')) #拿到的是最大值而不是数据 F对象、Q对象F对象：可以使用模型的A属性与B属性进行比较 from django.db.models import F,Qdef grades(request): Grades.objects.filter(ggirlnum__gt=F('gboynum')+20) Q对象： 概述：过滤器方法中的关键字参数，条件为and模式 需求：进行or查询 解决：使用Q对象 from django.db.models import F,Qdef grades(request): Grades.objects.filter(Q(pk__lte=3) | Q(sage_gt=50))) #pk小于等于3或者年龄大于50的 #Grades.objects.filter(~Q(pk__lte=3)) pk大于3的","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Django01-基本流程","slug":"Django01-基本流程","date":"2019-07-21T11:16:01.000Z","updated":"2019-09-01T13:00:33.422Z","comments":true,"path":"2019/07/21/Django01-基本流程/","link":"","permalink":"/2019/07/21/Django01-基本流程/","excerpt":"","text":"创建数据库进入数据库(系统权限cmd) mysql -u root -p create DATABASE Django1; 配置数据库首先在__init__.py下添加以下代码： import pymysqlpymysql.install_as_MySQLdb() _settings\\_.py下修改以下代码： DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 数据库名, 'USER': , 'PASSWORD': , 'HOST': 'localhost', #数据库服务器ip 'PORT': ‘3306’, &#125;&#125; 创建应用进入django项目目录 python manage.py startapp myapp 目录说明： admin.py:站点配置 models.py:模型 views.py:视图 在settings.py文件中将myapp应用加入到INSTALLED_APPS选项中 定义模型概述：一个数据表对应一个模型 在myapp下的models.py中创建 from django.db import models# Create your models here.#不要写init方法class Grades(models.Model): gname = models.CharField(max_length=20) gdate = models.DateTimeField() ggirlnum = models.IntegerField() gboynum = models.IntegerField() isDelete = models.BooleanField(default=False)class Students(models.Model): sname =models.CharField(max_length=20) sgender = models.BooleanField(default=True) sage = models.IntegerField() scontend = models.CharField(max_length=20) isDelete = models.BooleanField(default=False) #关联外键 sgrade = models.ForeignKey(\"Grades\") #类名 在数据库中生成数据表生成迁移文件：在migrations目录下生成一个迁移文件，此时数据库中还没有生成数据表 python manage.py makemigrations 执行迁移：相当于执行mysql语句创建数据表 python manage.py migrate 查看数据表： use django1show tables;desc myapp_grades; 测试数据操作： python manage.py shellfrom myapp.models import Grades,Studentsfrom django.utils import timezonefrom datetime import * 数据操作： Grades.object.all() #类名.object.all()grade1.gname=\"pythonname\"...grade1.save() #保存到数据库 #重写__str__()方法方便查看结果def __str__(self): return \"%s-%d-%d\"%(self.gname,self.ggirlnum,self.gboynum)#查询某个对象Grades.object.get(pk=2) #id=2的对象 primary key#删除对象grade1.delete() 关联对象获得关联对象的集合： #获取python04班级所有学生#对象名.关联类名小写_set.all()grades1.students_set.all() 创建对象 stu3=grade1.students_set.create(sname=&apos;&apos;,...) 需求：在创建班级时直接创建多个学生 class StudentsInfo(admin.TabularInline): #admin.StackedInline 两者只是显示方式不一样 model = Students extra = 2 #同时在GradeAdmin添加class GradeAdmin(admin.ModelAdmin): inlines = [StudentsInfo] 服务器启动服务器： python manage.py runserver ip:port #ip可有不写，不写代表本机ip 端口号默认8000 创建用户： python manage.py createsuperuser#然后按照提示输入用户名和密码 进入http://127.0.0.1:8000/admin/ 汉化： 把settings.py中的LANGUAGE_CODE=’zh_Hans’ TIME_ZONE=’Asia/Shanghai’ 管理数据表修改admin.py from django.contrib import admin# Register your models here.from .models import Grades,Students#注册class GradeAdmin(admin.ModelAdmin): #列表页属性 list_display = ['pk','gname','gdate','ggirl'] #显示的数据字段 list_filter = ['gname'] #过滤字段 search_fields = ['gname'] #搜索字段 list_per_page = 5 #分页 #添加 修改页属性 fields = [] #添加页各字段显示的顺序 fieldsets = [ (\"num\",&#123;\"fields\":[\"ggirlnum\",\"gboynum\"]&#125;), (\"base\", &#123;\"fields\": [\"gname\",\"gdate\",\"isDelete\"]&#125;), ] #给属性分组 和fields同时使用admin.site.register(Grades,GradeAdmin)admin.site.register(Students) 布尔值的显示class StudentsAdmin(admin.ModelAdmin): def gender(self): #写完该函数，要将list_display列表中的sgender修改为当前的函数名 if self.sgender: return \"男\" else: return \"女\" gender.short_description = \"性别\" #修改字段的描述 执行动作问题#执行动作的位置actions_on_top = Falseactions_on_bottom = True 使用装饰器完成注册将admin.site.register(Students,StudentsAdmin)注释掉，然后再相应的类上面(这里是Students)添加@admin.register(Students) 定义视图#views.pyfrom django.shortcuts import render# Create your views here.from django.http import HttpResponsedef index(request): return HttpResponse(\"Hello World!\") 配置url： 修改project目录下的urls.py文件 from django.conf.urls import url,includefrom django.contrib import adminurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^',include('myapp.urls'))] 在myapp目录下创建一个urls.py from django.conf.urls import urlfrom . import viewsurlpatterns = [ url(r'^$',views.index) #什么后缀都没有（即http://127.0.0.1:8000） 这里的意思即是对应到views.py中的index函数] 但此时如果http://127.0.0.1:8000/2会没有对应的响应页面 #myapp\\urls.py#添加对应的后缀匹配url(r'^(\\d+)$',views.detail) #(\\d+)的括号是组的概念，用于传递参数num#views.pydef detail(request,num): return HttpResponse(\"detail-%s\"%num) 模板的基本使用概述：模板是html页面，可以根据视图中传递过来的数据进行填充 创建模板目录： 在最外层的project目录下创建templates目录，再在目录下创建对应项目的目录模板(project/templates/myapp) 配置模板路径： 修改settings.py文件下的TEMPLATES 'DIRS': [os.path.join(BASE_DIR,'templates')] 定义视图模板文件： 模板语法：1.输出值，可以是变量，也可以是对象.属性2.&#123;%执行代码段%&#125; &lt;ul&gt; &#123;%for grade in grades%&#125; //这里被传入了gradesList &lt;li&gt; &lt;a href=\"&#123;&#123;grade.id&#125;&#125;\"&gt;&#123;&#123;grade.gname&#125;&#125;&lt;/a&gt; &lt;/li&gt; &#123;%endfor%&#125;&lt;/ul&gt; #views.pyfrom .models import Gradesdef grades(request): #去模板里取数据 gradesList=Grades.objects.all() #将数据传递给模板,模板再渲染页面，将渲染好的页面返回浏览器 return render(request,'myapp/grades.html',&#123;\"grades\":gradesList&#125;)def gradesStudents(request,num): grade=Grades.objects.get(pk=num) studentsList=grade.students_set.all() return render(request,'myapp/students.html',&#123;\"students\",studentsList&#125;)","categories":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"/tags/Django/"},{"name":"技术","slug":"技术","permalink":"/tags/技术/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"/categories/技术/"}]},{"title":"Hexo-Theme-Sakura","slug":"Hexo-Theme-Sakura","date":"2018-12-12T14:16:01.000Z","updated":"2019-10-07T14:54:29.321Z","comments":true,"path":"2018/12/12/Hexo-Theme-Sakura/","link":"","permalink":"/2018/12/12/Hexo-Theme-Sakura/","excerpt":"","text":"hexo-theme-sakura主题 English document 基于WordPress主题Sakura修改成Hexo的主题。 demo预览 正在开发中…… 交流群若你是使用者，加群QQ: 801511924 若你是创作者，加群QQ: 194472590 主题特性 首页大屏视频 首页随机封面 图片懒加载 valine评论 fancy-box相册 pjax支持，音乐不间断 aplayer音乐播放器 多级导航菜单（按现在大部分hexo主题来说，这也算是个特性了） 赞赏作者如果喜欢hexo-theme-sakura主题，可以考虑资助一下哦~非常感激！ paypal | Alipay 支付宝 | WeChat Pay 微信支付 未完善的使用教程那啥？老实说我目前也不是很有条理233333333~ 1、主题下载安装hexo-theme-sakura建议下载压缩包格式，因为除了主题内容还有些source的配置对新手来说比较太麻烦，直接下载解压就省去这些麻烦咯。 下载好后解压到博客根目录（不是主题目录哦，重复的选择替换）。接着在命令行（cmd、bash）运行npm i安装依赖。 2、主题配置博客根目录下的_config配置站点# Sitetitle: 你的站点名subtitle:description: 站点简介keywords:author: 作者名language: zh-cntimezone: 部署deploy: type: git repo: github: 你的github仓库地址 # coding: 你的coding仓库地址 branch: master 备份 （使用hexo b发布备份到远程仓库）backup: type: git message: backup my blog of https://honjun.github.io/ repository: # 你的github仓库地址,备份分支名 （建议新建backup分支） github: https://github.com/honjun/honjun.github.io.git,backup # coding: https://git.coding.net/hojun/hojun.git,backup 主题目录下的_config配置其中标明【改】的是需要修改部门，标明【选】是可改可不改，标明【非】是不用改的部分# site name# 站点名 【改】prefixName: さくら荘そのsiteName: hojun# favicon and site master avatar# 站点的favicon和头像 输入图片路径（下面的配置是都是cdn的相对路径，没有cdn请填写完整路径，建议使用jsdeliver搭建一个cdn啦，先去下载我的cdn替换下图片就行了，简单方便~）【改】favicon: /images/favicon.icoavatar: /img/custom/avatar.jpg# 站点url 【改】url: https://sakura.hojun.cn# 站点介绍（或者说是个人签名）【改】description: Live your life with passion! With some drive!# 站点cdn，没有就为空 【改】 若是cdn为空，一些图片地址就要填完整地址了，比如之前avatar就要填https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/custom/avatar.jpgcdn: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6# 开启pjax 【选】pjax: 1# 站点首页的公告信息 【改】notice: hexo-Sakura主题已经开源，目前正在开发中...# 懒加载的加载中图片 【选】lazyloadImg: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/loader/orange.progress-bar-stripe-loader.svg# 站点菜单配置 【选】menus: 首页: &#123; path: /, fa: fa-fort-awesome faa-shake &#125; 归档: &#123; path: /archives, fa: fa-archive faa-shake, submenus: &#123; 技术: &#123;path: /categories/技术/, fa: fa-code &#125;, 生活: &#123;path: /categories/生活/, fa: fa-file-text-o &#125;, 资源: &#123;path: /categories/资源/, fa: fa-cloud-download &#125;, 随想: &#123;path: /categories/随想/, fa: fa-commenting-o &#125;, 转载: &#123;path: /categories/转载/, fa: fa-book &#125; &#125; &#125; 清单: &#123; path: javascript:;, fa: fa-list-ul faa-vertical, submenus: &#123; 书单: &#123;path: /tags/悦读/, fa: fa-th-list faa-bounce &#125;, 番组: &#123;path: /bangumi/, fa: fa-film faa-vertical &#125;, 歌单: &#123;path: /music/, fa: fa-headphones &#125;, 图集: &#123;path: /tags/图集/, fa: fa-photo &#125; &#125; &#125; 留言板: &#123; path: /comment/, fa: fa-pencil-square-o faa-tada &#125; 友人帐: &#123; path: /links/, fa: fa-link faa-shake &#125; 赞赏: &#123; path: /donate/, fa: fa-heart faa-pulse &#125; 关于: &#123; path: /, fa: fa-leaf faa-wrench , submenus: &#123; 我？: &#123;path: /about/, fa: fa-meetup&#125;, 主题: &#123;path: /theme-sakura/, fa: iconfont icon-sakura &#125;, Lab: &#123;path: /lab/, fa: fa-cogs &#125;, &#125; &#125; 客户端: &#123; path: /client/, fa: fa-android faa-vertical &#125; RSS: &#123; path: /atom.xml, fa: fa-rss faa-pulse &#125;# Home page sort type: -1: newer first，1: older first. 【非】homePageSortType: -1# Home page article shown number) 【非】homeArticleShown: 10# 背景图片 【选】bgn: 8# startdash面板 url, title, desc img 【改】startdash: - &#123;url: /theme-sakura/, title: Sakura, desc: 本站 hexo 主题, img: /img/startdash/sakura.md.png&#125; - &#123;url: http://space.bilibili.com/271849279, title: Bilibili, desc: 博主的b站视频, img: /img/startdash/bilibili.jpg&#125; - &#123;url: /, title: hojun的万事屋, desc: 技术服务, img: /img/startdash/wangshiwu.jpg&#125;# your site build time or founded date# 你的站点建立日期 【改】siteBuildingTime: 07/17/2018# 社交按钮(social) url, img PC端配置 【改】social: github: &#123;url: http://github.com/honjun, img: /img/social/github.png&#125; sina: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/sina.png&#125; wangyiyun: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/wangyiyun.png&#125; zhihu: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/zhihu.png&#125; email: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/email.svg&#125; wechat: &#123;url: /#, qrcode: /img/custom/wechat.jpg, img: /img/social/wechat.png&#125;# 社交按钮(msocial) url, img 移动端配置 【改】msocial: github: &#123;url: http://github.com/honjun, fa: fa-github, color: 333&#125; weibo: &#123;url: http://weibo.com/mashirozx?is_all=1, fa: fa-weibo, color: dd4b39&#125; qq: &#123;url: https://wpa.qq.com/msgrd?v=3&amp;uin=954655431&amp;site=qq&amp;menu=yes, fa: fa-qq, color: 25c6fe&#125;# 赞赏二维码（其中wechatSQ是赞赏单页面的赞赏码图片）【改】donate: alipay: /img/custom/donate/AliPayQR.jpg wechat: /img/custom/donate/WeChanQR.jpg wechatSQ: /img/custom/donate/WeChanSQ.jpg# 首页视频地址为https://cdn.jsdelivr.net/gh/honjun/hojun@1.2/Unbroken.mp4，配置如下 【改】movies: url: https://cdn.jsdelivr.net/gh/honjun/hojun@1.2 # 多个视频用逗号隔开，随机获取。支持的格式目前已知MP4,Flv。其他的可以试下，不保证有用 name: Unbroken.mp4# 左下角aplayer播放器配置 主要改id和server这两项，修改详见[aplayer文档] 【改】aplayer: id: 2660651585 server: netease type: playlist fixed: true mini: false autoplay: false loop: all order: random preload: auto volume: 0.7 mutex: true# Valine评论配置【改】valine: truev_appId: GyC3NzMvd0hT9Yyd2hYIC0MN-gzGzoHszv_appKey: mgOpfzbkHYqU92CV4IDlAUHQ 分类页和标签页配置分类页 标签页 配置项在\\themes\\Sakura\\languages\\zh-cn.yml里。新增一个分类或标签最好加下哦，当然嫌麻烦可以直接使用一张默认图片（可以改主题或者直接把404图片替换下，征求下意见要不要给这个在配置文件中加个开关，可以issue或群里提出来），现在是没设置的话会使用那种倒立小狗404哦。#category# 按分类名创建技术: #中文标题 zh: 野生技术协会 # 英文标题 en: Geek – Only for Love # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/coding.jpg生活: zh: 生活 en: live img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/writing.jpg#tag# 标签名即是标题悦读: # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/reading.jpg 单页面封面配置如留言板页面页面，位于source下的comment下，打开index.md如下：---title: commentdate: 2018-12-20 23:13:48keywords: 留言板description: comments: true# 在这里配置单页面头部图片，自定义替换哦~photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/comment.jpg--- 单页面配置番组计划页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） ---layout: bangumititle: bangumicomments: falsedate: 2019-02-10 21:32:48keywords:description:bangumis: # 番组图片 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg # 番组名 title: 朝花夕誓——于离别之朝束起约定之花 # 追番状态 （追番ing/已追完） status: 已追完 # 追番进度 progress: 100 # 番剧日文名称 jp: さよならの朝に約束の花をかざろう # 放送时间 time: 放送时间: 2018-02-24 SUN. # 番剧介绍 desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg title: 朝花夕誓——于离别之朝束起约定之花 status: 已追完 progress: 50 jp: さよならの朝に約束の花をかざろう time: 放送时间: 2018-02-24 SUN. desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。--- 友链页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） ---layout: linkstitle: links# 创建日期，可以改下date: 2018-12-19 23:11:06 # 图片上的标题，自定义修改keywords: 友人帐 description: # true/false 开启/关闭评论comments: true # 页面头部图片，自定义修改photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/links.jpg # 友链配置links: # 类型分组 - group: 个人项目 # 类型简介 desc: 充分说明这家伙是条咸鱼 &lt; (￣︶￣)&gt; items: # 友链链接 - url: https://shino.cc/fgvf # 友链头像 img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg # 友链站点名 name: Google # 友链介绍 下面雷同 desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 # 类型分组... - group: 小伙伴们 desc: 欢迎交换友链 ꉂ(ˊᗜˋ) items: - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像--- 写文章配置主题集成了个人插件hexo-tag-bili和hexo-tag-fancybox_img。其中hexo-tag-bili用来在文章或单页面中插入B站外链视频，使用语法如下：&#123;% bili video_id [page] %&#125; 详细使用教程详见hexo-tag-bili。 hexo-tag-fancybox_img用来在文章或单页面中图片，使用语法如下：&#123;% fb_img src [caption] %&#125; 详细使用教程详见hexo-tag-fancybox_img 还有啥，一时想不起来……To be continued…","categories":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"/tags/hexo/"},{"name":"博客","slug":"博客","permalink":"/tags/博客/"}],"keywords":[{"name":"转载","slug":"转载","permalink":"/categories/转载/"}]}]}